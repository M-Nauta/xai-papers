[
  {
    "Paper-ID": "ijcai/PanLLZ20",
    "Title": "Explainable Recommendation via Interpretable Feature Mapping and Evaluation of Explainability.",
    "url": "https://doi.org/10.24963/ijcai.2020/373",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Deng Pan",
      "Xiangrui Li",
      "Xin Li 0081",
      "Dongxiao Zhu"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/TuHW0HZ20",
    "Title": "Select, Answer and Explain - Interpretable Multi-Hop Reading Comprehension over Multiple Documents.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/6441",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Ming Tu",
      "Kevin Huang 0002",
      "Guangtao Wang",
      "Jing Huang 0019",
      "Xiaodong He 0002",
      "Bowen Zhou"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/EsserRO20",
    "Title": "A Disentangling Invertible Interpretation Network for Explaining Latent Representations.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00924",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Patrick Esser",
      "Robin Rombach",
      "Bj\u00f6rn Ommer"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Representation Synthesis",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/LiuMWH0G20",
    "Title": "LP-Explain - Local Pictorial Explanation for Outliers.",
    "url": "https://doi.org/10.1109/ICDM50108.2020.00046",
    "Year": "2020",
    "Venue": "ICDM",
    "Authors": [
      "Haoyu Liu",
      "Fenglong Ma",
      "Yaqing Wang",
      "Shibo He",
      "Jiming Chen 0001",
      "Jing Gao"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Anomaly detection"
    ],
    "Type of Explanation": [
      "Feature plot"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/TsangCLFZL20",
    "Title": "Feature Interaction Interpretability - A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection.",
    "url": "https://openreview.net/forum?id=BkgnhTEtDS",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Michael Tsang",
      "Dehua Cheng",
      "Hanpeng Liu",
      "Xue Feng",
      "Eric Zhou",
      "Yan Liu 0002"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "Graph data",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Recommendation"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/RiegerSMY20",
    "Title": "Interpretations are Useful - Penalizing Explanations to Align Neural Networks with Prior Knowledge.",
    "url": "http://proceedings.mlr.press/v119/rieger20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Laura Rieger",
      "Chandan Singh",
      "W. James Murdoch",
      "Bin Yu"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/PanHLZL20",
    "Title": "xGAIL - Explainable Generative Adversarial Imitation Learning for Explainable Human Decision Analysis.",
    "url": "https://doi.org/10.1145/3394486.3403186",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Menghai Pan",
      "Weixiao Huang",
      "Yanhua Li",
      "Xun Zhou",
      "Jun Luo 0007"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/PalejaSCG20",
    "Title": "Interpretable and Personalized Apprenticeship Scheduling - Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/477bdb55b231264bb53a7942fd84254d-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Rohan R. Paleja",
      "Andrew Silva",
      "Letian Chen",
      "Matthew C. Gombolay"
    ],
    "Type of Data": [
      "Graph data",
      "Other"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/VuT20",
    "Title": "PGM-Explainer - Probabilistic Graphical Model Explanations for Graph Neural Networks.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/8fb134f258b1f7865a6ab2d935a897c9-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Minh N. Vu",
      "My T. Thai"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ZhouHZLSXT20",
    "Title": "Towards Interpretable Natural Language Understanding with Explanations as Latent Variables.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/4be2c8f27b8a420492f2d44463933eb6-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Wangchunshu Zhou",
      "Jinyi Hu",
      "Hanlin Zhang",
      "Xiaodan Liang",
      "Maosong Sun",
      "Chenyan Xiong",
      "Jian Tang"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/SenGVJ20",
    "Title": "The Curious Case of IR Explainability - Explaining Document Scores within and across Ranking Models.",
    "url": "https://doi.org/10.1145/3397271.3401286",
    "Year": "2020",
    "Venue": "SIGIR",
    "Authors": [
      "Procheta Sen",
      "Debasis Ganguly",
      "Manisha Verma",
      "Gareth J. F. Jones"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Other"
    ],
    "Type of Task": [
      "Retrieval"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/LiuYW19",
    "Title": "Towards Explainable NLP - A Generative Explanation Framework for Text Classification.",
    "url": "https://doi.org/10.18653/v1/p19-1560",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Hui Liu",
      "Qingyu Yin",
      "William Yang Wang"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text",
      "Other"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/WagnerKGHWB19",
    "Title": "Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wagner_Interpretable_and_Fine-Grained_Visual_Explanations_for_Convolutional_Neural_Networks_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "J\u00f6rg Wagner",
      "Jan Mathias K\u00f6hler",
      "Tobias Gindele",
      "Leon Hetzel",
      "Jakob Thadd\u00e4us Wiedemer",
      "Sven Behnke"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/MWT19",
    "Title": "Visual Explanation by Interpretation - Improving Visual Feedback Capabilities of Deep Neural Networks.",
    "url": "https://openreview.net/forum?id=H1ziPjC5Fm",
    "Year": "2019",
    "Venue": "ICLR",
    "Authors": [
      "Jos\u00e9 Oramas M.",
      "Kaili Wang",
      "Tinne Tuytelaars"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/Wang19",
    "Title": "Gaining Free or Low-Cost Interpretability with Interpretable Partial Substitute.",
    "url": "http://proceedings.mlr.press/v97/wang19a.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Tong Wang"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Text",
      "Time series"
    ],
    "Type of Problem": [
      "Model Explanation",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/SchwabK19",
    "Title": "CXPlain - Causal Explanations for Model Interpretation under Uncertainty.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/3ab6be46e1d6b21d59a3c3a0b9d0f6ef-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Patrick Schwab",
      "Walter Karlen"
    ],
    "Type of Data": [
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/ChenCXZ0QZ19",
    "Title": "Personalized Fashion Recommendation with Visual Explanations based on Multimodal Attention Network - Towards Visually Explainable Recommendation.",
    "url": "https://doi.org/10.1145/3331184.3331254",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Xu Chen 0017",
      "Hanxiong Chen",
      "Hongteng Xu",
      "Yongfeng Zhang",
      "Yixin Cao 0002",
      "Zheng Qin",
      "Hongyuan Zha"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/VermaG19",
    "Title": "LIRME - Locally Interpretable Ranking Model Explanation.",
    "url": "https://doi.org/10.1145/3331184.3331377",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Manisha Verma",
      "Debasis Ganguly"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic",
      "Other"
    ],
    "Type of Task": [
      "Retrieval"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ZhangCSWZ18",
    "Title": "Interpreting CNN Knowledge via an Explanatory Graph.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17354",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Quanshi Zhang",
      "Ruiming Cao",
      "Feng Shi",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Graph",
      "Prototypes",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/YangLWH18",
    "Title": "Towards Interpretation of Recommender Systems with Sorted Explanation Paths.",
    "url": "https://doi.org/10.1109/ICDM.2018.00082",
    "Year": "2018",
    "Venue": "ICDM",
    "Authors": [
      "Fan Yang 0023",
      "Ninghao Liu",
      "Suhang Wang",
      "Xia Hu"
    ],
    "Type of Data": [
      "Tabular / structured",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/ChenSWJ18",
    "Title": "Learning to Explain - An Information-Theoretic Perspective on Model Interpretation.",
    "url": "http://proceedings.mlr.press/v80/chen18j.html",
    "Year": "2018",
    "Venue": "ICML",
    "Authors": [
      "Jianbo Chen",
      "Le Song",
      "Martin J. Wainwright",
      "Michael I. Jordan"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/PeakeW18",
    "Title": "Explanation Mining - Post Hoc Interpretability of Latent Factor Models for Recommendation Systems.",
    "url": "https://doi.org/10.1145/3219819.3220072",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Georgina Peake",
      "Jun Wang"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/Alvarez-MelisJ18",
    "Title": "Towards Robust Interpretability with Self-Explaining Neural Networks.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "David Alvarez-Melis",
      "Tommi S. Jaakkola"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/DhurandharCLTTS18",
    "Title": "Explanations based on the Missing - Towards Contrastive Explanations with Pertinent Negatives.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/c5ff2543b53f4cc0ad3819a36752467b-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Amit Dhurandhar",
      "Pin-Yu Chen",
      "Ronny Luss",
      "Chun-Chen Tu",
      "Pai-Shun Ting",
      "Karthikeyan Shanmugam",
      "Payel Das"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/FongV17",
    "Title": "Interpretable Explanations of Black Boxes by Meaningful Perturbation.",
    "url": "https://doi.org/10.1109/ICCV.2017.371",
    "Year": "2017",
    "Venue": "ICCV",
    "Authors": [
      "Ruth C. Fong",
      "Andrea Vedaldi"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/AkulaWZ20",
    "Title": "CoCoX - Generating Conceptual and Counterfactual Explanations via Fault-Lines.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5643",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Arjun R. Akula",
      "Shuai Wang",
      "Song-Chun Zhu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ChenJ20",
    "Title": "LS-Tree - Model Interpretation When the Data Are Linguistic.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5749",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Jianbo Chen",
      "Michael I. Jordan"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/CiravegnaGMMG20",
    "Title": "A Constraint-Based Approach to Learning and Explanation.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5774",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Gabriele Ciravegna",
      "Francesco Giannini",
      "Stefano Melacci",
      "Marco Maggini",
      "Marco Gori"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/DalleigerV20",
    "Title": "Explainable Data Decompositions.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5780",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Sebastian Dalleiger",
      "Jilles Vreeken"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Clustering"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model",
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/DongNCCZSLCM20",
    "Title": "Asymmetrical Hierarchical Networks with Attentive Interactions for Interpretable Review-Based Recommendation.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/6268",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Xin Dong 0010",
      "Jingchao Ni",
      "Wei Cheng 0002",
      "Zhengzhang Chen",
      "Bo Zong",
      "Dongjin Song",
      "Yanchi Liu",
      "Haifeng Chen",
      "Gerard de Melo"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/HarderBP20",
    "Title": "Interpretable and Differentially Private Predictions.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5827",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Frederik Harder",
      "Matthias Bauer",
      "Mijung Park"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/HuaiWMZ20",
    "Title": "Towards Interpretation of Pairwise Learning.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5837",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Mengdi Huai",
      "Di Wang 0015",
      "Chenglin Miao",
      "Aidong Zhang"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ItoTSYI20",
    "Title": "Word-Level Contextual Sentiment Analysis with Interpretability.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5845",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Tomoki Ito",
      "Kota Tsubouchi",
      "Hiroki Sakaji",
      "Tatsuo Yamashita",
      "Kiyoshi Izumi"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/LiFANZ20",
    "Title": "MRI Reconstruction with Interpretable Pixel-Wise Operations Using Reinforcement Learning.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5423",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Wentian Li",
      "Xidong Feng",
      "Haotian An",
      "Xiang Yao Ng",
      "Yu-Jin Zhang"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/Madumal0SV20",
    "Title": "Explainable Reinforcement Learning through a Causal Lens.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5631",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Prashan Madumal",
      "Tim Miller 0001",
      "Liz Sonenberg",
      "Frank Vetere"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic",
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/NamGCWL20",
    "Title": "Relative Attributing Propagation - Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5632",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Woo-Jeoung Nam",
      "Shir Gur",
      "Jaesik Choi",
      "Lior Wolf",
      "Seong-Whan Lee"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/PathakLMP20",
    "Title": "Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-Like Molecules.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5433",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Yashaswi Pathak",
      "Siddhartha Laghuvarapu",
      "Sarvesh Mehta",
      "U. Deva Priyakumar"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/PatroAN20",
    "Title": "Explanation vs Attention - A Two-Player Game to Obtain Attention for VQA.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/6858",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Badri N. Patro",
      "Anupriy",
      "Vinay Namboodiri"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/WangZHZS20",
    "Title": "Dynamic Network Pruning with Interpretable Layerwise Channel Selection.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/6098",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Yulong Wang",
      "Xiaolu Zhang",
      "Xiaolin Hu",
      "Bo Zhang",
      "Hang Su 0006"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Representation Visualization",
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/WuPHKCZ0D20",
    "Title": "Regional Tree Regularization for Interpretability in Deep Neural Networks.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/6112",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Mike Wu",
      "Sonali Parbhoo",
      "Michael C. Hughes",
      "Ryan Kindle",
      "Leo A. Celi",
      "Maurizio Zazzi",
      "Volker Roth 0001",
      "Finale Doshi-Velez"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ZhongWTZ0S20",
    "Title": "Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction.",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5479",
    "Year": "2020",
    "Venue": "AAAI",
    "Authors": [
      "Haoxi Zhong",
      "Yuzhong Wang",
      "Cunchao Tu",
      "Tianyang Zhang",
      "Zhiyuan Liu 0001",
      "Maosong Sun"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering",
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/AtanasovaSLA20",
    "Title": "Generating Fact Checking Explanations.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.656",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Pepa Atanasova",
      "Jakob Grue Simonsen",
      "Christina Lioma",
      "Isabelle Augenstein"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Other"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/ChenZJ20",
    "Title": "Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.494",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Hanjie Chen",
      "Guangtao Zheng",
      "Yangfeng Ji"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/GonenJSG20",
    "Title": "Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.51",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Hila Gonen",
      "Ganesh Jawahar",
      "Djam\u00e9 Seddah",
      "Yoav Goldberg"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Localization",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/HanWT20",
    "Title": "Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.492",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Xiaochuang Han",
      "Byron C. Wallace",
      "Yulia Tsvetkov"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/KumarT20",
    "Title": "NILE - Natural Language Inference with Faithful Natural Language Explanations.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.771",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Sawan Kumar",
      "Partha P. Talukdar"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text",
      "Localization"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/LuL20",
    "Title": "GCAN - Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.48",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Yi-Ju Lu",
      "Cheng-Te Li"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/MohankumarNNKSR20",
    "Title": "Towards Transparent and Explainable Attention Models.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.387",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Akash Kumar Mohankumar",
      "Preksha Nema",
      "Sharan Narasimhan",
      "Mitesh M. Khapra",
      "Balaji Vasan Srinivasan",
      "Balaraman Ravindran"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Question Answering"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/ShahbaziFGT20",
    "Title": "Relation Extraction with Explanation.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.579",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Hamed Shahbazi",
      "Xiaoli Z. Fern",
      "Reza Ghaeini",
      "Prasad Tadepalli"
    ],
    "Type of Data": [
      "Text",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/SubramanianBGWS20",
    "Title": "Obtaining Faithful Interpretations from Compositional Neural Networks.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.495",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Sanjay Subramanian",
      "Ben Bogin",
      "Nitish Gupta",
      "Tomer Wolfson",
      "Sameer Singh 0001",
      "Jonathan Berant",
      "Matt Gardner 0001"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Question Answering"
    ],
    "Type of Explanation": [
      "Localization",
      "Other"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model",
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/WuCKL20",
    "Title": "Perturbed Masking - Parameter-free Probing for Analyzing and Interpreting BERT.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.383",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Zhiyong Wu",
      "Yun Chen",
      "Ben Kao",
      "Qun Liu"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Other"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/WuRZLN20",
    "Title": "DTCA - Decision Tree-based Co-Attention Networks for Explainable Claim Verification.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.97",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Lianwei Wu",
      "Yuan Rao",
      "Yongqiang Zhao",
      "Hao Liang",
      "Ambreen Nazir"
    ],
    "Type of Data": [
      "Text",
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/ZhangSFL20",
    "Title": "Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.717",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Jingyuan Zhang",
      "Mingming Sun",
      "Yue Feng",
      "Ping Li 0001"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/ZhouZY20",
    "Title": "Interpretable Operational Risk Classification with Semi-Supervised Variational Autoencoder.",
    "url": "https://doi.org/10.18653/v1/2020.acl-main.78",
    "Year": "2020",
    "Venue": "ACL",
    "Authors": [
      "Fan Zhou",
      "Shengming Zhang",
      "Yi Yang"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ChengRCZ20",
    "Title": "Explaining Knowledge Distillation by Quantifying the Knowledge.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.01294",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Xu Cheng",
      "Zhefan Rao",
      "Yilan Chen",
      "Quanshi Zhang"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/HuangL20",
    "Title": "Interpretable and Accurate Fine-grained Recognition via Region Grouping.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00869",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Zixuan Huang",
      "Yin Li"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/JakabGBV20",
    "Title": "Self-Supervised Learning of Interpretable Keypoints From Unlabelled Videos.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00881",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Tomas Jakab",
      "Ankush Gupta 0001",
      "Hakan Bilen",
      "Andrea Vedaldi"
    ],
    "Type of Data": [
      "Images",
      "Video"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/JalwanaABM20",
    "Title": "Attack to Explain Deep Representation.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00956",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Mohammad A. A. K. Jalwana",
      "Naveed Akhtar",
      "Mohammed Bennamoun",
      "Ajmal Mian"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/KimGPS20",
    "Title": "A Programmatic and Semantic Approach to Explaining and Debugging Neural Network Based Object Detectors.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.01114",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Edward Kim",
      "Divya Gopinath",
      "Corina S. Pasareanu",
      "Sanjit A. Seshia"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Explanation",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/LiuLZKWBRC20",
    "Title": "Towards Visually Explaining Variational Autoencoders.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00867",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "WenQian Liu",
      "Runze Li",
      "Meng Zheng",
      "Srikrishna Karanam",
      "Ziyan Wu",
      "Bir Bhanu",
      "Richard J. Radke",
      "Octavia I. Camps"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ShenGTZ20",
    "Title": "Interpreting the Latent Space of GANs for Semantic Face Editing.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00926",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Yujun Shen",
      "Jinjin Gu",
      "Xiaoou Tang",
      "Bolei Zhou"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/WangV20",
    "Title": "SCOUT - Self-Aware Discriminant Counterfactual Explanations.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00900",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Pei Wang",
      "Nuno Vasconcelos"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/WuSCZKLT20a",
    "Title": "Towards Global Explanations of Convolutional Neural Networks With Concept Attribution.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00868",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Weibin Wu",
      "Yuxin Su",
      "Xixian Chen",
      "Shenglin Zhao",
      "Irwin King",
      "Michael R. Lyu",
      "Yu-Wing Tai"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/XuYGLWLV20",
    "Title": "Explainable Object-Induced Action Decision for Autonomous Vehicles.",
    "url": "https://doi.org/10.1109/CVPR42600.2020.00954",
    "Year": "2020",
    "Venue": "CVPR",
    "Authors": [
      "Yiran Xu",
      "Xiaoyin Yang",
      "Lihang Gong",
      "Hsuan-Chu Lin",
      "Tz-Ying Wu",
      "Yunsheng Li",
      "Nuno Vasconcelos"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/JiWJMZ20",
    "Title": "Interpretable Spatiotemporal Deep Learning Model for Traffic Flow Prediction based on Potential Energy Fields.",
    "url": "https://doi.org/10.1109/ICDM50108.2020.00128",
    "Year": "2020",
    "Venue": "ICDM",
    "Authors": [
      "Jiahao Ji",
      "Jingyuan Wang",
      "Zhe Jiang 0001",
      "Jingtian Ma",
      "Hu Zhang"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/JinWDXR20",
    "Title": "Towards Hierarchical Importance Attribution - Explaining Compositional Semantics for Neural Sequence Models.",
    "url": "https://openreview.net/forum?id=BkxRRkSKwr",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Xisen Jin",
      "Zhongyu Wei",
      "Junyi Du",
      "Xiangyang Xue",
      "Xiang Ren 0001"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/MohanKSF20",
    "Title": "Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks.",
    "url": "https://openreview.net/forum?id=HJlSmC4FPS",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Sreyas Mohan",
      "Zahra Kadkhodaie",
      "Eero P. Simoncelli",
      "Carlos Fernandez-Granda"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Representation Synthesis",
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/OreshkinCCB20",
    "Title": "N-BEATS - Neural basis expansion analysis for interpretable time series forecasting.",
    "url": "https://openreview.net/forum?id=r1ecqn4YwB",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Boris N. Oreshkin",
      "Dmitri Carpov",
      "Nicolas Chapados",
      "Yoshua Bengio"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/PuriVGKDK020",
    "Title": "Explain Your Move - Understanding Agent Actions Using Specific and Relevant Feature Attribution.",
    "url": "https://openreview.net/forum?id=SJgzLkBKPB",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Nikaash Puri",
      "Sukriti Verma",
      "Piyush Gupta",
      "Dhruv Kayastha",
      "Shripad Deshmukh",
      "Balaji Krishnamurthy",
      "Sameer Singh 0001"
    ],
    "Type of Data": [
      "Images",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/SinglaPCB20",
    "Title": "Explanation by Progressive Exaggeration.",
    "url": "https://openreview.net/forum?id=H1xFWgrFPS",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Sumedha Singla",
      "Brian Pollack",
      "Junxiang Chen",
      "Kayhan Batmanghelich"
    ],
    "Type of Data": [
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Representation Synthesis",
      "Representation Visualization",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/YangS20",
    "Title": "Learn to Explain Efficiently via Neural Logic Inductive Learning.",
    "url": "https://openreview.net/forum?id=SJlh8CEYDB",
    "Year": "2020",
    "Venue": "ICLR",
    "Authors": [
      "Yuan Yang",
      "Le Song"
    ],
    "Type of Data": [
      "Images",
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/AndersPDMK20",
    "Title": "Fairwashing explanations with off-manifold detergent.",
    "url": "http://proceedings.mlr.press/v119/anders20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Christopher J. Anders",
      "Plamen Pasliev",
      "Ann-Kathrin Dombrowski",
      "Klaus-Robert M\u00fcller",
      "Pan Kessel"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/ChalasaniC00J20",
    "Title": "Concise Explanations of Neural Networks using Adversarial Training.",
    "url": "http://proceedings.mlr.press/v119/chalasani20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Prasad Chalasani",
      "Jiefeng Chen",
      "Amrita Roy Chowdhury 0001",
      "Xi Wu 0001",
      "Somesh Jha"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/ChaudharySG20",
    "Title": "Explainable and Discourse Topic-aware Neural Language Understanding.",
    "url": "http://proceedings.mlr.press/v119/chaudhary20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Yatin Chaudhary",
      "Hinrich Sch\u00fctze",
      "Pankaj Gupta"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Retrieval"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/JinBJ20a",
    "Title": "Multi-Objective Molecule Generation using Interpretable Substructures.",
    "url": "http://proceedings.mlr.press/v119/jin20b.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Wengong Jin",
      "Regina Barzilay",
      "Tommi S. Jaakkola"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/LakkarajuAB20",
    "Title": "Robust and Stable Black Box Explanations.",
    "url": "http://proceedings.mlr.press/v119/lakkaraju20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Himabindu Lakkaraju",
      "Nino Arsov",
      "Osbert Bastani"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Support Vector Machine",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "White-box model"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/MoshkovitzDRF20",
    "Title": "Explainable k-Means and k-Medians Clustering.",
    "url": "http://proceedings.mlr.press/v119/moshkovitz20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Michal Moshkovitz",
      "Sanjoy Dasgupta",
      "Cyrus Rashtchian",
      "Nave Frost"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Clustering"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/ParkCZYY20",
    "Title": "Multiresolution Tensor Learning for Efficient and Interpretable Spatial Analysis.",
    "url": "http://proceedings.mlr.press/v119/park20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Jung Yeon Park",
      "Kenneth Theo Carr",
      "Stephan Zheng",
      "Yisong Yue",
      "Rose Yu"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/PlumbTST20",
    "Title": "Explaining Groups of Points in Low-Dimensional Representations.",
    "url": "http://proceedings.mlr.press/v119/plumb20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Gregory Plumb",
      "Jonathan Terhorst",
      "Sriram Sankararaman",
      "Ameet Talwalkar"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/QuinnNR0V20",
    "Title": "DeepCoDA - personalized interpretability for compositional health data.",
    "url": "http://proceedings.mlr.press/v119/quinn20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Thomas P. Quinn",
      "Dang Nguyen",
      "Santu Rana",
      "Sunil Gupta 0001",
      "Svetha Venkatesh"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/ShiZM020",
    "Title": "Dispersed Exponential Family Mixture VAEs for Interpretable Text Generation.",
    "url": "http://proceedings.mlr.press/v119/shi20f.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Wenxian Shi",
      "Hao Zhou",
      "Ning Miao",
      "Lei Li 0005"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/VoynovB20",
    "Title": "Unsupervised Discovery of Interpretable Directions in the GAN Latent Space.",
    "url": "http://proceedings.mlr.press/v119/voynov20a.html",
    "Year": "2020",
    "Venue": "ICML",
    "Authors": [
      "Andrey Voynov",
      "Artem Babenko"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/AlbiniRBT20",
    "Title": "Relation-Based Counterfactual Explanations for Bayesian Network Classifiers.",
    "url": "https://doi.org/10.24963/ijcai.2020/63",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Emanuele Albini",
      "Antonio Rago 0001",
      "Pietro Baroni",
      "Francesca Toni"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/BeyazitTYT020",
    "Title": "Learning Interpretable Representations with Informative Entanglements.",
    "url": "https://doi.org/10.24963/ijcai.2020/273",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Ege Beyazit",
      "Doruk Tuncel",
      "Xu Yuan",
      "Nian-Feng Tzeng",
      "Xindong Wu 0001"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Representation learning",
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/ChenW0PSAC20",
    "Title": "Towards Explainable Conversational Recommendation.",
    "url": "https://doi.org/10.24963/ijcai.2020/414",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Zhongxia Chen",
      "Xiting Wang",
      "Xing Xie 0001",
      "Mehul Parsana",
      "Akshay Soni",
      "Xiang Ao",
      "Enhong Chen"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/CiravegnaGGMM20",
    "Title": "Human-Driven FOL Explanations of Deep Learning.",
    "url": "https://doi.org/10.24963/ijcai.2020/309",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Gabriele Ciravegna",
      "Francesco Giannini",
      "Marco Gori",
      "Marco Maggini",
      "Stefano Melacci"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/KanamoriTKA20",
    "Title": "DACE - Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization.",
    "url": "https://doi.org/10.24963/ijcai.2020/395",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Kentaro Kanamori",
      "Takuya Takagi",
      "Ken Kobayashi",
      "Hiroki Arimura"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic",
      "Support Vector Machine",
      "Tree Ensemble"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/LeL20",
    "Title": "Synthesizing Aspect-Driven Recommendation Explanations from Reviews.",
    "url": "https://doi.org/10.24963/ijcai.2020/336",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Trung-Hoang Le",
      "Hady W. Lauw"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/LiFCLYS20",
    "Title": "Recurrent Dirichlet Belief Networks for interpretable Dynamic Relational Data Modelling.",
    "url": "https://doi.org/10.24963/ijcai.2020/342",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Yaqiong Li",
      "Xuhui Fan",
      "Ling Chen",
      "Bin Li",
      "Zheng Yu",
      "Scott A. Sisson"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/RosaCN20",
    "Title": "Explainable Inference on Sequential Data via Memory-Tracking.",
    "url": "https://doi.org/10.24963/ijcai.2020/278",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Biagio La Rosa",
      "Roberto Capobianco",
      "Daniele Nardi"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/WangZ20a",
    "Title": "Interpretable Multimodal Learning for Intelligent Regulation in Online Payment Systems.",
    "url": "https://doi.org/10.24963/ijcai.2020/645",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Shuoyao Wang",
      "Diwei Zhu"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Retrieval"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Feature plot"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/WuRYWN20",
    "Title": "Evidence-Aware Hierarchical Interactive Attention Networks for Explainable Claim Verification.",
    "url": "https://doi.org/10.24963/ijcai.2020/193",
    "Year": "2020",
    "Venue": "IJCAI",
    "Authors": [
      "Lianwei Wu",
      "Yuan Rao",
      "Xiong Yang",
      "Wanzhen Wang",
      "Ambreen Nazir"
    ],
    "Type of Data": [
      "Text",
      "Graph data",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/GuoZQWSY20",
    "Title": "Interpretable Deep Graph Generation with Node-edge Co-disentanglement.",
    "url": "https://doi.org/10.1145/3394486.3403221",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Xiaojie Guo",
      "Liang Zhao 0002",
      "Zhao Qin",
      "Lingfei Wu",
      "Amarda Shehu",
      "Yanfang Ye"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/LancianoBG20",
    "Title": "Explainable Classification of Brain Networks via Contrast Subgraphs.",
    "url": "https://doi.org/10.1145/3394486.3403383",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Tommaso Lanciano",
      "Francesco Bonchi",
      "Aristides Gionis"
    ],
    "Type of Data": [
      "Images",
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature plot",
      "Graph",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/LeW020",
    "Title": "GRACE - Generating Concise and Informative Contrastive Sample to Explain Neural Network Model's Prediction.",
    "url": "https://doi.org/10.1145/3394486.3403066",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Thai Le",
      "Suhang Wang",
      "Dongwon Lee 0001"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/LiangBCBW20",
    "Title": "Adversarial Infidelity Learning for Model Interpretation.",
    "url": "https://doi.org/10.1145/3394486.3403071",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Jian Liang",
      "Bing Bai",
      "Yuren Cao",
      "Kun Bai",
      "Fei Wang"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "Time series",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/TangLSSMW20",
    "Title": "Knowing your FATE - Friendship, Action and Temporal Explanations for User Engagement Prediction on Social Apps.",
    "url": "https://doi.org/10.1145/3394486.3403276",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Xianfeng Tang",
      "Yozen Liu",
      "Neil Shah",
      "Xiaolin Shi",
      "Prasenjit Mitra",
      "Suhang Wang"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/YuanTHJ20",
    "Title": "XGNN - Towards Model-Level Explanations of Graph Neural Networks.",
    "url": "https://doi.org/10.1145/3394486.3403085",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Hao Yuan",
      "Jiliang Tang",
      "Xia Hu",
      "Shuiwang Ji"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ZhangQ0LCZD20",
    "Title": "INPREM - An Interpretable and Trustworthy Predictive Model for Healthcare.",
    "url": "https://doi.org/10.1145/3394486.3403087",
    "Year": "2020",
    "Venue": "KDD",
    "Authors": [
      "Xianli Zhang",
      "Buyue Qian",
      "Shilei Cao 0001",
      "Yang Li",
      "Hang Chen",
      "Yefeng Zheng",
      "Ian Davidson"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/0001GCIN20",
    "Title": "Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/eccd2a86bae4728b38627162ba297828-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Jo\u00e3o Marques-Silva 0001",
      "Thomas Gerspacher",
      "Martin C. Cooper",
      "Alexey Ignatiev",
      "Nina Narodytska"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ArikLYSELM0ZNSN20",
    "Title": "Interpretable Sequence Learning for Covid-19 Forecasting.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/d9dbc51dc534921589adf460c85cd824-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Sercan \u00d6mer Arik",
      "Chun-Liang Li",
      "Jinsung Yoon",
      "Rajarishi Sinha",
      "Arkady Epshteyn",
      "Long T. Le",
      "Vikas Menon",
      "Shashank Singh 0005",
      "Leyou Zhang",
      "Martin Nikoltchev",
      "Yash Sonthalia",
      "Hootan Nakhost",
      "Elli Kanal",
      "Tomas Pfister"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/BassSSTSR20",
    "Title": "ICAM - Interpretable Classification via Disentangled Representations and Feature Attribution Mapping.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/56f9f88906aebf4ad985aaec7fa01313-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Cher Bass",
      "Mariana da Silva",
      "Carole H. Sudre",
      "Petru-Daniel Tudosiu",
      "Stephen M. Smith",
      "Emma C. Robinson"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/CrabbeZZS20",
    "Title": "Learning outside the Black-Box - The pursuit of interpretable models.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/ce758408f6ef98d7c7a7b786eca7b3a8-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Jonathan Crabb\u00e9",
      "Yao Zhang",
      "William R. Zame",
      "Mihaela van der Schaar"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Support Vector Machine",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/FryeRF20",
    "Title": "Asymmetric Shapley values - incorporating causal knowledge into model-agnostic explainability.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/0d770c496aa3da6d2c3f2bd19e7b9d6b-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Christopher Frye",
      "Colin Rowat",
      "Ilya Feige"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Time series",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/HarkonenHLP20",
    "Title": "GANSpace - Discovering Interpretable GAN Controls.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/6fe43269967adbb64ec6149852b5cc3e-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Erik H\u00e4rk\u00f6nen",
      "Aaron Hertzmann",
      "Jaakko Lehtinen",
      "Sylvain Paris"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/HeskesSBC20",
    "Title": "Causal Shapley Values - Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Tom Heskes",
      "Evi Sijben",
      "Ioan Gabriel Bucur",
      "Tom Claassen"
    ],
    "Type of Data": [
      "Time series",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/JainVMLTH20",
    "Title": "Interpretable multi-timescale models for predicting fMRI responses to continuous natural speech.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/9e9a30b74c49d07d8150c8c83b1ccf07-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Shailee Jain",
      "Vy A. Vo",
      "Shivangi Mahto",
      "Amanda LeBel",
      "Javier S. Turek",
      "Alexander Huth"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/LuoCXYZC020",
    "Title": "Parameterized Explainer for Graph Neural Network.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/e37b08dd3015330dcbb5d6663667b8b8-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Dongsheng Luo",
      "Wei Cheng 0002",
      "Dongkuan Xu",
      "Wenchao Yu",
      "Bo Zong",
      "Haifeng Chen",
      "Xiang Zhang 0001"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/MuA20",
    "Title": "Compositional Explanations of Neurons.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/c74956ffb38ba48ed6ce977af6727275-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Jesse Mu",
      "Jacob Andreas"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/OShaughnessyCCR20",
    "Title": "Generative causal explanations of black-box classifiers.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/3a93a609b97ec0ab0ff5539eb79ef33a-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "\"Matthew R. OShaughnessy\"",
      "Gregory Canal",
      "Marissa Connor",
      "Christopher Rozell",
      "Mark A. Davenport"
    ],
    "Type of Data": [
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Graph",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/PedapatiBSD20",
    "Title": "Learning Global Transparent Models consistent with Local Contrastive Explanations.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/24aef8cb3281a2422a59b51659f1ad2e-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Tejaswini Pedapati",
      "Avinash Balakrishnan",
      "Karthikeyan Shanmugam",
      "Amit Dhurandhar"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/RamamurthyVZD20",
    "Title": "Model Agnostic Multilevel Explanations.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/426f990b332ef8193a61cc90516c1245-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Karthikeyan Natesan Ramamurthy",
      "Bhanukiran Vinzamuri",
      "Yunfeng Zhang",
      "Amit Dhurandhar"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/RawalL20",
    "Title": "Beyond Individualized Recourse - Interpretable and Interactive Summaries of Actionable Recourses.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/8ee7730e97c67473a424ccfeff49ab20-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Kaivalya Rawal",
      "Himabindu Lakkaraju"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/TsangR020",
    "Title": "How does This Interaction Affect Me? Interpretable Attribution for Feature Interactions.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/443dec3062d0286986e21dc0631734c9-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Michael Tsang",
      "Sirisha Rambhatla",
      "Yan Liu 0002"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/TsengSK20",
    "Title": "Fourier-transform-based attribution priors improve the interpretability and stability of deep learning models for genomics.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/1487987e862c44b91a0296cf3866387e-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Alex Tseng",
      "Avanti Shrikumar",
      "Anshul Kundaje"
    ],
    "Type of Data": [
      "Any",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/Yau0H20",
    "Title": "What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/d5ab8dc7ef67ca92e41d730982c5c602-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Herman Yau",
      "Chris Russell 0001",
      "Simon Hadfield"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/YehKALPR20",
    "Title": "On Completeness-aware Concept-Based Explanations in Deep Neural Networks.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/ecb287ff763c169694f682af52c1f309-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Chih-Kuan Yeh",
      "Been Kim",
      "Sercan \u00d6mer Arik",
      "Chun-Liang Li",
      "Tomas Pfister",
      "Pradeep Ravikumar"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ZhouW20",
    "Title": "Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE.",
    "url": "https://proceedings.neurips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html",
    "Year": "2020",
    "Venue": "NeurIPS",
    "Authors": [
      "Ding Zhou",
      "Xue-Xin Wei"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Representation Visualization",
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/ChenYYH0020",
    "Title": "Try This Instead - Personalized and Interpretable Substitute Recommendation.",
    "url": "https://doi.org/10.1145/3397271.3401042",
    "Year": "2020",
    "Venue": "SIGIR",
    "Authors": [
      "Tong Chen 0005",
      "Hongzhi Yin",
      "Guanhua Ye",
      "Zi Huang",
      "Yang Wang 0023",
      "Meng Wang 0001"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/QuAW20",
    "Title": "Towards Explainable Retrieval Models for Precision Medicine Literature Search.",
    "url": "https://doi.org/10.1145/3397271.3401277",
    "Year": "2020",
    "Venue": "SIGIR",
    "Authors": [
      "Jiaming Qu",
      "Jaime Arguello",
      "Yue Wang 0035"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Retrieval"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/YangZWL020",
    "Title": "Neural Concept Map Generation for Effective Document Classification with Interpretable Structured Summarization.",
    "url": "https://doi.org/10.1145/3397271.3401312",
    "Year": "2020",
    "Venue": "SIGIR",
    "Authors": [
      "Carl Yang",
      "Jieyu Zhang",
      "Haonan Wang",
      "Bangzheng Li",
      "Jiawei Han 0001"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/LiJC0WL20",
    "Title": "Directional and Explainable Serendipity Recommendation.",
    "url": "https://doi.org/10.1145/3366423.3380100",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Xueqi Li",
      "Wenjun Jiang",
      "Weiguang Chen",
      "Jie Wu 0001",
      "Guojun Wang 0001",
      "Kenli Li 0001"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/MathewSLS20",
    "Title": "The POLAR Framework - Polar Opposites Enable Interpretability of Pre-Trained Word Embeddings.",
    "url": "https://doi.org/10.1145/3366423.3380227",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Binny Mathew",
      "Sandipan Sikdar",
      "Florian Lemmerich",
      "Markus Strohmaier"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/NaumzikZF20",
    "Title": "Mining Points-of-Interest for Explaining Urban Phenomena - A Scalable Variational Inference Approach.",
    "url": "https://doi.org/10.1145/3366423.3380298",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Christof Naumzik",
      "Patrick Zoechbauer",
      "Stefan Feuerriegel"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Feature plot",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/PawelczykBK20",
    "Title": "Learning Model-Agnostic Counterfactual Explanations for Tabular Data.",
    "url": "https://doi.org/10.1145/3366423.3380087",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Martin Pawelczyk",
      "Klaus Broelemann",
      "Gjergji Kasneci"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/SunWZFHW20",
    "Title": "Dual Learning for Explainable Recommendation - Towards Unifying User Preference Prediction and Review Generation.",
    "url": "https://doi.org/10.1145/3366423.3380164",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Peijie Sun",
      "Le Wu",
      "Kun Zhang",
      "Yanjie Fu",
      "Richang Hong",
      "Meng Wang 0001"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/WangZZSP20",
    "Title": "DyCRS - Dynamic Interpretable Postoperative Complication Risk Scoring.",
    "url": "https://doi.org/10.1145/3366423.3380253",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Wen Wang",
      "Han Zhao 0002",
      "Honglei Zhuang",
      "Nirav Shah",
      "Rema Padman"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Time series"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/ZhuXSZCGH20",
    "Title": "Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection.",
    "url": "https://doi.org/10.1145/3366423.3380172",
    "Year": "2020",
    "Venue": "WWW",
    "Authors": [
      "Yongchun Zhu",
      "Dongbo Xi",
      "Bowen Song",
      "Fuzhen Zhuang",
      "Shuai Chen",
      "Xi Gu",
      "Qing He 0003"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/AnnasamyS19",
    "Title": "Towards Better Interpretability in Deep Q-Networks.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33014561",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Raghuram Mandyam Annasamy",
      "Katia P. Sycara"
    ],
    "Type of Data": [
      "Images",
      "Other"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Heatmap",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ChenZQ19",
    "Title": "Dynamic Explainable Recommendation Based on Neural Attentive Models.",
    "url": "https://doi.org/10.1609/aaai.v33i01.330153",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Xu Chen 0017",
      "Yongfeng Zhang",
      "Zheng Qin"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/GaoWW019",
    "Title": "Explainable Recommendation through Attentive Multi-View Learning.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33013622",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Jingyue Gao",
      "Xiting Wang",
      "Yasha Wang",
      "Xing Xie 0001"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/HeLSB19",
    "Title": "Interpretable Predictive Modeling for Climate Variables with Weighted Lasso.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33011385",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Sijie He",
      "Xinyan Li",
      "Vidyashankar Sivakumar",
      "Arindam Banerjee 0001"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/IgnatievNM19",
    "Title": "Abduction-Based Explanations for Machine Learning Models.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33011511",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Alexey Ignatiev",
      "Nina Narodytska",
      "Jo\u00e3o Marques-Silva 0001"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/LanG19",
    "Title": "Accurate and Interpretable Factorization Machines.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33014139",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Liang Lan",
      "Yu Geng 0002"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/LyuYLG19",
    "Title": "SDRL - Interpretable and Data-Efficient Deep Reinforcement Learning Leveraging Symbolic Planning.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33012970",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Daoming Lyu",
      "Fangkai Yang",
      "Bo Liu",
      "Steven Gustafson"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/PolatoA19",
    "Title": "Interpretable Preference Learning - A Game Theoretic Framework for Large Margin On-Line Feature and Rule Learning.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33014723",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Mirko Polato",
      "Fabio Aiolli"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ShakerinG19",
    "Title": "Induction of Non-Monotonic Logic Programs to Explain Boosted Tree Models Using LIME.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33013052",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Farhad Shakerin",
      "Gopal Gupta"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/SilvaFH19",
    "Title": "Exploring Knowledge Graphs in an Interpretable Composite Approach for Text Entailment.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33017023",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Vivian Dos Santos Silva",
      "Andr\u00e9 Freitas",
      "Siegfried Handschuh"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/TopinV19",
    "Title": "Generation of Policy-Level Explanations for Reinforcement Learning.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33012514",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Nicholay Topin",
      "Manuela Veloso"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Graph",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/WangWX00C19",
    "Title": "Explainable Reasoning over Knowledge Graphs for Recommendation.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33015329",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Xiang Wang 0010",
      "Dingxian Wang",
      "Canran Xu",
      "Xiangnan He 0001",
      "Yixin Cao 0002",
      "Tat-Seng Chua"
    ],
    "Type of Data": [
      "Graph data",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Graph",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/WickramanayakeH19",
    "Title": "FLEX - Faithful Linguistic Explanations for Neural Net Based Model Decisions.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33012539",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Sandareka Wickramanayake",
      "Wynne Hsu",
      "Mong-Li Lee"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/YuanCHJ19",
    "Title": "Interpreting Deep Models for Text Analysis via Optimization and Regularization Methods.",
    "url": "https://doi.org/10.1609/aaai.v33i01.33015717",
    "Year": "2019",
    "Venue": "AAAI",
    "Authors": [
      "Hao Yuan",
      "Yongjun Chen",
      "Xia Hu",
      "Shuiwang Ji"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/BastingsAT19",
    "Title": "Interpretable Neural Predictions with Differentiable Binary Variables.",
    "url": "https://doi.org/10.18653/v1/p19-1284",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Jasmijn Bastings",
      "Wilker Aziz",
      "Ivan Titov"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation",
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Localization",
      "Text",
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/JiangJCB19",
    "Title": "Explore, Propose, and Assemble - An Interpretable Model for Multi-Hop Reading Comprehension.",
    "url": "https://doi.org/10.18653/v1/p19-1261",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Yichen Jiang",
      "Nitish Joshi",
      "Yen-Chun Chen 0001",
      "Mohit Bansal"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/LuZXLZX19",
    "Title": "Constructing Interpretive Spatio-Temporal Features for Multi-Turn Responses Selection.",
    "url": "https://doi.org/10.18653/v1/p19-1006",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Junyu Lu",
      "Chenbin Zhang",
      "Zeying Xie",
      "Guang Ling",
      "Tom Chao Zhou",
      "Zenglin Xu"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/MoonSKS19",
    "Title": "OpenDialKG - Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs.",
    "url": "https://doi.org/10.18653/v1/p19-1081",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Seungwhan Moon",
      "Pararth Shah",
      "Anuj Kumar",
      "Rajen Subba"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/PanigrahiSB19",
    "Title": "Word2Sense - Sparse Interpretable Word Embeddings.",
    "url": "https://doi.org/10.18653/v1/p19-1570",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Abhishek Panigrahi",
      "Harsha Vardhan Simhadri",
      "Chiranjib Bhattacharyya"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble",
      "Support Vector Machine",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification",
      "Representation learning",
      "Other"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/RajaniMXS19",
    "Title": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning.",
    "url": "https://doi.org/10.18653/v1/p19-1487",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Nazneen Fatema Rajani",
      "Bryan McCann",
      "Caiming Xiong",
      "Richard Socher"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/SydorovaPR19",
    "Title": "Interpretable Question Answering on Knowledge Bases and Text.",
    "url": "https://doi.org/10.18653/v1/p19-1488",
    "Year": "2019",
    "Venue": "ACL",
    "Authors": [
      "Alona Sydorova",
      "Nina P\u00f6rner",
      "Benjamin Roth 0001"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/FukuiHYF19",
    "Title": "Attention Branch Network - Learning of Attention Mechanism for Visual Explanation.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fukui_Attention_Branch_Network_Learning_of_Attention_Mechanism_for_Visual_Explanation_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Hiroshi Fukui",
      "Tsubasa Hirakawa",
      "Takayoshi Yamashita",
      "Hironobu Fujiyoshi"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/KanehiraH19",
    "Title": "Learning to Explain With Complemental Examples.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Learning_to_Explain_With_Complemental_Examples_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Atsushi Kanehira",
      "Tatsuya Harada"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/KanehiraTIH19",
    "Title": "Multimodal Explanations by Predicting Counterfactuality in Videos.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Multimodal_Explanations_by_Predicting_Counterfactuality_in_Videos_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Atsushi Kanehira",
      "Kentaro Takemoto",
      "Sho Inayoshi",
      "Tatsuya Harada"
    ],
    "Type of Data": [
      "Video"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/PopeKRMH19",
    "Title": "Explainability Methods for Graph Convolutional Neural Networks.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Phillip E. Pope",
      "Soheil Kolouri",
      "Mohammad Rostami",
      "Charles E. Martin",
      "Heiko Hoffmann"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ShiZL19",
    "Title": "Explainable and Explicit Visual Reasoning Over Scene Graphs.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Explainable_and_Explicit_Visual_Reasoning_Over_Scene_Graphs_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Jiaxin Shi",
      "Hanwang Zhang",
      "Juanzi Li"
    ],
    "Type of Data": [
      "Images",
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ZengLSSYCU19",
    "Title": "End-To-End Interpretable Neural Motion Planner.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_End-To-End_Interpretable_Neural_Motion_Planner_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Wenyuan Zeng",
      "Wenjie Luo",
      "Simon Suo",
      "Abbas Sadat",
      "Bin Yang 0021",
      "Sergio Casas 0002",
      "Raquel Urtasun"
    ],
    "Type of Data": [
      "Time series",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ZhangYMW19",
    "Title": "Interpreting CNNs via Decision Trees.",
    "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.html",
    "Year": "2019",
    "Venue": "CVPR",
    "Authors": [
      "Quanshi Zhang",
      "Yu Yang",
      "Haotian Ma",
      "Ying Nian Wu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Tree",
      "Heatmap",
      "Prototypes",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/ChenCHRZ19",
    "Title": "Explaining Neural Networks Semantically and Quantitatively.",
    "url": "https://doi.org/10.1109/ICCV.2019.00928",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Runjin Chen",
      "Hao Chen",
      "Ge Huang",
      "Jie Ren",
      "Quanshi Zhang"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/ManhardtA0BBNT19",
    "Title": "Explaining the Ambiguity of Object Detection and 6D Pose From Visual Data.",
    "url": "https://doi.org/10.1109/ICCV.2019.00694",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Fabian Manhardt",
      "Diego Mart\u00edn Arroyo",
      "Christian Rupprecht 0001",
      "Benjamin Busam",
      "Tolga Birdal",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/MicheliniLLJ19",
    "Title": "A Tour of Convolutional Networks Guided by Linear Interpreters.",
    "url": "https://doi.org/10.1109/ICCV.2019.00485",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Pablo Navarrete Michelini",
      "Hanwen Liu",
      "Yunhua Lu",
      "Xingqun Jiang"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Generation"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/PatroLPN19",
    "Title": "U-CAM - Visual Explanation Using Uncertainty Based Class Activation Maps.",
    "url": "https://doi.org/10.1109/ICCV.2019.00754",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Badri N. Patro",
      "Mayank Lunayach",
      "Shivansh Patel",
      "Vinay Namboodiri"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Question Answering"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/SelvarajuLSJGHB19",
    "Title": "Taking a HINT - Leveraging Explanations to Make Vision and Language Models More Grounded.",
    "url": "https://doi.org/10.1109/ICCV.2019.00268",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Ramprasaath Ramasamy Selvaraju",
      "Stefan Lee",
      "Yilin Shen",
      "Hongxia Jin",
      "Shalini Ghosh",
      "Larry P. Heck",
      "Dhruv Batra",
      "Devi Parikh"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering",
      "Generation"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/SubramanyaPP19",
    "Title": "Fooling Network Interpretation in Image Classification.",
    "url": "https://doi.org/10.1109/ICCV.2019.00211",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Akshayvarun Subramanya",
      "Vipin Pillai",
      "Hamed Pirsiavash"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/SunRS19",
    "Title": "Adaptive Activation Thresholding - Dynamic Routing Type Behavior for Interpretability in Convolutional Neural Networks.",
    "url": "https://doi.org/10.1109/ICCV.2019.00504",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Yiyou Sun",
      "Sathya N. Ravi",
      "Vikas Singh"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/WuS19",
    "Title": "Towards Interpretable Object Detection by Unfolding Latent Structures.",
    "url": "https://doi.org/10.1109/ICCV.2019.00613",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Tianfu Wu 0001",
      "Xi Song"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/YinTLS019",
    "Title": "Towards Interpretable Face Recognition.",
    "url": "https://doi.org/10.1109/ICCV.2019.00944",
    "Year": "2019",
    "Venue": "ICCV",
    "Authors": [
      "Bangjie Yin",
      "Luan Tran",
      "Haoxiang Li",
      "Xiaohui Shen",
      "Xiaoming Liu 0002"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/AssafGBS19",
    "Title": "MTEX-CNN - Multivariate Time Series EXplanations for Predictions with Convolutional Neural Networks.",
    "url": "https://doi.org/10.1109/ICDM.2019.00106",
    "Year": "2019",
    "Venue": "ICDM",
    "Authors": [
      "Roy Assaf",
      "Ioana Giurgiu",
      "Frank Bagehorn",
      "Anika Schumann"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/ChenL0X19",
    "Title": "Scalable Explanation of Inferences on Large Graphs.",
    "url": "https://doi.org/10.1109/ICDM.2019.00111",
    "Year": "2019",
    "Venue": "ICDM",
    "Authors": [
      "Chao Chen",
      "Yifei Liu",
      "Xi Zhang 0008",
      "Sihong Xie"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/HamdiA19",
    "Title": "Interpretable Feature Learning of Graphs using Tensor Decomposition.",
    "url": "https://doi.org/10.1109/ICDM.2019.00037",
    "Year": "2019",
    "Venue": "ICDM",
    "Authors": [
      "Shah Muhammad Hamdi",
      "Rafal A. Angryk"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/YooS19",
    "Title": "EDiT - Interpreting Ensemble Models via Compact Soft Decision Trees.",
    "url": "https://doi.org/10.1109/ICDM.2019.00187",
    "Year": "2019",
    "Venue": "ICDM",
    "Authors": [
      "Jaemin Yoo",
      "Lee Sael"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/ZhangQLYWZ19",
    "Title": "KnowRisk - An Interpretable Knowledge-Guided Model for Disease Risk Prediction.",
    "url": "https://doi.org/10.1109/ICDM.2019.00196",
    "Year": "2019",
    "Venue": "ICDM",
    "Authors": [
      "Xianli Zhang",
      "Buyue Qian",
      "Yang Li",
      "Changchang Yin",
      "Xudong Wang",
      "Qinghua Zheng"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/ZhouSC19",
    "Title": "A Model-Agnostic Approach for Explaining the Predictions on Clustered Data.",
    "url": "https://doi.org/10.1109/ICDM.2019.00202",
    "Year": "2019",
    "Venue": "ICDM",
    "Authors": [
      "Zihan Zhou 0003",
      "Mingxuan Sun",
      "Jianhua Chen 0003"
    ],
    "Type of Data": [
      "User-item matrix",
      "Other"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic",
      "Other"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/ChangCGD19",
    "Title": "Explaining Image Classifiers by Counterfactual Generation.",
    "url": "https://openreview.net/forum?id=B1MXz20cYQ",
    "Year": "2019",
    "Venue": "ICLR",
    "Authors": [
      "Chun-Hao Chang",
      "Elliot Creager",
      "Anna Goldenberg",
      "David Duvenaud"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/ChenSWJ19",
    "Title": "L-Shapley and C-Shapley - Efficient Model Interpretation for Structured Data.",
    "url": "https://openreview.net/forum?id=S1E3Ko09F7",
    "Year": "2019",
    "Venue": "ICLR",
    "Authors": [
      "Jianbo Chen",
      "Le Song",
      "Martin J. Wainwright",
      "Michael I. Jordan"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/FortuinHLSR19",
    "Title": "SOM-VAE - Interpretable Discrete Representation Learning on Time Series.",
    "url": "https://openreview.net/forum?id=rygjcsR9Y7",
    "Year": "2019",
    "Venue": "ICLR",
    "Authors": [
      "Vincent Fortuin",
      "Matthias H\u00fcser",
      "Francesco Locatello",
      "Heiko Strathmann",
      "Gunnar R\u00e4tsch"
    ],
    "Type of Data": [
      "Images",
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Representation learning",
      "Clustering"
    ],
    "Type of Explanation": [
      "Representation Visualization",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/SinghMY19",
    "Title": "Hierarchical interpretations for neural network predictions.",
    "url": "https://openreview.net/forum?id=SkEqro0ctQ",
    "Year": "2019",
    "Venue": "ICLR",
    "Authors": [
      "Chandan Singh",
      "W. James Murdoch",
      "Bin Yu"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/ZhengPBH19",
    "Title": "Revealing interpretable object representations from human behavior.",
    "url": "https://openreview.net/forum?id=ryxSrhC9KX",
    "Year": "2019",
    "Venue": "ICLR",
    "Authors": [
      "Charles Y. Zheng",
      "Francisco Pereira",
      "Chris I. Baker",
      "Martin N. Hebart"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/0002LA19",
    "Title": "Exploring interpretable LSTM neural networks over multi-variable data.",
    "url": "http://proceedings.mlr.press/v97/guo19b.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Tian Guo 0002",
      "Tao Lin",
      "Nino Antulov-Fantulin"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/AnconaOG19",
    "Title": "Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Value Approximation.",
    "url": "http://proceedings.mlr.press/v97/ancona19a.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Marco Ancona",
      "Cengiz \u00d6ztireli",
      "Markus H. Gross"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/DunckerBBS19",
    "Title": "Learning interpretable continuous-time models of latent stochastic dynamical systems.",
    "url": "http://proceedings.mlr.press/v97/duncker19a.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Lea Duncker",
      "Gergo Bohner",
      "Julien Boussard",
      "Maneesh Sahani"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Representation Visualization",
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/GoyalWEBPL19",
    "Title": "Counterfactual Visual Explanations.",
    "url": "http://proceedings.mlr.press/v97/goyal19a.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Yash Goyal",
      "Ziyan Wu",
      "Jan Ernst",
      "Dhruv Batra",
      "Devi Parikh",
      "Stefan Lee"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Prototypes",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/SinglaWFF19",
    "Title": "Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation.",
    "url": "http://proceedings.mlr.press/v97/singla19a.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Sahil Singla 0002",
      "Eric Wallace",
      "Shi Feng",
      "Soheil Feizi"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/VedantamDLRBP19",
    "Title": "Probabilistic Neural Symbolic Models for Interpretable Visual Question Answering.",
    "url": "http://proceedings.mlr.press/v97/vedantam19a.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Ramakrishna Vedantam",
      "Karan Desai",
      "Stefan Lee",
      "Marcus Rohrbach",
      "Dhruv Batra",
      "Devi Parikh"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model",
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/WangZB19",
    "Title": "Bias Also Matters - Bias Attribution for Deep Neural Network Explanation.",
    "url": "http://proceedings.mlr.press/v97/wang19p.html",
    "Year": "2019",
    "Venue": "ICML",
    "Authors": [
      "Shengjie Wang",
      "Tianyi Zhou",
      "Jeff A. Bilmes"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/ChenW0WBWC19",
    "Title": "Co-Attentive Multi-Task Learning for Explainable Recommendation.",
    "url": "https://doi.org/10.24963/ijcai.2019/296",
    "Year": "2019",
    "Venue": "IJCAI",
    "Authors": [
      "Zhongxia Chen",
      "Xiting Wang",
      "Xing Xie 0001",
      "Tong Wu",
      "Guoqing Bu",
      "Yining Wang",
      "Enhong Chen"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/FuscoVVWS19",
    "Title": "RecoNet - An Interpretable Neural Architecture for Recommender Systems.",
    "url": "https://doi.org/10.24963/ijcai.2019/325",
    "Year": "2019",
    "Venue": "IJCAI",
    "Authors": [
      "Francesco Fusco",
      "Michalis Vlachos",
      "Vasileios Vasileiadis",
      "Kathrin Wardatzky",
      "Johannes Schneider"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/HouWCLZL19",
    "Title": "Explainable Fashion Recommendation - A Semantic Attribute Region Guided Approach.",
    "url": "https://doi.org/10.24963/ijcai.2019/650",
    "Year": "2019",
    "Venue": "IJCAI",
    "Authors": [
      "Min Hou",
      "Le Wu",
      "Enhong Chen",
      "Zhi Li",
      "Vincent W. Zheng",
      "Qi Liu 0003"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap",
      "Localization",
      "Prototypes",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/KennyK19",
    "Title": "Twin-Systems to Explain Artificial Neural Networks using Case-Based Reasoning - Comparative Tests of Feature-Weighting Methods in ANN-CBR Twins for XAI.",
    "url": "https://doi.org/10.24963/ijcai.2019/376",
    "Year": "2019",
    "Venue": "IJCAI",
    "Authors": [
      "Eoin M. Kenny",
      "Mark T. Keane"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Model Explanation",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/LiYYJ19",
    "Title": "Learning Interpretable Deep State Space Model for Probabilistic Time Series Forecasting.",
    "url": "https://doi.org/10.24963/ijcai.2019/402",
    "Year": "2019",
    "Venue": "IJCAI",
    "Authors": [
      "Longyuan Li",
      "Junchi Yan",
      "Xiaokang Yang",
      "Yaohui Jin"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/ZhangR19",
    "Title": "Learning Interpretable Relational Structures of Hinge-loss Markov Random Fields.",
    "url": "https://doi.org/10.24963/ijcai.2019/838",
    "Year": "2019",
    "Venue": "IJCAI",
    "Authors": [
      "Yue Zhang",
      "Arti Ramesh"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning",
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ChengSHZ19",
    "Title": "Incorporating Interpretability into Latent Factor Models via Fast Influence Analysis.",
    "url": "https://doi.org/10.1145/3292500.3330857",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Weiyu Cheng",
      "Yanyan Shen",
      "Linpeng Huang",
      "Yanmin Zhu"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/Jia0RLH19",
    "Title": "Improving the Quality of Explanations with Local Embedding Perturbations.",
    "url": "https://doi.org/10.1145/3292500.3330930",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Yunzhe Jia",
      "James Bailey 0001",
      "Kotagiri Ramamohanarao",
      "Christopher Leckie",
      "Michael E. Houle"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/MingXQR19",
    "Title": "Interpretable and Steerable Sequence Learning via Prototypes.",
    "url": "https://doi.org/10.1145/3292500.3330908",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Yao Ming",
      "Panpan Xu",
      "Huamin Qu",
      "Liu Ren"
    ],
    "Type of Data": [
      "Text",
      "Time series",
      "Other"
    ],
    "Type of Problem": [
      "Outcome Explanation",
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ShuCW0L19",
    "Title": "dEFEND - Explainable Fake News Detection.",
    "url": "https://doi.org/10.1145/3292500.3330935",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Kai Shu",
      "Limeng Cui",
      "Suhang Wang",
      "Dongwon Lee 0001",
      "Huan Liu 0001"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/Tao0WFYZ019",
    "Title": "Log2Intent - Towards Interpretable User Modeling via Recurrent Semantics Memory Unit.",
    "url": "https://doi.org/10.1145/3292500.3330889",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Zhiqiang Tao",
      "Sheng Li 0001",
      "Zhaowen Wang",
      "Chen Fang",
      "Longqi Yang",
      "Handong Zhao",
      "Yun Fu 0001"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model",
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/YanZDSSK19",
    "Title": "GroupINN - Grouping-based Interpretable Neural Network for Classification of Limited, Noisy Brain Data.",
    "url": "https://doi.org/10.1145/3292500.3330921",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Yujun Yan",
      "Jiong Zhu",
      "Marlena Duda",
      "Eric Solarz",
      "Chandra Sekhar Sripada",
      "Danai Koutra"
    ],
    "Type of Data": [
      "Images",
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/YoshidaTK19",
    "Title": "Learning Interpretable Metric between Graphs - Convex Formulation and Computation with Graph Mining.",
    "url": "https://doi.org/10.1145/3292500.3330845",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Tomoki Yoshida",
      "Ichiro Takeuchi",
      "Masayuki Karasuyama"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization",
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ZhangTKLCC19",
    "Title": "Axiomatic Interpretability for Multiclass Additive Models.",
    "url": "https://doi.org/10.1145/3292500.3330898",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Xuezhou Zhang",
      "Sarah Tan",
      "Paul Koch",
      "Yin Lou",
      "Urszula Chajewska",
      "Rich Caruana"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature plot"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ZhaoGS19",
    "Title": "Riker - Mining Rich Keyword Representations for Interpretable Product Question Answering.",
    "url": "https://doi.org/10.1145/3292500.3330985",
    "Year": "2019",
    "Venue": "KDD",
    "Authors": [
      "Jie Zhao",
      "Ziyu Guan",
      "Huan Sun"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ChenLTBRS19",
    "Title": "This Looks Like That - Deep Learning for Interpretable Image Recognition.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/adf7ee2dcf142b0e11888e72b43fcb75-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Chaofan Chen",
      "Oscar Li",
      "Daniel Tao",
      "Alina Barnett",
      "Cynthia Rudin",
      "Jonathan Su"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/GhorbaniWZK19",
    "Title": "Towards Automatic Concept-based Explanations.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Amirata Ghorbani",
      "James Wexler",
      "James Y. Zou",
      "Been Kim"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes",
      "Localization",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/HoyerMKKF19",
    "Title": "Grid Saliency for Context Explanations of Semantic Segmentation.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/6950aa02ae8613af620668146dd11840-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Lukas Hoyer",
      "Mauricio Munoz",
      "Prateek Katiyar",
      "Anna Khoreva",
      "Volker Fischer 0003"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/KimL19",
    "Title": "Learning Dynamics of Attention - Human Prior for Interpretable Machine Reasoning.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/ae3539867aaeec609a4260c6feb725f4-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Wonjae Kim",
      "Yoonho Lee"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/WangN19",
    "Title": "Deliberative Explanations - visualizing network insecurities.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/68053af2923e00204c3ca7c6a3150cf7-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Pei Wang",
      "Nuno Vasconcelos"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/YingBYZL19",
    "Title": "GNNExplainer - Generating Explanations for Graph Neural Networks.",
    "url": "https://proceedings.neurips.cc/paper/2019/hash/d80b7040b773199015de6d3b4293c8ff-Abstract.html",
    "Year": "2019",
    "Venue": "NeurIPS",
    "Authors": [
      "Zhitao Ying",
      "Dylan Bourgeois",
      "Jiaxuan You",
      "Marinka Zitnik",
      "Jure Leskovec"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Graph"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/BalogRA19",
    "Title": "Transparent, Scrutable and Explainable User Models for Personalized Recommendation.",
    "url": "https://doi.org/10.1145/3331184.3331211",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Krisztian Balog",
      "Filip Radlinski",
      "Shushan Arakelyan"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/HanSYWN19",
    "Title": "Prototype-guided Attribute-wise Interpretable Scheme for Clothing Matching.",
    "url": "https://doi.org/10.1145/3331184.3331245",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Xianjing Han",
      "Xuemeng Song",
      "Jianhua Yin",
      "Yinglong Wang 0001",
      "Liqiang Nie"
    ],
    "Type of Data": [
      "Images",
      "Text",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/LiQPQDW19",
    "Title": "A Capsule Network for Recommendation and Explaining What You Like and Dislike.",
    "url": "https://doi.org/10.1145/3331184.3331216",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Chenliang Li",
      "Cong Quan",
      "Li Peng",
      "Yunwei Qi",
      "Yuming Deng",
      "Libing Wu"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/TaoJWW19",
    "Title": "The FacT - Taming Latent Factor Models for Explainability with Factorization Trees.",
    "url": "https://doi.org/10.1145/3331184.3331244",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Yiyi Tao",
      "Yiling Jia",
      "Nan Wang",
      "Hongning Wang"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Decision Tree",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/XianFMMZ19",
    "Title": "Reinforcement Knowledge Graph Reasoning for Explainable Recommendation.",
    "url": "https://doi.org/10.1145/3331184.3331203",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Yikun Xian",
      "Zuohui Fu",
      "S. Muthukrishnan",
      "Gerard de Melo",
      "Yongfeng Zhang"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning",
      "Recommendation"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/Yang0WMF0C19",
    "Title": "Interpretable Fashion Matching with Rich Attributes.",
    "url": "https://doi.org/10.1145/3331184.3331242",
    "Year": "2019",
    "Venue": "SIGIR",
    "Authors": [
      "Xun Yang",
      "Xiangnan He 0001",
      "Xiang Wang 0010",
      "Yunshan Ma",
      "Fuli Feng",
      "Meng Wang 0001",
      "Tat-Seng Chua"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Decision Tree",
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/MaZCJWLMR19",
    "Title": "Jointly Learning Explainable Rules for Recommendation with Knowledge Graph.",
    "url": "https://doi.org/10.1145/3308558.3313607",
    "Year": "2019",
    "Venue": "WWW",
    "Authors": [
      "Weizhi Ma",
      "Min Zhang 0006",
      "Yue Cao",
      "Woojeong Jin",
      "Chenyang Wang",
      "Yiqun Liu 0001",
      "Shaoping Ma",
      "Xiang Ren 0001"
    ],
    "Type of Data": [
      "Graph data",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/BiskSCM18",
    "Title": "Learning Interpretable Spatial Operations in a Rich 3D Blocks World.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17410",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Yonatan Bisk",
      "Kevin J. Shih",
      "Yejin Choi",
      "Daniel Marcu"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/HsuM0S18",
    "Title": "An Interpretable Generative Adversarial Approach to Classification of Latent Entity Relations in Unstructured Sentences.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16629",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Shiou Tian Hsu",
      "Changsung Moon",
      "Paul Jones 0001",
      "Nagiza F. Samatova"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/LiLCR18",
    "Title": "Deep Learning for Case-Based Reasoning Through Prototypes - A Neural Network That Explains Its Predictions.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17082",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Oscar Li",
      "Hao Liu 0015",
      "Chaofan Chen",
      "Cynthia Rudin"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/NguyenKLW18",
    "Title": "An Interpretable Joint Graphical Model for Fact-Checking From Crowds.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16673",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "An T. Nguyen 0001",
      "Aditya Kharosekar",
      "Matthew Lease",
      "Byron C. Wallace"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/PalangiSHD18",
    "Title": "Question-Answering with Grammatically-Interpretable Representations.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17090",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Hamid Palangi",
      "Paul Smolensky",
      "Xiaodong He 0001",
      "Li Deng 0001"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Question Answering"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/Ribeiro0G18",
    "Title": "Anchors - High-Precision Model-Agnostic Explanations.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16982",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Marco T\u00falio Ribeiro",
      "Sameer Singh 0001",
      "Carlos Guestrin"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification",
      "Question Answering"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/RossD18",
    "Title": "Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17337",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Andrew Slavin Ross",
      "Finale Doshi-Velez"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/RustamovK18",
    "Title": "Interpretable Graph-Based Semi-Supervised Learning via Flows.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16396",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Raif M. Rustamov",
      "James T. Klosowski"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/SubramanianPJBH18",
    "Title": "SPINE - SParse Interpretable Neural Embeddings.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17433",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Anant Subramanian",
      "Danish Pruthi",
      "Harsh Jhamtani",
      "Taylor Berg-Kirkpatrick",
      "Eduard H. Hovy"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Support Vector Machine",
      "Logistic Regression",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Regression",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/WuHPZ0D18",
    "Title": "Beyond Sparsity - Tree Regularization of Deep Models for Interpretability.",
    "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16285",
    "Year": "2018",
    "Venue": "AAAI",
    "Authors": [
      "Mike Wu",
      "Michael C. Hughes",
      "Sonali Parbhoo",
      "Maurizio Zazzi",
      "Volker Roth 0001",
      "Finale Doshi-Velez"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Time series"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Tree"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/EskenaziLZ18",
    "Title": "Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation.",
    "url": "https://www.aclweb.org/anthology/P18-1101/",
    "Year": "2018",
    "Venue": "ACL",
    "Authors": [
      "Tiancheng Zhao",
      "Kyusong Lee",
      "Maxine Esk\u00e9nazi"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/InuiTT18",
    "Title": "Interpretable and Compositional Relation Learning by Joint Training with an Autoencoder.",
    "url": "https://www.aclweb.org/anthology/P18-1200/",
    "Year": "2018",
    "Venue": "ACL",
    "Authors": [
      "Ryo Takahashi",
      "Ran Tian",
      "Kentaro Inui"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Representation learning",
      "Other"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/MorencyCPLZ18",
    "Title": "Multimodal Language Analysis in the Wild - CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph.",
    "url": "https://www.aclweb.org/anthology/P18-1208/",
    "Year": "2018",
    "Venue": "ACL",
    "Authors": [
      "Amir Zadeh 0001",
      "Paul Pu Liang",
      "Soujanya Poria",
      "Erik Cambria",
      "Louis-Philippe Morency"
    ],
    "Type of Data": [
      "Text",
      "Video",
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/SchutzeRP18",
    "Title": "Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement.",
    "url": "https://www.aclweb.org/anthology/P18-1032/",
    "Year": "2018",
    "Venue": "ACL",
    "Authors": [
      "Nina P\u00f6rner",
      "Hinrich Sch\u00fctze",
      "Benjamin Roth 0001"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ChuangL0F18",
    "Title": "Learning to Act Properly - Predicting and Explaining Affordances From Images.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chuang_Learning_to_Act_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Ching-Yao Chuang",
      "Jiaman Li",
      "Antonio Torralba 0001",
      "Sanja Fidler"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/FongV18",
    "Title": "Net2Vec - Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Ruth Fong",
      "Andrea Vedaldi"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/MascharkaTSM18",
    "Title": "Transparency by Design - Closing the Gap Between Performance and Interpretability in Visual Reasoning.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mascharka_Transparency_by_Design_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "David Mascharka",
      "Philip Tran",
      "Ryan Soklaski",
      "Arjun Majumdar"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ParkHARSDR18",
    "Title": "Multimodal Explanations - Justifying Decisions and Pointing to the Evidence.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Dong Huk Park",
      "Lisa Anne Hendricks",
      "Zeynep Akata",
      "Anna Rohrbach",
      "Bernt Schiele",
      "Trevor Darrell",
      "Marcus Rohrbach"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/WangS0H18",
    "Title": "Interpret Neural Networks by Identifying Critical Data Routing Paths.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Interpret_Neural_Networks_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Yulong Wang",
      "Hang Su 0006",
      "Bo Zhang 0010",
      "Xiaolin Hu 0001"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/WuLCJL18",
    "Title": "Interpretable Video Captioning via Trajectory Structured Localization.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Xian Wu",
      "Guanbin Li",
      "Qingxing Cao",
      "Qingge Ji",
      "Liang Lin"
    ],
    "Type of Data": [
      "Video"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ZhangWZ18a",
    "Title": "Interpretable Convolutional Neural Networks.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Quanshi Zhang",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/ZhangXWXY18",
    "Title": "DeepVoting - A Robust and Explainable Deep Network for Semantic Part Detection Under Partial Occlusion.",
    "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.html",
    "Year": "2018",
    "Venue": "CVPR",
    "Authors": [
      "Zhishuai Zhang",
      "Cihang Xie",
      "Jianyu Wang",
      "Lingxi Xie",
      "Alan L. Yuille"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization",
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/JhaWXZ18",
    "Title": "Interpretable Word Embeddings for Medical Domain.",
    "url": "https://doi.org/10.1109/ICDM.2018.00135",
    "Year": "2018",
    "Venue": "ICDM",
    "Authors": [
      "Kishlay Jha",
      "Yaqing Wang",
      "Guangxu Xun",
      "Aidong Zhang"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/KarlssonRPG18",
    "Title": "Explainable Time Series Tweaking via Irreversible and Reversible Temporal Transformations.",
    "url": "https://doi.org/10.1109/ICDM.2018.00036",
    "Year": "2018",
    "Venue": "ICDM",
    "Authors": [
      "Isak Karlsson",
      "Jonathan Rebane",
      "Panagiotis Papapetrou",
      "Aristides Gionis"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/WangCYWW018",
    "Title": "A Reinforcement Learning Framework for Explainable Recommendation.",
    "url": "https://doi.org/10.1109/ICDM.2018.00074",
    "Year": "2018",
    "Venue": "ICDM",
    "Authors": [
      "Xiting Wang",
      "Yiru Chen",
      "Jie Yang",
      "Le Wu",
      "Zhengtao Wu",
      "Xing Xie 0001"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/KindermansSAMEK18",
    "Title": "Learning how to explain neural networks - PatternNet and PatternAttribution.",
    "url": "https://openreview.net/forum?id=Hkn7CBaTW",
    "Year": "2018",
    "Venue": "ICLR",
    "Authors": [
      "Pieter-Jan Kindermans",
      "Kristof T. Sch\u00fctt",
      "Maximilian Alber",
      "Klaus-Robert M\u00fcller",
      "Dumitru Erhan",
      "Been Kim",
      "Sven D\u00e4hne"
    ],
    "Type of Data": [
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/ShuXS18",
    "Title": "Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning.",
    "url": "https://openreview.net/forum?id=SJJQVZW0b",
    "Year": "2018",
    "Venue": "ICLR",
    "Authors": [
      "Tianmin Shu",
      "Caiming Xiong",
      "Richard Socher"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Graph",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/TrottXS18",
    "Title": "Interpretable Counting for Visual Question Answering.",
    "url": "https://openreview.net/forum?id=S1J2ZyZ0Z",
    "Year": "2018",
    "Venue": "ICLR",
    "Authors": [
      "Alexander Trott",
      "Caiming Xiong",
      "Richard Socher"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Question Answering"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/AdelGW18",
    "Title": "Discovering Interpretable Representations for Both Deep Generative and Discriminative Models.",
    "url": "http://proceedings.mlr.press/v80/adel18a.html",
    "Year": "2018",
    "Venue": "ICML",
    "Authors": [
      "Tameem Adel",
      "Zoubin Ghahramani",
      "Adrian Weller"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/AinsworthFLF18",
    "Title": "oi-VAE - Output Interpretable VAEs for Nonlinear Group Factor Analysis.",
    "url": "http://proceedings.mlr.press/v80/ainsworth18a.html",
    "Year": "2018",
    "Venue": "ICML",
    "Authors": [
      "Samuel K. Ainsworth",
      "Nicholas J. Foti",
      "Adrian K. C. Lee",
      "Emily B. Fox"
    ],
    "Type of Data": [
      "Images",
      "Video",
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/KimWGCWVS18",
    "Title": "Interpretability Beyond Feature Attribution - Quantitative Testing with Concept Activation Vectors (TCAV).",
    "url": "http://proceedings.mlr.press/v80/kim18d.html",
    "Year": "2018",
    "Venue": "ICML",
    "Authors": [
      "Been Kim",
      "Martin Wattenberg",
      "Justin Gilmer",
      "Carrie J. Cai",
      "James Wexler",
      "Fernanda B. Vi\u00e9gas",
      "Rory Sayres"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap",
      "Prototypes",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/VermaMSKC18",
    "Title": "Programmatically Interpretable Reinforcement Learning.",
    "url": "http://proceedings.mlr.press/v80/verma18a.html",
    "Year": "2018",
    "Venue": "ICML",
    "Authors": [
      "Abhinav Verma",
      "Vijayaraghavan Murali",
      "Rishabh Singh",
      "Pushmeet Kohli",
      "Swarat Chaudhuri"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/HuJCC18",
    "Title": "Interpretable Recommendation via Attraction Modeling - Learning Multilevel Attractiveness over Multimodal Movie Contents.",
    "url": "https://doi.org/10.24963/ijcai.2018/472",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Liang Hu 0004",
      "Songlei Jian",
      "Longbing Cao",
      "Qingkui Chen"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/LabreucheF18",
    "Title": "Explaining Multi-Criteria Decision Aiding Models with an Extended Shapley Value.",
    "url": "https://doi.org/10.24963/ijcai.2018/46",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Christophe Labreuche",
      "Simon Fossier"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/LiuSH18",
    "Title": "Contextual Outlier Interpretation.",
    "url": "https://doi.org/10.24963/ijcai.2018/341",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Ninghao Liu",
      "Donghwa Shin",
      "Xia Hu"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Support Vector Machine",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Anomaly detection"
    ],
    "Type of Explanation": [
      "Localization",
      "Prototypes",
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/LuoAPWZYH18",
    "Title": "Beyond Polarity - Interpretable Financial Sentiment Analysis with Hierarchical Query-driven Attention.",
    "url": "https://doi.org/10.24963/ijcai.2018/590",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Ling Luo",
      "Xiang Ao",
      "Feiyang Pan",
      "Jin Wang 0007",
      "Tong Zhao",
      "Ningzi Yu",
      "Qing He 0003"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/RagoCT18",
    "Title": "Argumentation-Based Recommendations - Fantastic Explanations and How to Find Them.",
    "url": "https://doi.org/10.24963/ijcai.2018/269",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Antonio Rago 0001",
      "Oana Cocarascu",
      "Francesca Toni"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/SatoSS018",
    "Title": "Interpretable Adversarial Perturbation in Input Embedding Space for Text.",
    "url": "https://doi.org/10.24963/ijcai.2018/601",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Motoki Sato",
      "Jun Suzuki",
      "Hiroyuki Shindo",
      "Yuji Matsumoto 0001"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Prototypes",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/ShihCD18",
    "Title": "A Symbolic Approach to Explaining Bayesian Network Classifiers.",
    "url": "https://doi.org/10.24963/ijcai.2018/708",
    "Year": "2018",
    "Venue": "IJCAI",
    "Authors": [
      "Andy Shih",
      "Arthur Choi",
      "Adnan Darwiche"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Explanation",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "White-box model"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/BaiZEV18",
    "Title": "Interpretable Representation Learning for Healthcare via Capturing Disease Progression through Time.",
    "url": "https://doi.org/10.1145/3219819.3219904",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Tian Bai",
      "Shanshan Zhang",
      "Brian L. Egleston",
      "Slobodan Vucetic"
    ],
    "Type of Data": [
      "Text",
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ChuHHWP18",
    "Title": "Exact and Consistent Interpretation for Piecewise Linear Neural Networks - A Closed Form Solution.",
    "url": "https://doi.org/10.1145/3219819.3220063",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Lingyang Chu",
      "Xia Hu",
      "Juhua Hu",
      "Lanjun Wang",
      "Jian Pei"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "White-box model"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/DuLSH18",
    "Title": "Towards Explanation of DNN-based Prediction with Guided Feature Inversion.",
    "url": "https://doi.org/10.1145/3219819.3220099",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Mengnan Du",
      "Ninghao Liu",
      "Qingquan Song",
      "Xia Hu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/Janakiraman18",
    "Title": "Explaining Aviation Safety Incidents Using Deep Temporal Multiple Instance Learning.",
    "url": "https://doi.org/10.1145/3219819.3219871",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Vijay Manikandan Janakiraman"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/LiuHLH18",
    "Title": "On Interpretation of Network Embedding via Taxonomy Induction.",
    "url": "https://doi.org/10.1145/3219819.3220001",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Ninghao Liu",
      "Xiao Huang 0001",
      "Jundong Li",
      "Xia Hu"
    ],
    "Type of Data": [
      "Graph data",
      "Other"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Representation Visualization",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/LiuYH18",
    "Title": "Adversarial Detection with Model Interpretation.",
    "url": "https://doi.org/10.1145/3219819.3220027",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Ninghao Liu",
      "Hongxia Yang",
      "Xia Hu"
    ],
    "Type of Data": [
      "Text",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Support Vector Machine",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/WangWLW18",
    "Title": "Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis.",
    "url": "https://doi.org/10.1145/3219819.3220060",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Jingyuan Wang",
      "Ze Wang",
      "Jianfeng Li",
      "Junjie Wu 0001"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/YangSJ018",
    "Title": "I Know You'll Be Back - Interpretable New User Clustering and Churn Prediction on a Mobile Social Application.",
    "url": "https://doi.org/10.1145/3219819.3219821",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Carl Yang",
      "Xiaolin Shi",
      "Luo Jie",
      "Jiawei Han 0001"
    ],
    "Type of Data": [
      "Time series",
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Clustering",
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/ZangC018",
    "Title": "Learning and Interpreting Complex Distributions in Empirical Data.",
    "url": "https://doi.org/10.1145/3219819.3220073",
    "Year": "2018",
    "Venue": "KDD",
    "Authors": [
      "Chengxi Zang",
      "Peng Cui 0001",
      "Wenwu Zhu 0001"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Time series"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/CamburuRLB18",
    "Title": "e-SNLI - Natural Language Inference with Natural Language Explanations.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/4c7a167bb329bd92580a99ce422d6fa6-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Oana-Maria Camburu",
      "Tim Rockt\u00e4schel",
      "Thomas Lukasiewicz",
      "Phil Blunsom"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Text"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/GuoHTXL18",
    "Title": "Explaining Deep Learning Models - A Bayesian Non-parametric Approach.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/4b4edc2630fe75800ddc29a7b4070add-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Wenbo Guo 0002",
      "Sui Huang",
      "Yunzhe Tao",
      "Xinyu Xing",
      "Lin Lin"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/GuptaBCC18",
    "Title": "Diminishing Returns Shape Constraints for Interpretability and Regularization.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/caa202034f268232c26fac9435f54e15-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Maya R. Gupta",
      "Dara Bahri",
      "Andrew Cotter",
      "Kevin Robert Canini"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Other"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/HeoLKLKYH18",
    "Title": "Uncertainty-Aware Attention for Reliable Interpretation and Prediction.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/285e19f20beded7d215102b49d5c09a0-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Jay Heo",
      "Haebeom Lee",
      "Saehoon Kim",
      "Juho Lee",
      "Kwang Joon Kim",
      "Eunho Yang",
      "Sung Ju Hwang"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/Norcliffe-Brown18",
    "Title": "Learning Conditioned Graph Structures for Interpretable Visual Question Answering.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/4aeae10ea1c6433c926cdfa558d31134-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Will Norcliffe-Brown",
      "Stathis Vafeias",
      "Sarah Parisot"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Question Answering"
    ],
    "Type of Explanation": [
      "Graph",
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/PlumbMT18",
    "Title": "Model Agnostic Supervised Local Explanations.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/b495ce63ede0f4efc9eec62cb947c162-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Gregory Plumb",
      "Denali Molitor",
      "Ameet S. Talwalkar"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation",
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/TsangLPML18",
    "Title": "Neural Interaction Transparency (NIT) - Disentangling Learned Interactions for Improved Interpretability.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/74378afe5e8b20910cf1f939e57f0480-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Michael Tsang",
      "Hanpeng Liu",
      "Sanjay Purushotham",
      "Pavankumar Murali",
      "Yan Liu 0002"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Logistic Regression",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/Wang18",
    "Title": "Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/32bbf7b2bc4ed14eb1e9c2580056a989-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Tong Wang"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/YehKYR18",
    "Title": "Representer Point Selection for Explaining Deep Neural Networks.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/8a7129b8f3edd95b7d969dfc2c8e9d9d-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Chih-Kuan Yeh",
      "Joon Sik Kim",
      "Ian En-Hsu Yen",
      "Pradeep Ravikumar"
    ],
    "Type of Data": [
      "Any",
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ZhangSS18",
    "Title": "Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections.",
    "url": "https://proceedings.neurips.cc/paper/2018/hash/300891a62162b960cf02ce3827bb363c-Abstract.html",
    "Year": "2018",
    "Venue": "NeurIPS",
    "Authors": [
      "Xin Zhang 0035",
      "Armando Solar-Lezama",
      "Rishabh Singh"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/WangWJY18",
    "Title": "Explainable Recommendation via Multi-Task Learning in Opinionated Text Data.",
    "url": "https://doi.org/10.1145/3209978.3210010",
    "Year": "2018",
    "Venue": "SIGIR",
    "Authors": [
      "Nan Wang",
      "Hongning Wang",
      "Yiling Jia",
      "Yue Yin"
    ],
    "Type of Data": [
      "User-item matrix",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Localization",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/ChenZLM18",
    "Title": "Neural Attentional Rating Regression with Review-level Explanations.",
    "url": "https://doi.org/10.1145/3178876.3186070",
    "Year": "2018",
    "Venue": "WWW",
    "Authors": [
      "Chong Chen",
      "Min Zhang 0006",
      "Yiqun Liu 0001",
      "Shaoping Ma"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/Wang0FNC18",
    "Title": "TEM - Tree-enhanced Embedding Model for Explainable Recommendation.",
    "url": "https://doi.org/10.1145/3178876.3186066",
    "Year": "2018",
    "Venue": "WWW",
    "Authors": [
      "Xiang Wang 0010",
      "Xiangnan He 0001",
      "Fuli Feng",
      "Liqiang Nie",
      "Tat-Seng Chua"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method",
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "www/WuWYLZ18",
    "Title": "Sharing Deep Neural Network Models with Interpretation.",
    "url": "https://doi.org/10.1145/3178876.3185995",
    "Year": "2018",
    "Venue": "WWW",
    "Authors": [
      "Huijun Wu 0001",
      "Chen Wang 0008",
      "Jie Yin",
      "Kai Lu",
      "Liming Zhu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/ZhangCWZ17",
    "Title": "Growing Interpretable Part Graphs on ConvNets via Multi-Shot Learning.",
    "url": "http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14909",
    "Year": "2017",
    "Venue": "AAAI",
    "Authors": [
      "Quanshi Zhang",
      "Ruiming Cao",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Support Vector Machine"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Graph",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/XieMDH17",
    "Title": "An Interpretable Knowledge Transfer Model for Knowledge Base Completion.",
    "url": "https://doi.org/10.18653/v1/P17-1088",
    "Year": "2017",
    "Venue": "ACL",
    "Authors": [
      "Qizhe Xie",
      "Xuezhe Ma",
      "Zihang Dai",
      "Eduard H. Hovy"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/BauZKO017",
    "Title": "Network Dissection - Quantifying Interpretability of Deep Visual Representations.",
    "url": "https://doi.org/10.1109/CVPR.2017.354",
    "Year": "2017",
    "Venue": "CVPR",
    "Authors": [
      "David Bau",
      "Bolei Zhou",
      "Aditya Khosla",
      "Aude Oliva",
      "Antonio Torralba 0001"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Localization",
      "Text"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/DongSZZ17",
    "Title": "Improving Interpretability of Deep Neural Networks with Semantic Information.",
    "url": "https://doi.org/10.1109/CVPR.2017.110",
    "Year": "2017",
    "Venue": "CVPR",
    "Authors": [
      "Yinpeng Dong",
      "Hang Su 0006",
      "Jun Zhu 0001",
      "Bo Zhang 0010"
    ],
    "Type of Data": [
      "Video"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "cvpr/LiangLSFYX17",
    "Title": "Interpretable Structure-Evolving LSTM.",
    "url": "https://doi.org/10.1109/CVPR.2017.234",
    "Year": "2017",
    "Venue": "CVPR",
    "Authors": [
      "Xiaodan Liang",
      "Liang Lin",
      "Xiaohui Shen",
      "Jiashi Feng",
      "Shuicheng Yan",
      "Eric P. Xing"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/KimC17",
    "Title": "Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention.",
    "url": "https://doi.org/10.1109/ICCV.2017.320",
    "Year": "2017",
    "Venue": "ICCV",
    "Authors": [
      "Jinkyu Kim",
      "John F. Canny"
    ],
    "Type of Data": [
      "Images",
      "Video"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/SelvarajuCDVPB17",
    "Title": "Grad-CAM - Visual Explanations from Deep Networks via Gradient-Based Localization.",
    "url": "https://doi.org/10.1109/ICCV.2017.74",
    "Year": "2017",
    "Venue": "ICCV",
    "Authors": [
      "Ramprasaath R. Selvaraju",
      "Michael Cogswell",
      "Abhishek Das",
      "Ramakrishna Vedantam",
      "Devi Parikh",
      "Dhruv Batra"
    ],
    "Type of Data": [
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iccv/WorrallGTB17",
    "Title": "Interpretable Transformations with Encoder-Decoder Networks.",
    "url": "https://doi.org/10.1109/ICCV.2017.611",
    "Year": "2017",
    "Venue": "ICCV",
    "Authors": [
      "Daniel E. Worrall",
      "Stephan J. Garbin",
      "Daniyar Turmukhambetov",
      "Gabriel J. Brostow"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Generation",
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/OyamadaN17",
    "Title": "Relational Mixture of Experts - Explainable Demographics Prediction with Behavioral Data.",
    "url": "https://doi.org/10.1109/ICDM.2017.45",
    "Year": "2017",
    "Venue": "ICDM",
    "Authors": [
      "Masafumi Oyamada",
      "Shinji Nakadai"
    ],
    "Type of Data": [
      "User-item matrix"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Support Vector Machine",
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Heatmap"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "iclr/YuV17",
    "Title": "Towards Deep Interpretability (MUS-ROVER II) - Learning Hierarchical Representations of Tonal Music.",
    "url": "https://openreview.net/forum?id=ryhqQFKgl",
    "Year": "2017",
    "Venue": "ICLR",
    "Authors": [
      "Haizi Yu",
      "Lav R. Varshney"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Graph"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/DempseyMSDGMR17",
    "Title": "iSurvive - An Interpretable, Event-time Prediction Model for mHealth.",
    "url": "http://proceedings.mlr.press/v70/dempsey17a.html",
    "Year": "2017",
    "Venue": "ICML",
    "Authors": [
      "Walter H. Dempsey",
      "Alexander Moreno",
      "Christy K. Scott",
      "Michael L. Dennis",
      "David H. Gustafson",
      "Susan A. Murphy",
      "James M. Rehg"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Time series"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icml/FoersterGSCS17",
    "Title": "Input Switched Affine Networks - An RNN Architecture Designed for Interpretability.",
    "url": "http://proceedings.mlr.press/v70/foerster17a.html",
    "Year": "2017",
    "Venue": "ICML",
    "Authors": [
      "Jakob N. Foerster",
      "Justin Gilmer",
      "Jascha Sohl-Dickstein",
      "Jan Chorowski",
      "David Sussillo"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation",
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Generation"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "ijcai/RossHD17",
    "Title": "Right for the Right Reasons - Training Differentiable Models by Constraining their Explanations.",
    "url": "https://doi.org/10.24963/ijcai.2017/371",
    "Year": "2017",
    "Venue": "IJCAI",
    "Authors": [
      "Andrew Slavin Ross",
      "Michael C. Hughes",
      "Finale Doshi-Velez"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Supervised explanation training"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/TolomeiSHL17",
    "Title": "Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking.",
    "url": "https://doi.org/10.1145/3097983.3098039",
    "Year": "2017",
    "Venue": "KDD",
    "Authors": [
      "Gabriele Tolomei",
      "Fabrizio Silvestri",
      "Andrew Haines",
      "Mounia Lalmas"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Tree Ensemble"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Other"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ElenbergDFK17",
    "Title": "Streaming Weak Submodularity - Interpreting Neural Networks on the Fly.",
    "url": "https://proceedings.neurips.cc/paper/2017/hash/c182f930a06317057d31c73bb2fedd4f-Abstract.html",
    "Year": "2017",
    "Venue": "NeurIPS",
    "Authors": [
      "Ethan R. Elenberg",
      "Alexandros G. Dimakis",
      "Moran Feldman",
      "Amin Karbasi"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/HsuZG17",
    "Title": "Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data.",
    "url": "https://proceedings.neurips.cc/paper/2017/hash/0a0a0c8aaa00ade50f74a3f0ca981ed7-Abstract.html",
    "Year": "2017",
    "Venue": "NeurIPS",
    "Authors": [
      "Wei-Ning Hsu",
      "Yu Zhang 0033",
      "James R. Glass"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement",
      "Representation Synthesis"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/LiSE17",
    "Title": "InfoGAIL - Interpretable Imitation Learning from Visual Demonstrations.",
    "url": "https://proceedings.neurips.cc/paper/2017/hash/2cd4e8a2ce081c3d7c32c3cde4312ef7-Abstract.html",
    "Year": "2017",
    "Venue": "NeurIPS",
    "Authors": [
      "Yunzhu Li",
      "Jiaming Song",
      "Stefano Ermon"
    ],
    "Type of Data": [
      "Other"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Policy learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/LundbergL17",
    "Title": "A Unified Approach to Interpreting Model Predictions.",
    "url": "https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html",
    "Year": "2017",
    "Venue": "NeurIPS",
    "Authors": [
      "Scott M. Lundberg",
      "Su-In Lee"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Any"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/RaghuGYS17",
    "Title": "SVCCA - Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability.",
    "url": "https://proceedings.neurips.cc/paper/2017/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html",
    "Year": "2017",
    "Venue": "NeurIPS",
    "Authors": [
      "Maithra Raghu",
      "Justin Gilmer",
      "Jason Yosinski",
      "Jascha Sohl-Dickstein"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/ChenCHCCSD16",
    "Title": "Interpretable Clustering via Discriminative Rectangle Mixture Model.",
    "url": "https://doi.org/10.1109/ICDM.2016.0097",
    "Year": "2016",
    "Venue": "ICDM",
    "Authors": [
      "Junxiang Chen",
      "Yale Chang",
      "Brian Hobbs",
      "Peter J. Castaldi",
      "Michael H. Cho",
      "Edwin K. Silverman",
      "Jennifer G. Dy"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Clustering"
    ],
    "Type of Explanation": [
      "Decision Rules",
      "Representation Visualization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/DangSSSB16",
    "Title": "Outlier Detection from Network Data with Subnetwork Interpretation.",
    "url": "https://doi.org/10.1109/ICDM.2016.0101",
    "Year": "2016",
    "Venue": "ICDM",
    "Authors": [
      "Xuan-Hong Dang",
      "Arlei Silva",
      "Ambuj K. Singh",
      "Ananthram Swami",
      "Prithwish Basu"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Anomaly detection"
    ],
    "Type of Explanation": [
      "Localization"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/WangRDLKM16",
    "Title": "Bayesian Rule Sets for Interpretable Classification.",
    "url": "https://doi.org/10.1109/ICDM.2016.0171",
    "Year": "2016",
    "Venue": "ICDM",
    "Authors": [
      "Tong Wang 0011",
      "Cynthia Rudin",
      "Finale Doshi-Velez",
      "Yimin Liu",
      "Erica Klampfl",
      "Perry MacNeille"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/LakkarajuBL16",
    "Title": "Interpretable Decision Sets - A Joint Framework for Description and Prediction.",
    "url": "https://doi.org/10.1145/2939672.2939874",
    "Year": "2016",
    "Venue": "KDD",
    "Authors": [
      "Himabindu Lakkaraju",
      "Stephen H. Bach",
      "Jure Leskovec"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Decision Rules"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/Ribeiro0G16",
    "Title": "\"Why Should I Trust You?\" - Explaining the Predictions of Any Classifier.",
    "url": "https://doi.org/10.1145/2939672.2939778",
    "Year": "2016",
    "Venue": "KDD",
    "Authors": [
      "Marco T\u00falio Ribeiro",
      "Sameer Singh 0001",
      "Carlos Guestrin"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Tree Ensemble",
      "Support Vector Machine",
      "Any (for a specific task); model-agnostic",
      "Logistic Regression",
      "Other"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Localization"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ChenCDHSSA16",
    "Title": "InfoGAN - Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.",
    "url": "https://proceedings.neurips.cc/paper/2016/hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Abstract.html",
    "Year": "2016",
    "Venue": "NeurIPS",
    "Authors": [
      "Xi Chen 0022",
      "Yan Duan",
      "Rein Houthooft",
      "John Schulman",
      "Ilya Sutskever",
      "Pieter Abbeel"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Disentanglement"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ChoiBSKSS16",
    "Title": "RETAIN - An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism.",
    "url": "https://proceedings.neurips.cc/paper/2016/hash/231141b34c82aa95e48810a9d1b33a79-Abstract.html",
    "Year": "2016",
    "Venue": "NeurIPS",
    "Authors": [
      "Edward Choi",
      "Mohammad Taha Bahadori",
      "Jimeng Sun",
      "Joshua Kulas",
      "Andy Schuetz",
      "Walter F. Stewart"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/Jitkrittum0CG16",
    "Title": "Interpretable Distribution Features with Maximum Testing Power.",
    "url": "https://proceedings.neurips.cc/paper/2016/hash/0a09c8844ba8f0936c20bd791130d6b6-Abstract.html",
    "Year": "2016",
    "Venue": "NeurIPS",
    "Authors": [
      "Wittawat Jitkrittum",
      "Zolt\u00e1n Szab\u00f3 0001",
      "Kacper P. Chwialkowski",
      "Arthur Gretton"
    ],
    "Type of Data": [
      "Tabular / structured",
      "Images",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic",
      "Other"
    ],
    "Type of Task": [
      "Other"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Heatmap"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/KimKK16",
    "Title": "Examples are not enough, learn to criticize! Criticism for Interpretability.",
    "url": "https://proceedings.neurips.cc/paper/2016/hash/5680522b8e2bb01943234bce7bf84534-Abstract.html",
    "Year": "2016",
    "Venue": "NeurIPS",
    "Authors": [
      "Been Kim",
      "Oluwasanmi Koyejo",
      "Rajiv Khanna"
    ],
    "Type of Data": [
      "Images"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network",
      "Any (for a specific task); model-agnostic"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/LakkarajuL16",
    "Title": "Confusions over Time - An Interpretable Bayesian Model to Characterize Trends in Decision Making.",
    "url": "https://proceedings.neurips.cc/paper/2016/hash/97d0145823aeb8ed80617be62e08bdcc-Abstract.html",
    "Year": "2016",
    "Venue": "NeurIPS",
    "Authors": [
      "Himabindu Lakkaraju",
      "Jure Leskovec"
    ],
    "Type of Data": [
      "Time series",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification",
      "Clustering"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/ZhaoP16",
    "Title": "Interpretable Nonlinear Dynamic Modeling of Neural Trajectories.",
    "url": "https://proceedings.neurips.cc/paper/2016/hash/b2531e7bb29bf22e1daae486fae3417a-Abstract.html",
    "Year": "2016",
    "Venue": "NeurIPS",
    "Authors": [
      "Yuan Zhao 0004",
      "Il Memming Park"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Model Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Regression"
    ],
    "Type of Explanation": [
      "White-box model"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/ZhaoLRMYR16",
    "Title": "Explainable User Clustering in Short Text Streams.",
    "url": "https://doi.org/10.1145/2911451.2911522",
    "Year": "2016",
    "Venue": "SIGIR",
    "Authors": [
      "Yukun Zhao",
      "Shangsong Liang",
      "Zhaochun Ren",
      "Jun Ma 0001",
      "Emine Yilmaz",
      "Maarten de Rijke"
    ],
    "Type of Data": [
      "Text",
      "Time series",
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Clustering"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "aaai/KimPRS15",
    "Title": "Scalable and Interpretable Data Representation for High-Dimensional, Complex Data.",
    "url": "http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9738",
    "Year": "2015",
    "Venue": "AAAI",
    "Authors": [
      "Been Kim",
      "Kayur Patel",
      "Afshin Rostamizadeh",
      "Julie A. Shah"
    ],
    "Type of Data": [
      "Text"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/WangFM15",
    "Title": "Trading Interpretability for Accuracy - Oblique Treed Sparse Additive Models.",
    "url": "https://doi.org/10.1145/2783258.2783407",
    "Year": "2015",
    "Venue": "KDD",
    "Authors": [
      "Jialei Wang",
      "Ryohei Fujimaki",
      "Yosuke Motohashi"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Transparent Box Design"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Classification",
      "Regression"
    ],
    "Type of Explanation": [
      "Decision Tree",
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "nips/KimSD15",
    "Title": "Mind the Gap - A Generative Approach to Interpretable Feature Selection and Extraction.",
    "url": "https://proceedings.neurips.cc/paper/2015/hash/82965d4ed8150294d4330ace00821d77-Abstract.html",
    "Year": "2015",
    "Venue": "NeurIPS",
    "Authors": [
      "Been Kim",
      "Julie A. Shah",
      "Finale Doshi-Velez"
    ],
    "Type of Data": [
      "Tabular / structured"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Clustering"
    ],
    "Type of Explanation": [
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "acl/FysheTMM14",
    "Title": "Interpretable Semantic Vectors from a Joint Model of Brain- and Text- Based Meaning.",
    "url": "https://doi.org/10.3115/v1/p14-1046",
    "Year": "2014",
    "Venue": "ACL",
    "Authors": [
      "Alona Fyshe",
      "Partha Pratim Talukdar",
      "Brian Murphy",
      "Tom M. Mitchell"
    ],
    "Type of Data": [
      "Time series",
      "Text"
    ],
    "Type of Problem": [
      "Model Inspection",
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Representation learning"
    ],
    "Type of Explanation": [
      "Heatmap",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "icdm/ChanLBR14",
    "Title": "TRIBAC - Discovering Interpretable Clusters and Latent Structures in Graphs.",
    "url": "https://doi.org/10.1109/ICDM.2014.118",
    "Year": "2014",
    "Venue": "ICDM",
    "Authors": [
      "Jeffrey Chan",
      "Christopher Leckie",
      "James Bailey 0001",
      "Kotagiri Ramamohanarao"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Model Inspection"
    ],
    "Type of Model to be Explained": [
      "Other"
    ],
    "Type of Task": [
      "Clustering"
    ],
    "Type of Explanation": [
      "Feature plot"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/BarbieriBM14",
    "Title": "Who to follow and why - link prediction with explanations.",
    "url": "https://doi.org/10.1145/2623330.2623733",
    "Year": "2014",
    "Venue": "KDD",
    "Authors": [
      "Nicola Barbieri",
      "Francesco Bonchi",
      "Giuseppe Manco 0001"
    ],
    "Type of Data": [
      "Graph data"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Bayesian or Hierarchical Network"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Localization",
      "Feature Importance"
    ],
    "Method used to explain": [
      "Post-hoc explanation method"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "kdd/GhalwashRO14",
    "Title": "Utilizing temporal patterns for estimating uncertainty in interpretable early decision making.",
    "url": "https://doi.org/10.1145/2623330.2623694",
    "Year": "2014",
    "Venue": "KDD",
    "Authors": [
      "Mohamed F. Ghalwash",
      "Vladan Radosavljevic",
      "Zoran Obradovic"
    ],
    "Type of Data": [
      "Time series"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "Any (for a specific task); model-agnostic",
      "Other"
    ],
    "Type of Task": [
      "Classification"
    ],
    "Type of Explanation": [
      "Prototypes"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  },
  {
    "Paper-ID": "sigir/ZhangL0ZLM14",
    "Title": "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis.",
    "url": "https://doi.org/10.1145/2600428.2609579",
    "Year": "2014",
    "Venue": "SIGIR",
    "Authors": [
      "Yongfeng Zhang",
      "Guokun Lai",
      "Min Zhang 0006",
      "Yi Zhang",
      "Yiqun Liu 0001",
      "Shaoping Ma"
    ],
    "Type of Data": [
      "Text",
      "User-item matrix"
    ],
    "Type of Problem": [
      "Outcome Explanation"
    ],
    "Type of Model to be Explained": [
      "(Deep) Neural Network"
    ],
    "Type of Task": [
      "Recommendation"
    ],
    "Type of Explanation": [
      "Feature Importance",
      "Text"
    ],
    "Method used to explain": [
      "Interpretability built into the predictive model"
    ],
    "Should the paper be included?": "Yes",
    "Should the paper be included with filter?": "Yes"
  } 
]
