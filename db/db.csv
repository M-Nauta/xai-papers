Paper-ID,Title,url,Year,Venue,Authors,Type of Data,Type of Problem,Type of Model to be Explained,Type of Task,Type of Explanation,Method used to explain,Should the paper be included?,Should the paper be included with filter?
ijcai/PanLLZ20,Explainable Recommendation via Interpretable Feature Mapping and Evaluation of Explainability.,https://doi.org/10.24963/ijcai.2020/373,2020,IJCAI,"Deng Pan, Xiangrui Li, Xin Li 0081, Dongxiao Zhu",User-item matrix,Outcome Explanation,"(Deep) Neural Network, Other",Recommendation,"Disentanglement, Feature Importance",Post-hoc explanation method,Yes,Yes
aaai/TuHW0HZ20,"Select, Answer and Explain - Interpretable Multi-Hop Reading Comprehension over Multiple Documents.",https://aaai.org/ojs/index.php/AAAI/article/view/6441,2020,AAAI,"Ming Tu, Kevin Huang 0002, Guangtao Wang, Jing Huang 0019, Xiaodong He 0002, Bowen Zhou",Text,Outcome Explanation,(Deep) Neural Network,Question Answering,"Feature Importance, Localization",Supervised explanation training,Yes,Yes
cvpr/EsserRO20,A Disentangling Invertible Interpretation Network for Explaining Latent Representations.,https://doi.org/10.1109/CVPR42600.2020.00924,2020,CVPR,"Patrick Esser, Robin Rombach, Björn Ommer",Images,Model Inspection,(Deep) Neural Network,"Classification, Representation learning","Disentanglement, Representation Synthesis, Representation Visualization",Post-hoc explanation method,Yes,Yes
icdm/LiuMWH0G20,LP-Explain - Local Pictorial Explanation for Outliers.,https://doi.org/10.1109/ICDM50108.2020.00046,2020,ICDM,"Haoyu Liu, Fenglong Ma, Yaqing Wang, Shibo He, Jiming Chen 0001, Jing Gao",Tabular / structured,Outcome Explanation,Any (for a specific task); model-agnostic,Anomaly detection,Feature plot,Post-hoc explanation method,Yes,Yes
iclr/TsangCLFZL20,Feature Interaction Interpretability - A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection.,https://openreview.net/forum?id=BkgnhTEtDS,2020,ICLR,"Michael Tsang, Dehua Cheng, Hanpeng Liu, Xue Feng, Eric Zhou, Yan Liu 0002","Images, Text, Graph data, Any",Model Inspection,"(Deep) Neural Network, Any (for a specific task); model-agnostic","Classification, Recommendation",Localization,Post-hoc explanation method,Yes,Yes
icml/RiegerSMY20,Interpretations are Useful - Penalizing Explanations to Align Neural Networks with Prior Knowledge.,http://proceedings.mlr.press/v119/rieger20a.html,2020,ICML,"Laura Rieger, Chandan Singh, W. James Murdoch, Bin Yu","Tabular / structured, Images, Text",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Heatmap",Supervised explanation training,Yes,Yes
kdd/PanHLZL20,xGAIL - Explainable Generative Adversarial Imitation Learning for Explainable Human Decision Analysis.,https://doi.org/10.1145/3394486.3403186,2020,KDD,"Menghai Pan, Weixiao Huang, Yanhua Li, Xun Zhou, Jun Luo 0007",Other,Outcome Explanation,(Deep) Neural Network,Policy learning,Heatmap,Post-hoc explanation method,Yes,Yes
nips/PalejaSCG20,Interpretable and Personalized Apprenticeship Scheduling - Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations.,https://proceedings.neurips.cc/paper/2020/hash/477bdb55b231264bb53a7942fd84254d-Abstract.html,2020,NeurIPS,"Rohan R. Paleja, Andrew Silva, Letian Chen, Matthew C. Gombolay","Graph data, Other",Transparent Box Design,Other,Policy learning,Decision Tree,Interpretability built into the predictive model,Yes,Yes
nips/VuT20,PGM-Explainer - Probabilistic Graphical Model Explanations for Graph Neural Networks.,https://proceedings.neurips.cc/paper/2020/hash/8fb134f258b1f7865a6ab2d935a897c9-Abstract.html,2020,NeurIPS,"Minh N. Vu, My T. Thai",Graph data,Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Graph,Post-hoc explanation method,Yes,Yes
nips/ZhouHZLSXT20,Towards Interpretable Natural Language Understanding with Explanations as Latent Variables.,https://proceedings.neurips.cc/paper/2020/hash/4be2c8f27b8a420492f2d44463933eb6-Abstract.html,2020,NeurIPS,"Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, Jian Tang",Text,Outcome Explanation,(Deep) Neural Network,Classification,Text,Supervised explanation training,Yes,Yes
sigir/SenGVJ20,The Curious Case of IR Explainability - Explaining Document Scores within and across Ranking Models.,https://doi.org/10.1145/3397271.3401286,2020,SIGIR,"Procheta Sen, Debasis Ganguly, Manisha Verma, Gareth J. F. Jones",Text,"Model Inspection, Outcome Explanation","(Deep) Neural Network, Other",Retrieval,Feature Importance,Post-hoc explanation method,Yes,Yes
acl/LiuYW19,Towards Explainable NLP - A Generative Explanation Framework for Text Classification.,https://doi.org/10.18653/v1/p19-1560,2019,ACL,"Hui Liu, Qingyu Yin, William Yang Wang",Text,Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,"Text, Other",Supervised explanation training,Yes,Yes
cvpr/WagnerKGHWB19,Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks.,http://openaccess.thecvf.com/content_CVPR_2019/html/Wagner_Interpretable_and_Fine-Grained_Visual_Explanations_for_Convolutional_Neural_Networks_CVPR_2019_paper.html,2019,CVPR,"Jörg Wagner, Jan Mathias Köhler, Tobias Gindele, Leon Hetzel, Jakob Thaddäus Wiedemer, Sven Behnke",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Heatmap",Post-hoc explanation method,Yes,Yes
iclr/MWT19,Visual Explanation by Interpretation - Improving Visual Feedback Capabilities of Deep Neural Networks.,https://openreview.net/forum?id=H1ziPjC5Fm,2019,ICLR,"José Oramas M., Kaili Wang, Tinne Tuytelaars",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Heatmap, Representation Synthesis",Post-hoc explanation method,Yes,Yes
icml/Wang19,Gaining Free or Low-Cost Interpretability with Interpretable Partial Substitute.,http://proceedings.mlr.press/v97/wang19a.html,2019,ICML,Tong Wang,"Tabular / structured, Text, Time series","Model Explanation, Outcome Explanation","(Deep) Neural Network, Tree Ensemble, Any (for a specific task); model-agnostic",Classification,Decision Rules,Post-hoc explanation method,Yes,Yes
nips/SchwabK19,CXPlain - Causal Explanations for Model Interpretation under Uncertainty.,https://proceedings.neurips.cc/paper/2019/hash/3ab6be46e1d6b21d59a3c3a0b9d0f6ef-Abstract.html,2019,NeurIPS,"Patrick Schwab, Walter Karlen","Images, Any",Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic","Classification, Regression",Feature Importance,Post-hoc explanation method,Yes,Yes
sigir/ChenCXZ0QZ19,Personalized Fashion Recommendation with Visual Explanations based on Multimodal Attention Network - Towards Visually Explainable Recommendation.,https://doi.org/10.1145/3331184.3331254,2019,SIGIR,"Xu Chen 0017, Hanxiong Chen, Hongteng Xu, Yongfeng Zhang, Yixin Cao 0002, Zheng Qin, Hongyuan Zha","Images, Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,Heatmap,Supervised explanation training,Yes,Yes
sigir/VermaG19,LIRME - Locally Interpretable Ranking Model Explanation.,https://doi.org/10.1145/3331184.3331377,2019,SIGIR,"Manisha Verma, Debasis Ganguly",Text,Outcome Explanation,"Any (for a specific task); model-agnostic, Other",Retrieval,Feature Importance,Post-hoc explanation method,Yes,Yes
aaai/ZhangCSWZ18,Interpreting CNN Knowledge via an Explanatory Graph.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17354,2018,AAAI,"Quanshi Zhang, Ruiming Cao, Feng Shi, Ying Nian Wu, Song-Chun Zhu",Images,Model Inspection,(Deep) Neural Network,Classification,"Heatmap, Graph, Prototypes, Localization",Post-hoc explanation method,Yes,Yes
icdm/YangLWH18,Towards Interpretation of Recommender Systems with Sorted Explanation Paths.,https://doi.org/10.1109/ICDM.2018.00082,2018,ICDM,"Fan Yang 0023, Ninghao Liu, Suhang Wang, Xia Hu","Tabular / structured, User-item matrix",Outcome Explanation,Other,Recommendation,Graph,Post-hoc explanation method,Yes,Yes
icml/ChenSWJ18,Learning to Explain - An Information-Theoretic Perspective on Model Interpretation.,http://proceedings.mlr.press/v80/chen18j.html,2018,ICML,"Jianbo Chen, Le Song, Martin J. Wainwright, Michael I. Jordan","Tabular / structured, Images, Text",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Localization",Post-hoc explanation method,Yes,Yes
kdd/PeakeW18,Explanation Mining - Post Hoc Interpretability of Latent Factor Models for Recommendation Systems.,https://doi.org/10.1145/3219819.3220072,2018,KDD,"Georgina Peake, Jun Wang",User-item matrix,Model Explanation,Other,Recommendation,Decision Rules,Post-hoc explanation method,Yes,Yes
nips/Alvarez-MelisJ18,Towards Robust Interpretability with Self-Explaining Neural Networks.,https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html,2018,NeurIPS,"David Alvarez-Melis, Tommi S. Jaakkola","Tabular / structured, Images",Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
nips/DhurandharCLTTS18,Explanations based on the Missing - Towards Contrastive Explanations with Pertinent Negatives.,https://proceedings.neurips.cc/paper/2018/hash/c5ff2543b53f4cc0ad3819a36752467b-Abstract.html,2018,NeurIPS,"Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Pai-Shun Ting, Karthikeyan Shanmugam, Payel Das","Tabular / structured, Images",Outcome Explanation,(Deep) Neural Network,Classification,Localization,Post-hoc explanation method,Yes,Yes
iccv/FongV17,Interpretable Explanations of Black Boxes by Meaningful Perturbation.,https://doi.org/10.1109/ICCV.2017.371,2017,ICCV,"Ruth C. Fong, Andrea Vedaldi",Images,Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Heatmap,Post-hoc explanation method,Yes,Yes
aaai/AkulaWZ20,CoCoX - Generating Conceptual and Counterfactual Explanations via Fault-Lines.,https://aaai.org/ojs/index.php/AAAI/article/view/5643,2020,AAAI,"Arjun R. Akula, Shuai Wang, Song-Chun Zhu",Images,Outcome Explanation,(Deep) Neural Network,Classification,Prototypes,Post-hoc explanation method,Yes,Yes
aaai/ChenJ20,LS-Tree - Model Interpretation When the Data Are Linguistic.,https://aaai.org/ojs/index.php/AAAI/article/view/5749,2020,AAAI,"Jianbo Chen, Michael I. Jordan",Text,"Model Inspection, Outcome Explanation","(Deep) Neural Network, Any (for a specific task); model-agnostic, Logistic Regression",Classification,"Feature Importance, Graph",Post-hoc explanation method,Yes,Yes
aaai/CiravegnaGMMG20,A Constraint-Based Approach to Learning and Explanation.,https://aaai.org/ojs/index.php/AAAI/article/view/5774,2020,AAAI,"Gabriele Ciravegna, Francesco Giannini, Stefano Melacci, Marco Maggini, Marco Gori",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,Decision Rules,Post-hoc explanation method,Yes,Yes
aaai/DalleigerV20,Explainable Data Decompositions.,https://aaai.org/ojs/index.php/AAAI/article/view/5780,2020,AAAI,"Sebastian Dalleiger, Jilles Vreeken",Tabular / structured,Outcome Explanation,Other,Clustering,Other,"Interpretability built into the predictive model, Post-hoc explanation method",Yes,Yes
aaai/DongNCCZSLCM20,Asymmetrical Hierarchical Networks with Attentive Interactions for Interpretable Review-Based Recommendation.,https://aaai.org/ojs/index.php/AAAI/article/view/6268,2020,AAAI,"Xin Dong 0010, Jingchao Ni, Wei Cheng 0002, Zhengzhang Chen, Bo Zong, Dongjin Song, Yanchi Liu, Haifeng Chen, Gerard de Melo",Text,Outcome Explanation,(Deep) Neural Network,Recommendation,Feature Importance,Post-hoc explanation method,Yes,Yes
aaai/HarderBP20,Interpretable and Differentially Private Predictions.,https://aaai.org/ojs/index.php/AAAI/article/view/5827,2020,AAAI,"Frederik Harder, Matthias Bauer, Mijung Park","Tabular / structured, Images",Model Explanation,(Deep) Neural Network,Classification,"Feature Importance, Representation Synthesis",Post-hoc explanation method,Yes,Yes
aaai/HuaiWMZ20,Towards Interpretation of Pairwise Learning.,https://aaai.org/ojs/index.php/AAAI/article/view/5837,2020,AAAI,"Mengdi Huai, Di Wang 0015, Chenglin Miao, Aidong Zhang","Tabular / structured, Images, Other",Outcome Explanation,Any (for a specific task); model-agnostic,"Classification, Representation learning",Feature Importance,Post-hoc explanation method,Yes,Yes
aaai/ItoTSYI20,Word-Level Contextual Sentiment Analysis with Interpretability.,https://aaai.org/ojs/index.php/AAAI/article/view/5845,2020,AAAI,"Tomoki Ito, Kota Tsubouchi, Hiroki Sakaji, Tatsuo Yamashita, Kiyoshi Izumi",Text,Outcome Explanation,(Deep) Neural Network,Classification,Localization,Interpretability built into the predictive model,Yes,Yes
aaai/LiFANZ20,MRI Reconstruction with Interpretable Pixel-Wise Operations Using Reinforcement Learning.,https://aaai.org/ojs/index.php/AAAI/article/view/5423,2020,AAAI,"Wentian Li, Xidong Feng, Haotian An, Xiang Yao Ng, Yu-Jin Zhang",Images,Outcome Explanation,Other,Policy learning,Localization,Interpretability built into the predictive model,Yes,Yes
aaai/Madumal0SV20,Explainable Reinforcement Learning through a Causal Lens.,https://aaai.org/ojs/index.php/AAAI/article/view/5631,2020,AAAI,"Prashan Madumal, Tim Miller 0001, Liz Sonenberg, Frank Vetere",Other,Outcome Explanation,"(Deep) Neural Network, Tree Ensemble, Any (for a specific task); model-agnostic, Other",Policy learning,Text,Interpretability built into the predictive model,Yes,Yes
aaai/NamGCWL20,Relative Attributing Propagation - Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks.,https://aaai.org/ojs/index.php/AAAI/article/view/5632,2020,AAAI,"Woo-Jeoung Nam, Shir Gur, Jaesik Choi, Lior Wolf, Seong-Whan Lee",Images,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
aaai/PathakLMP20,Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-Like Molecules.,https://aaai.org/ojs/index.php/AAAI/article/view/5433,2020,AAAI,"Yashaswi Pathak, Siddhartha Laghuvarapu, Sarvesh Mehta, U. Deva Priyakumar",Graph data,Outcome Explanation,(Deep) Neural Network,Regression,Feature Importance,Interpretability built into the predictive model,Yes,Yes
aaai/PatroAN20,Explanation vs Attention - A Two-Player Game to Obtain Attention for VQA.,https://aaai.org/ojs/index.php/AAAI/article/view/6858,2020,AAAI,"Badri N. Patro, Anupriy, Vinay Namboodiri","Images, Text",Outcome Explanation,(Deep) Neural Network,Question Answering,Heatmap,Supervised explanation training,Yes,Yes
aaai/WangZHZS20,Dynamic Network Pruning with Interpretable Layerwise Channel Selection.,https://aaai.org/ojs/index.php/AAAI/article/view/6098,2020,AAAI,"Yulong Wang, Xiaolu Zhang, Xiaolin Hu, Bo Zhang, Hang Su 0006",Images,Model Inspection,(Deep) Neural Network,Classification,"Representation Visualization, Other",Post-hoc explanation method,Yes,Yes
aaai/WuPHKCZ0D20,Regional Tree Regularization for Interpretability in Deep Neural Networks.,https://aaai.org/ojs/index.php/AAAI/article/view/6112,2020,AAAI,"Mike Wu, Sonali Parbhoo, Michael C. Hughes, Ryan Kindle, Leo A. Celi, Maurizio Zazzi, Volker Roth 0001, Finale Doshi-Velez",Tabular / structured,Model Explanation,(Deep) Neural Network,Classification,Decision Tree,Post-hoc explanation method,Yes,Yes
aaai/ZhongWTZ0S20,Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction.,https://aaai.org/ojs/index.php/AAAI/article/view/5479,2020,AAAI,"Haoxi Zhong, Yuzhong Wang, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu 0001, Maosong Sun",Text,Outcome Explanation,(Deep) Neural Network,"Question Answering, Classification",Localization,Interpretability built into the predictive model,Yes,Yes
acl/AtanasovaSLA20,Generating Fact Checking Explanations.,https://doi.org/10.18653/v1/2020.acl-main.656,2020,ACL,"Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, Isabelle Augenstein",Text,Outcome Explanation,(Deep) Neural Network,"Classification, Other",Text,Supervised explanation training,Yes,Yes
acl/ChenZJ20,Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection.,https://doi.org/10.18653/v1/2020.acl-main.494,2020,ACL,"Hanjie Chen, Guangtao Zheng, Yangfeng Ji",Text,Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,"Feature Importance, Graph",Post-hoc explanation method,Yes,Yes
acl/GonenJSG20,"Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora.",https://doi.org/10.18653/v1/2020.acl-main.51,2020,ACL,"Hila Gonen, Ganesh Jawahar, Djamé Seddah, Yoav Goldberg",Text,Transparent Box Design,Other,Other,"Localization, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
acl/HanWT20,Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions.,https://doi.org/10.18653/v1/2020.acl-main.492,2020,ACL,"Xiaochuang Han, Byron C. Wallace, Yulia Tsvetkov",Text,Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Prototypes",Post-hoc explanation method,Yes,Yes
acl/KumarT20,NILE - Natural Language Inference with Faithful Natural Language Explanations.,https://doi.org/10.18653/v1/2020.acl-main.771,2020,ACL,"Sawan Kumar, Partha P. Talukdar",Text,Outcome Explanation,(Deep) Neural Network,Classification,"Text, Localization",Supervised explanation training,Yes,Yes
acl/LuL20,GCAN - Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media.,https://doi.org/10.18653/v1/2020.acl-main.48,2020,ACL,"Yi-Ju Lu, Cheng-Te Li",Text,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,Heatmap,Interpretability built into the predictive model,Yes,Yes
acl/MohankumarNNKSR20,Towards Transparent and Explainable Attention Models.,https://doi.org/10.18653/v1/2020.acl-main.387,2020,ACL,"Akash Kumar Mohankumar, Preksha Nema, Sharan Narasimhan, Mitesh M. Khapra, Balaji Vasan Srinivasan, Balaraman Ravindran",Text,Outcome Explanation,(Deep) Neural Network,"Classification, Question Answering",Feature Importance,Interpretability built into the predictive model,Yes,Yes
acl/ShahbaziFGT20,Relation Extraction with Explanation.,https://doi.org/10.18653/v1/2020.acl-main.579,2020,ACL,"Hamed Shahbazi, Xiaoli Z. Fern, Reza Ghaeini, Prasad Tadepalli","Text, Other",Outcome Explanation,(Deep) Neural Network,Other,Feature Importance,Post-hoc explanation method,Yes,Yes
acl/SubramanianBGWS20,Obtaining Faithful Interpretations from Compositional Neural Networks.,https://doi.org/10.18653/v1/2020.acl-main.495,2020,ACL,"Sanjay Subramanian, Ben Bogin, Nitish Gupta, Tomer Wolfson, Sameer Singh 0001, Jonathan Berant, Matt Gardner 0001","Images, Text",Outcome Explanation,(Deep) Neural Network,"Classification, Question Answering","Localization, Other","Interpretability built into the predictive model, Supervised explanation training",Yes,Yes
acl/WuCKL20,Perturbed Masking - Parameter-free Probing for Analyzing and Interpreting BERT.,https://doi.org/10.18653/v1/2020.acl-main.383,2020,ACL,"Zhiyong Wu, Yun Chen, Ben Kao, Qun Liu",Text,"Model Inspection, Outcome Explanation",(Deep) Neural Network,"Classification, Other","Heatmap, Other",Post-hoc explanation method,Yes,Yes
acl/WuRZLN20,DTCA - Decision Tree-based Co-Attention Networks for Explainable Claim Verification.,https://doi.org/10.18653/v1/2020.acl-main.97,2020,ACL,"Lianwei Wu, Yuan Rao, Yongqiang Zhao, Hao Liang, Ambreen Nazir","Text, Graph data",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Localization",Interpretability built into the predictive model,Yes,Yes
acl/ZhangSFL20,"Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts.",https://doi.org/10.18653/v1/2020.acl-main.717,2020,ACL,"Jingyuan Zhang, Mingming Sun, Yue Feng, Ping Li 0001",Graph data,Transparent Box Design,Bayesian or Hierarchical Network,Other,Graph,Interpretability built into the predictive model,Yes,Yes
acl/ZhouZY20,Interpretable Operational Risk Classification with Semi-Supervised Variational Autoencoder.,https://doi.org/10.18653/v1/2020.acl-main.78,2020,ACL,"Fan Zhou, Shengming Zhang, Yi Yang",Text,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Interpretability built into the predictive model,Yes,Yes
cvpr/ChengRCZ20,Explaining Knowledge Distillation by Quantifying the Knowledge.,https://doi.org/10.1109/CVPR42600.2020.01294,2020,CVPR,"Xu Cheng, Zhefan Rao, Yilan Chen, Quanshi Zhang",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Localization",Post-hoc explanation method,Yes,Yes
cvpr/HuangL20,Interpretable and Accurate Fine-grained Recognition via Region Grouping.,https://doi.org/10.1109/CVPR42600.2020.00869,2020,CVPR,"Zixuan Huang, Yin Li",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Localization",Interpretability built into the predictive model,Yes,Yes
cvpr/JakabGBV20,Self-Supervised Learning of Interpretable Keypoints From Unlabelled Videos.,https://doi.org/10.1109/CVPR42600.2020.00881,2020,CVPR,"Tomas Jakab, Ankush Gupta 0001, Hakan Bilen, Andrea Vedaldi","Images, Video",Outcome Explanation,(Deep) Neural Network,Other,"Disentanglement, Localization",Interpretability built into the predictive model,Yes,Yes
cvpr/JalwanaABM20,Attack to Explain Deep Representation.,https://doi.org/10.1109/CVPR42600.2020.00956,2020,CVPR,"Mohammad A. A. K. Jalwana, Naveed Akhtar, Mohammed Bennamoun, Ajmal Mian",Images,Model Inspection,(Deep) Neural Network,Classification,Representation Synthesis,Post-hoc explanation method,Yes,Yes
cvpr/KimGPS20,A Programmatic and Semantic Approach to Explaining and Debugging Neural Network Based Object Detectors.,https://doi.org/10.1109/CVPR42600.2020.01114,2020,CVPR,"Edward Kim, Divya Gopinath, Corina S. Pasareanu, Sanjit A. Seshia",Images,"Model Explanation, Outcome Explanation",(Deep) Neural Network,Classification,Decision Rules,Post-hoc explanation method,Yes,Yes
cvpr/LiuLZKWBRC20,Towards Visually Explaining Variational Autoencoders.,https://doi.org/10.1109/CVPR42600.2020.00867,2020,CVPR,"WenQian Liu, Runze Li, Meng Zheng, Srikrishna Karanam, Ziyan Wu, Bir Bhanu, Richard J. Radke, Octavia I. Camps",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Generation,"Disentanglement, Heatmap",Interpretability built into the predictive model,Yes,Yes
cvpr/ShenGTZ20,Interpreting the Latent Space of GANs for Semantic Face Editing.,https://doi.org/10.1109/CVPR42600.2020.00926,2020,CVPR,"Yujun Shen, Jinjin Gu, Xiaoou Tang, Bolei Zhou",Images,Model Inspection,(Deep) Neural Network,Generation,Disentanglement,Post-hoc explanation method,Yes,Yes
cvpr/WangV20,SCOUT - Self-Aware Discriminant Counterfactual Explanations.,https://doi.org/10.1109/CVPR42600.2020.00900,2020,CVPR,"Pei Wang, Nuno Vasconcelos",Images,Outcome Explanation,(Deep) Neural Network,Classification,Localization,Post-hoc explanation method,Yes,Yes
cvpr/WuSCZKLT20a,Towards Global Explanations of Convolutional Neural Networks With Concept Attribution.,https://doi.org/10.1109/CVPR42600.2020.00868,2020,CVPR,"Weibin Wu, Yuxin Su, Xixian Chen, Shenglin Zhao, Irwin King, Michael R. Lyu, Yu-Wing Tai",Images,Model Inspection,(Deep) Neural Network,Classification,"Feature Importance, Representation Synthesis",Post-hoc explanation method,Yes,Yes
cvpr/XuYGLWLV20,Explainable Object-Induced Action Decision for Autonomous Vehicles.,https://doi.org/10.1109/CVPR42600.2020.00954,2020,CVPR,"Yiran Xu, Xiaoyin Yang, Lihang Gong, Hsuan-Chu Lin, Tz-Ying Wu, Yunsheng Li, Nuno Vasconcelos",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Text",Supervised explanation training,Yes,Yes
icdm/JiWJMZ20,Interpretable Spatiotemporal Deep Learning Model for Traffic Flow Prediction based on Potential Energy Fields.,https://doi.org/10.1109/ICDM50108.2020.00128,2020,ICDM,"Jiahao Ji, Jingyuan Wang, Zhe Jiang 0001, Jingtian Ma, Hu Zhang",Time series,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Interpretability built into the predictive model,Yes,Yes
iclr/JinWDXR20,Towards Hierarchical Importance Attribution - Explaining Compositional Semantics for Neural Sequence Models.,https://openreview.net/forum?id=BkxRRkSKwr,2020,ICLR,"Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, Xiang Ren 0001",Text,Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,"Feature Importance, Graph",Post-hoc explanation method,Yes,Yes
iclr/MohanKSF20,Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks.,https://openreview.net/forum?id=HJlSmC4FPS,2020,ICLR,"Sreyas Mohan, Zahra Kadkhodaie, Eero P. Simoncelli, Carlos Fernandez-Granda",Images,Model Inspection,(Deep) Neural Network,Other,"Representation Synthesis, Other",Post-hoc explanation method,Yes,Yes
iclr/OreshkinCCB20,N-BEATS - Neural basis expansion analysis for interpretable time series forecasting.,https://openreview.net/forum?id=r1ecqn4YwB,2020,ICLR,"Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio",Time series,Model Inspection,(Deep) Neural Network,Regression,Feature plot,Interpretability built into the predictive model,Yes,Yes
iclr/PuriVGKDK020,Explain Your Move - Understanding Agent Actions Using Specific and Relevant Feature Attribution.,https://openreview.net/forum?id=SJgzLkBKPB,2020,ICLR,"Nikaash Puri, Sukriti Verma, Piyush Gupta, Dhruv Kayastha, Shripad Deshmukh, Balaji Krishnamurthy, Sameer Singh 0001","Images, Other",Outcome Explanation,(Deep) Neural Network,Policy learning,Heatmap,Post-hoc explanation method,Yes,Yes
iclr/SinglaPCB20,Explanation by Progressive Exaggeration.,https://openreview.net/forum?id=H1xFWgrFPS,2020,ICLR,"Sumedha Singla, Brian Pollack, Junxiang Chen, Kayhan Batmanghelich","Images, Any",Outcome Explanation,(Deep) Neural Network,Classification,"Representation Synthesis, Representation Visualization, Heatmap",Post-hoc explanation method,Yes,Yes
iclr/YangS20,Learn to Explain Efficiently via Neural Logic Inductive Learning.,https://openreview.net/forum?id=SJlh8CEYDB,2020,ICLR,"Yuan Yang, Le Song","Images, Graph data","Model Inspection, Outcome Explanation","(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Decision Rules,Post-hoc explanation method,Yes,Yes
icml/AndersPDMK20,Fairwashing explanations with off-manifold detergent.,http://proceedings.mlr.press/v119/anders20a.html,2020,ICML,"Christopher J. Anders, Plamen Pasliev, Ann-Kathrin Dombrowski, Klaus-Robert Müller, Pan Kessel","Tabular / structured, Images",Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic, Logistic Regression",Classification,"Feature Importance, Heatmap","Post-hoc explanation method, Supervised explanation training",Yes,Yes
icml/ChalasaniC00J20,Concise Explanations of Neural Networks using Adversarial Training.,http://proceedings.mlr.press/v119/chalasani20a.html,2020,ICML,"Prasad Chalasani, Jiefeng Chen, Amrita Roy Chowdhury 0001, Xi Wu 0001, Somesh Jha","Tabular / structured, Images",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Heatmap",Post-hoc explanation method,Yes,Yes
icml/ChaudharySG20,Explainable and Discourse Topic-aware Neural Language Understanding.,http://proceedings.mlr.press/v119/chaudhary20a.html,2020,ICML,"Yatin Chaudhary, Hinrich Schütze, Pankaj Gupta",Text,Outcome Explanation,(Deep) Neural Network,"Classification, Retrieval",Other,Supervised explanation training,Yes,Yes
icml/JinBJ20a,Multi-Objective Molecule Generation using Interpretable Substructures.,http://proceedings.mlr.press/v119/jin20b.html,2020,ICML,"Wengong Jin, Regina Barzilay, Tommi S. Jaakkola",Graph data,Transparent Box Design,(Deep) Neural Network,Generation,Prototypes,Interpretability built into the predictive model,Yes,Yes
icml/LakkarajuAB20,Robust and Stable Black Box Explanations.,http://proceedings.mlr.press/v119/lakkaraju20a.html,2020,ICML,"Himabindu Lakkaraju, Nino Arsov, Osbert Bastani",Tabular / structured,Model Explanation,"(Deep) Neural Network, Tree Ensemble, Support Vector Machine, Any (for a specific task); model-agnostic",Classification,"Decision Rules, White-box model",Post-hoc explanation method,Yes,Yes
icml/MoshkovitzDRF20,Explainable k-Means and k-Medians Clustering.,http://proceedings.mlr.press/v119/moshkovitz20a.html,2020,ICML,"Michal Moshkovitz, Sanjoy Dasgupta, Cyrus Rashtchian, Nave Frost",Tabular / structured,Transparent Box Design,Other,Clustering,Decision Tree,Interpretability built into the predictive model,Yes,Yes
icml/ParkCZYY20,Multiresolution Tensor Learning for Efficient and Interpretable Spatial Analysis.,http://proceedings.mlr.press/v119/park20a.html,2020,ICML,"Jung Yeon Park, Kenneth Theo Carr, Stephan Zheng, Yisong Yue, Rose Yu","Tabular / structured, Images",Model Inspection,(Deep) Neural Network,"Classification, Regression",Heatmap,Post-hoc explanation method,Yes,Yes
icml/PlumbTST20,Explaining Groups of Points in Low-Dimensional Representations.,http://proceedings.mlr.press/v119/plumb20a.html,2020,ICML,"Gregory Plumb, Jonathan Terhorst, Sriram Sankararaman, Ameet Talwalkar",Tabular / structured,Model Inspection,(Deep) Neural Network,Representation learning,"Feature Importance, Representation Visualization",Post-hoc explanation method,Yes,Yes
icml/QuinnNR0V20,DeepCoDA - personalized interpretability for compositional health data.,http://proceedings.mlr.press/v119/quinn20a.html,2020,ICML,"Thomas P. Quinn, Dang Nguyen, Santu Rana, Sunil Gupta 0001, Svetha Venkatesh",Tabular / structured,Transparent Box Design,(Deep) Neural Network,Classification,White-box model,Interpretability built into the predictive model,Yes,Yes
icml/ShiZM020,Dispersed Exponential Family Mixture VAEs for Interpretable Text Generation.,http://proceedings.mlr.press/v119/shi20f.html,2020,ICML,"Wenxian Shi, Hao Zhou, Ning Miao, Lei Li 0005",Text,Model Inspection,(Deep) Neural Network,Generation,Disentanglement,Interpretability built into the predictive model,Yes,Yes
icml/VoynovB20,Unsupervised Discovery of Interpretable Directions in the GAN Latent Space.,http://proceedings.mlr.press/v119/voynov20a.html,2020,ICML,"Andrey Voynov, Artem Babenko",Images,Model Inspection,(Deep) Neural Network,Generation,Disentanglement,Post-hoc explanation method,Yes,Yes
ijcai/AlbiniRBT20,Relation-Based Counterfactual Explanations for Bayesian Network Classifiers.,https://doi.org/10.24963/ijcai.2020/63,2020,IJCAI,"Emanuele Albini, Antonio Rago 0001, Pietro Baroni, Francesca Toni",Tabular / structured,Outcome Explanation,Bayesian or Hierarchical Network,Classification,Graph,Post-hoc explanation method,Yes,Yes
ijcai/BeyazitTYT020,Learning Interpretable Representations with Informative Entanglements.,https://doi.org/10.24963/ijcai.2020/273,2020,IJCAI,"Ege Beyazit, Doruk Tuncel, Xu Yuan, Nian-Feng Tzeng, Xindong Wu 0001",Images,Model Inspection,"(Deep) Neural Network, Any (for a specific task); model-agnostic","Representation learning, Generation",Disentanglement,Interpretability built into the predictive model,Yes,Yes
ijcai/ChenW0PSAC20,Towards Explainable Conversational Recommendation.,https://doi.org/10.24963/ijcai.2020/414,2020,IJCAI,"Zhongxia Chen, Xiting Wang, Xing Xie 0001, Mehul Parsana, Akshay Soni, Xiang Ao, Enhong Chen",User-item matrix,Outcome Explanation,"(Deep) Neural Network, Other",Recommendation,Text,Post-hoc explanation method,Yes,Yes
ijcai/CiravegnaGGMM20,Human-Driven FOL Explanations of Deep Learning.,https://doi.org/10.24963/ijcai.2020/309,2020,IJCAI,"Gabriele Ciravegna, Francesco Giannini, Marco Gori, Marco Maggini, Stefano Melacci",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,Decision Rules,Interpretability built into the predictive model,Yes,Yes
ijcai/KanamoriTKA20,DACE - Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization.,https://doi.org/10.24963/ijcai.2020/395,2020,IJCAI,"Kentaro Kanamori, Takuya Takagi, Ken Kobayashi, Hiroki Arimura",Tabular / structured,Outcome Explanation,"Any (for a specific task); model-agnostic, Support Vector Machine, Tree Ensemble",Classification,Prototypes,Post-hoc explanation method,Yes,Yes
ijcai/LeL20,Synthesizing Aspect-Driven Recommendation Explanations from Reviews.,https://doi.org/10.24963/ijcai.2020/336,2020,IJCAI,"Trung-Hoang Le, Hady W. Lauw",User-item matrix,Outcome Explanation,Other,Recommendation,Text,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
ijcai/LiFCLYS20,Recurrent Dirichlet Belief Networks for interpretable Dynamic Relational Data Modelling.,https://doi.org/10.24963/ijcai.2020/342,2020,IJCAI,"Yaqiong Li, Xuhui Fan, Ling Chen, Bin Li, Zheng Yu, Scott A. Sisson",Graph data,Transparent Box Design,Bayesian or Hierarchical Network,Classification,White-box model,Interpretability built into the predictive model,Yes,Yes
ijcai/RosaCN20,Explainable Inference on Sequential Data via Memory-Tracking.,https://doi.org/10.24963/ijcai.2020/278,2020,IJCAI,"Biagio La Rosa, Roberto Capobianco, Daniele Nardi",Other,Outcome Explanation,(Deep) Neural Network,Policy learning,Feature Importance,Post-hoc explanation method,Yes,Yes
ijcai/WangZ20a,Interpretable Multimodal Learning for Intelligent Regulation in Online Payment Systems.,https://doi.org/10.24963/ijcai.2020/645,2020,IJCAI,"Shuoyao Wang, Diwei Zhu","Tabular / structured, Text","Model Inspection, Outcome Explanation",(Deep) Neural Network,Retrieval,"Feature Importance, Feature plot",Post-hoc explanation method,Yes,Yes
ijcai/WuRYWN20,Evidence-Aware Hierarchical Interactive Attention Networks for Explainable Claim Verification.,https://doi.org/10.24963/ijcai.2020/193,2020,IJCAI,"Lianwei Wu, Yuan Rao, Xiong Yang, Wanzhen Wang, Ambreen Nazir","Text, Graph data, Other",Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
kdd/GuoZQWSY20,Interpretable Deep Graph Generation with Node-edge Co-disentanglement.,https://doi.org/10.1145/3394486.3403221,2020,KDD,"Xiaojie Guo, Liang Zhao 0002, Zhao Qin, Lingfei Wu, Amarda Shehu, Yanfang Ye",Graph data,Model Inspection,(Deep) Neural Network,"Generation, Representation learning",Disentanglement,Interpretability built into the predictive model,Yes,Yes
kdd/LancianoBG20,Explainable Classification of Brain Networks via Contrast Subgraphs.,https://doi.org/10.1145/3394486.3403383,2020,KDD,"Tommaso Lanciano, Francesco Bonchi, Aristides Gionis","Images, Graph data",Model Inspection,Bayesian or Hierarchical Network,Classification,"Feature plot, Graph, Localization",Interpretability built into the predictive model,Yes,Yes
kdd/LeW020,GRACE - Generating Concise and Informative Contrastive Sample to Explain Neural Network Model's Prediction.,https://doi.org/10.1145/3394486.3403066,2020,KDD,"Thai Le, Suhang Wang, Dongwon Lee 0001",Tabular / structured,Outcome Explanation,(Deep) Neural Network,Classification,Text,Post-hoc explanation method,Yes,Yes
kdd/LiangBCBW20,Adversarial Infidelity Learning for Model Interpretation.,https://doi.org/10.1145/3394486.3403071,2020,KDD,"Jian Liang, Bing Bai, Yuren Cao, Kun Bai, Fei Wang","Images, Text, Time series, Any",Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Localization,Post-hoc explanation method,Yes,Yes
kdd/TangLSSMW20,"Knowing your FATE - Friendship, Action and Temporal Explanations for User Engagement Prediction on Social Apps.",https://doi.org/10.1145/3394486.3403276,2020,KDD,"Xianfeng Tang, Yozen Liu, Neil Shah, Xiaolin Shi, Prasenjit Mitra, Suhang Wang",Graph data,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Feature Importance, Heatmap",Interpretability built into the predictive model,Yes,Yes
kdd/YuanTHJ20,XGNN - Towards Model-Level Explanations of Graph Neural Networks.,https://doi.org/10.1145/3394486.3403085,2020,KDD,"Hao Yuan, Jiliang Tang, Xia Hu, Shuiwang Ji",Graph data,Model Inspection,(Deep) Neural Network,Classification,Prototypes,Post-hoc explanation method,Yes,Yes
kdd/ZhangQ0LCZD20,INPREM - An Interpretable and Trustworthy Predictive Model for Healthcare.,https://doi.org/10.1145/3394486.3403087,2020,KDD,"Xianli Zhang, Buyue Qian, Shilei Cao 0001, Yang Li, Hang Chen, Yefeng Zheng, Ian Davidson","Tabular / structured, Time series",Outcome Explanation,(Deep) Neural Network,Classification,Feature plot,Interpretability built into the predictive model,Yes,Yes
nips/0001GCIN20,Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay.,https://proceedings.neurips.cc/paper/2020/hash/eccd2a86bae4728b38627162ba297828-Abstract.html,2020,NeurIPS,"João Marques-Silva 0001, Thomas Gerspacher, Martin C. Cooper, Alexey Ignatiev, Nina Narodytska",Tabular / structured,"Model Inspection, Outcome Explanation",Bayesian or Hierarchical Network,Classification,Localization,Post-hoc explanation method,Yes,Yes
nips/ArikLYSELM0ZNSN20,Interpretable Sequence Learning for Covid-19 Forecasting.,https://proceedings.neurips.cc/paper/2020/hash/d9dbc51dc534921589adf460c85cd824-Abstract.html,2020,NeurIPS,"Sercan Ömer Arik, Chun-Liang Li, Jinsung Yoon, Rajarishi Sinha, Arkady Epshteyn, Long T. Le, Vikas Menon, Shashank Singh 0005, Leyou Zhang, Martin Nikoltchev, Yash Sonthalia, Hootan Nakhost, Elli Kanal, Tomas Pfister",Time series,Transparent Box Design,(Deep) Neural Network,Regression,White-box model,Interpretability built into the predictive model,Yes,Yes
nips/BassSSTSR20,ICAM - Interpretable Classification via Disentangled Representations and Feature Attribution Mapping.,https://proceedings.neurips.cc/paper/2020/hash/56f9f88906aebf4ad985aaec7fa01313-Abstract.html,2020,NeurIPS,"Cher Bass, Mariana da Silva, Carole H. Sudre, Petru-Daniel Tudosiu, Stephen M. Smith, Emma C. Robinson",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,"Classification, Representation learning",Heatmap,Post-hoc explanation method,Yes,Yes
nips/CrabbeZZS20,Learning outside the Black-Box - The pursuit of interpretable models.,https://proceedings.neurips.cc/paper/2020/hash/ce758408f6ef98d7c7a7b786eca7b3a8-Abstract.html,2020,NeurIPS,"Jonathan Crabbé, Yao Zhang, William R. Zame, Mihaela van der Schaar",Tabular / structured,Model Explanation,"(Deep) Neural Network, Support Vector Machine, Any (for a specific task); model-agnostic",Classification,Feature Importance,Post-hoc explanation method,Yes,Yes
nips/FryeRF20,Asymmetric Shapley values - incorporating causal knowledge into model-agnostic explainability.,https://proceedings.neurips.cc/paper/2020/hash/0d770c496aa3da6d2c3f2bd19e7b9d6b-Abstract.html,2020,NeurIPS,"Christopher Frye, Colin Rowat, Ilya Feige","Tabular / structured, Time series, Any","Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,Feature Importance,Post-hoc explanation method,Yes,Yes
nips/HarkonenHLP20,GANSpace - Discovering Interpretable GAN Controls.,https://proceedings.neurips.cc/paper/2020/hash/6fe43269967adbb64ec6149852b5cc3e-Abstract.html,2020,NeurIPS,"Erik Härkönen, Aaron Hertzmann, Jaakko Lehtinen, Sylvain Paris",Images,Model Inspection,(Deep) Neural Network,Generation,"Disentanglement, Representation Synthesis",Post-hoc explanation method,Yes,Yes
nips/HeskesSBC20,Causal Shapley Values - Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models.,https://proceedings.neurips.cc/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html,2020,NeurIPS,"Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, Tom Claassen","Time series, Any",Outcome Explanation,Any (for a specific task); model-agnostic,"Classification, Regression",Feature Importance,Post-hoc explanation method,Yes,Yes
nips/JainVMLTH20,Interpretable multi-timescale models for predicting fMRI responses to continuous natural speech.,https://proceedings.neurips.cc/paper/2020/hash/9e9a30b74c49d07d8150c8c83b1ccf07-Abstract.html,2020,NeurIPS,"Shailee Jain, Vy A. Vo, Shivangi Mahto, Amanda LeBel, Javier S. Turek, Alexander Huth",Time series,Outcome Explanation,(Deep) Neural Network,"Classification, Regression",Heatmap,Interpretability built into the predictive model,Yes,Yes
nips/LuoCXYZC020,Parameterized Explainer for Graph Neural Network.,https://proceedings.neurips.cc/paper/2020/hash/e37b08dd3015330dcbb5d6663667b8b8-Abstract.html,2020,NeurIPS,"Dongsheng Luo, Wei Cheng 0002, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng Chen, Xiang Zhang 0001",Graph data,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Graph, Feature Importance",Post-hoc explanation method,Yes,Yes
nips/MuA20,Compositional Explanations of Neurons.,https://proceedings.neurips.cc/paper/2020/hash/c74956ffb38ba48ed6ce977af6727275-Abstract.html,2020,NeurIPS,"Jesse Mu, Jacob Andreas","Images, Text",Model Inspection,(Deep) Neural Network,Classification,"Decision Rules, Localization",Post-hoc explanation method,Yes,Yes
nips/OShaughnessyCCR20,Generative causal explanations of black-box classifiers.,https://proceedings.neurips.cc/paper/2020/hash/3a93a609b97ec0ab0ff5539eb79ef33a-Abstract.html,2020,NeurIPS,"""Matthew R. OShaughnessy"", Gregory Canal, Marissa Connor, Christopher Rozell, Mark A. Davenport","Images, Any","Model Inspection, Outcome Explanation",Any (for a specific task); model-agnostic,Classification,"Disentanglement, Graph, Representation Synthesis",Post-hoc explanation method,Yes,Yes
nips/PedapatiBSD20,Learning Global Transparent Models consistent with Local Contrastive Explanations.,https://proceedings.neurips.cc/paper/2020/hash/24aef8cb3281a2422a59b51659f1ad2e-Abstract.html,2020,NeurIPS,"Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar",Tabular / structured,Model Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Decision Tree,Post-hoc explanation method,Yes,Yes
nips/RamamurthyVZD20,Model Agnostic Multilevel Explanations.,https://proceedings.neurips.cc/paper/2020/hash/426f990b332ef8193a61cc90516c1245-Abstract.html,2020,NeurIPS,"Karthikeyan Natesan Ramamurthy, Bhanukiran Vinzamuri, Yunfeng Zhang, Amit Dhurandhar",Tabular / structured,"Model Inspection, Outcome Explanation","(Deep) Neural Network, Tree Ensemble, Any (for a specific task); model-agnostic","Classification, Regression",Feature Importance,Post-hoc explanation method,Yes,Yes
nips/RawalL20,Beyond Individualized Recourse - Interpretable and Interactive Summaries of Actionable Recourses.,https://proceedings.neurips.cc/paper/2020/hash/8ee7730e97c67473a424ccfeff49ab20-Abstract.html,2020,NeurIPS,"Kaivalya Rawal, Himabindu Lakkaraju",Tabular / structured,Model Explanation,"(Deep) Neural Network, Tree Ensemble, Any (for a specific task); model-agnostic, Logistic Regression",Classification,Decision Rules,Post-hoc explanation method,Yes,Yes
nips/TsangR020,How does This Interaction Affect Me? Interpretable Attribution for Feature Interactions.,https://proceedings.neurips.cc/paper/2020/hash/443dec3062d0286986e21dc0631734c9-Abstract.html,2020,NeurIPS,"Michael Tsang, Sirisha Rambhatla, Yan Liu 0002","Images, Text, Any",Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Post-hoc explanation method,Yes,Yes
nips/TsengSK20,Fourier-transform-based attribution priors improve the interpretability and stability of deep learning models for genomics.,https://proceedings.neurips.cc/paper/2020/hash/1487987e862c44b91a0296cf3866387e-Abstract.html,2020,NeurIPS,"Alex Tseng, Avanti Shrikumar, Anshul Kundaje","Any, Other",Outcome Explanation,Other,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
nips/Yau0H20,What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes.,https://proceedings.neurips.cc/paper/2020/hash/d5ab8dc7ef67ca92e41d730982c5c602-Abstract.html,2020,NeurIPS,"Herman Yau, Chris Russell 0001, Simon Hadfield",Other,Outcome Explanation,Other,Policy learning,Heatmap,Post-hoc explanation method,Yes,Yes
nips/YehKALPR20,On Completeness-aware Concept-Based Explanations in Deep Neural Networks.,https://proceedings.neurips.cc/paper/2020/hash/ecb287ff763c169694f682af52c1f309-Abstract.html,2020,NeurIPS,"Chih-Kuan Yeh, Been Kim, Sercan Ömer Arik, Chun-Liang Li, Tomas Pfister, Pradeep Ravikumar","Images, Text, Any",Model Inspection,(Deep) Neural Network,Classification,"Feature Importance, Prototypes",Post-hoc explanation method,Yes,Yes
nips/ZhouW20,Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE.,https://proceedings.neurips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html,2020,NeurIPS,"Ding Zhou, Xue-Xin Wei",Time series,Outcome Explanation,(Deep) Neural Network,Other,"Representation Visualization, Feature plot",Interpretability built into the predictive model,Yes,Yes
sigir/ChenYYH0020,Try This Instead - Personalized and Interpretable Substitute Recommendation.,https://doi.org/10.1145/3397271.3401042,2020,SIGIR,"Tong Chen 0005, Hongzhi Yin, Guanhua Ye, Zi Huang, Yang Wang 0023, Meng Wang 0001","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,"Feature Importance, Text",Interpretability built into the predictive model,Yes,Yes
sigir/QuAW20,Towards Explainable Retrieval Models for Precision Medicine Literature Search.,https://doi.org/10.1145/3397271.3401277,2020,SIGIR,"Jiaming Qu, Jaime Arguello, Yue Wang 0035",Text,Transparent Box Design,Other,Retrieval,Decision Tree,Interpretability built into the predictive model,Yes,Yes
sigir/YangZWL020,Neural Concept Map Generation for Effective Document Classification with Interpretable Structured Summarization.,https://doi.org/10.1145/3397271.3401312,2020,SIGIR,"Carl Yang, Jieyu Zhang, Haonan Wang, Bangzheng Li, Jiawei Han 0001",Text,Outcome Explanation,(Deep) Neural Network,Classification,"Graph, Text",Interpretability built into the predictive model,Yes,Yes
www/LiJC0WL20,Directional and Explainable Serendipity Recommendation.,https://doi.org/10.1145/3366423.3380100,2020,WWW,"Xueqi Li, Wenjun Jiang, Weiguang Chen, Jie Wu 0001, Guojun Wang 0001, Kenli Li 0001",User-item matrix,Outcome Explanation,(Deep) Neural Network,Recommendation,"Localization, Text",Post-hoc explanation method,Yes,Yes
www/MathewSLS20,The POLAR Framework - Polar Opposites Enable Interpretability of Pre-Trained Word Embeddings.,https://doi.org/10.1145/3366423.3380227,2020,WWW,"Binny Mathew, Sandipan Sikdar, Florian Lemmerich, Markus Strohmaier",Text,Outcome Explanation,"Tree Ensemble, Any (for a specific task); model-agnostic",Classification,Disentanglement,Post-hoc explanation method,Yes,Yes
www/NaumzikZF20,Mining Points-of-Interest for Explaining Urban Phenomena - A Scalable Variational Inference Approach.,https://doi.org/10.1145/3366423.3380298,2020,WWW,"Christof Naumzik, Patrick Zoechbauer, Stefan Feuerriegel",Other,Transparent Box Design,Other,Other,"Feature Importance, Feature plot, Heatmap",Interpretability built into the predictive model,Yes,Yes
www/PawelczykBK20,Learning Model-Agnostic Counterfactual Explanations for Tabular Data.,https://doi.org/10.1145/3366423.3380087,2020,WWW,"Martin Pawelczyk, Klaus Broelemann, Gjergji Kasneci",Tabular / structured,Outcome Explanation,"Any (for a specific task); model-agnostic, Logistic Regression",Classification,Representation Synthesis,Post-hoc explanation method,Yes,Yes
www/SunWZFHW20,Dual Learning for Explainable Recommendation - Towards Unifying User Preference Prediction and Review Generation.,https://doi.org/10.1145/3366423.3380164,2020,WWW,"Peijie Sun, Le Wu, Kun Zhang, Yanjie Fu, Richang Hong, Meng Wang 0001","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,Text,Supervised explanation training,Yes,Yes
www/WangZZSP20,DyCRS - Dynamic Interpretable Postoperative Complication Risk Scoring.,https://doi.org/10.1145/3366423.3380253,2020,WWW,"Wen Wang, Han Zhao 0002, Honglei Zhuang, Nirav Shah, Rema Padman","Tabular / structured, Time series",Transparent Box Design,Other,Classification,White-box model,Interpretability built into the predictive model,Yes,Yes
www/ZhuXSZCGH20,Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection.,https://doi.org/10.1145/3366423.3380172,2020,WWW,"Yongchun Zhu, Dongbo Xi, Bowen Song, Fuzhen Zhuang, Shuai Chen, Xi Gu, Qing He 0003",Other,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
aaai/AnnasamyS19,Towards Better Interpretability in Deep Q-Networks.,https://doi.org/10.1609/aaai.v33i01.33014561,2019,AAAI,"Raghuram Mandyam Annasamy, Katia P. Sycara","Images, Other",Model Inspection,(Deep) Neural Network,Policy learning,"Disentanglement, Heatmap, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
aaai/ChenZQ19,Dynamic Explainable Recommendation Based on Neural Attentive Models.,https://doi.org/10.1609/aaai.v33i01.330153,2019,AAAI,"Xu Chen 0017, Yongfeng Zhang, Zheng Qin","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,Localization,Interpretability built into the predictive model,Yes,Yes
aaai/GaoWW019,Explainable Recommendation through Attentive Multi-View Learning.,https://doi.org/10.1609/aaai.v33i01.33013622,2019,AAAI,"Jingyue Gao, Xiting Wang, Yasha Wang, Xing Xie 0001","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,"Localization, Text",Interpretability built into the predictive model,Yes,Yes
aaai/HeLSB19,Interpretable Predictive Modeling for Climate Variables with Weighted Lasso.,https://doi.org/10.1609/aaai.v33i01.33011385,2019,AAAI,"Sijie He, Xinyan Li, Vidyashankar Sivakumar, Arindam Banerjee 0001",Time series,Transparent Box Design,Other,Regression,White-box model,Interpretability built into the predictive model,Yes,Yes
aaai/IgnatievNM19,Abduction-Based Explanations for Machine Learning Models.,https://doi.org/10.1609/aaai.v33i01.33011511,2019,AAAI,"Alexey Ignatiev, Nina Narodytska, João Marques-Silva 0001","Tabular / structured, Images",Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Localization,Post-hoc explanation method,Yes,Yes
aaai/LanG19,Accurate and Interpretable Factorization Machines.,https://doi.org/10.1609/aaai.v33i01.33014139,2019,AAAI,"Liang Lan, Yu Geng 0002","Tabular / structured, Text",Transparent Box Design,Other,Classification,"Feature Importance, Heatmap",Interpretability built into the predictive model,Yes,Yes
aaai/LyuYLG19,SDRL - Interpretable and Data-Efficient Deep Reinforcement Learning Leveraging Symbolic Planning.,https://doi.org/10.1609/aaai.v33i01.33012970,2019,AAAI,"Daoming Lyu, Fangkai Yang, Bo Liu, Steven Gustafson",Images,Model Inspection,(Deep) Neural Network,Policy learning,Other,Interpretability built into the predictive model,Yes,Yes
aaai/PolatoA19,Interpretable Preference Learning - A Game Theoretic Framework for Large Margin On-Line Feature and Rule Learning.,https://doi.org/10.1609/aaai.v33i01.33014723,2019,AAAI,"Mirko Polato, Fabio Aiolli","Tabular / structured, Images",Transparent Box Design,Other,Classification,"Decision Rules, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
aaai/ShakerinG19,Induction of Non-Monotonic Logic Programs to Explain Boosted Tree Models Using LIME.,https://doi.org/10.1609/aaai.v33i01.33013052,2019,AAAI,"Farhad Shakerin, Gopal Gupta","Tabular / structured, Any",Model Inspection,Tree Ensemble,Classification,Decision Rules,Post-hoc explanation method,Yes,Yes
aaai/SilvaFH19,Exploring Knowledge Graphs in an Interpretable Composite Approach for Text Entailment.,https://doi.org/10.1609/aaai.v33i01.33017023,2019,AAAI,"Vivian Dos Santos Silva, André Freitas, Siegfried Handschuh",Text,Outcome Explanation,Other,Classification,"Graph, Text",Post-hoc explanation method,Yes,Yes
aaai/TopinV19,Generation of Policy-Level Explanations for Reinforcement Learning.,https://doi.org/10.1609/aaai.v33i01.33012514,2019,AAAI,"Nicholay Topin, Manuela Veloso",Other,Outcome Explanation,Other,Policy learning,"Graph, Feature Importance",Post-hoc explanation method,Yes,Yes
aaai/WangWX00C19,Explainable Reasoning over Knowledge Graphs for Recommendation.,https://doi.org/10.1609/aaai.v33i01.33015329,2019,AAAI,"Xiang Wang 0010, Dingxian Wang, Canran Xu, Xiangnan He 0001, Yixin Cao 0002, Tat-Seng Chua","Graph data, User-item matrix",Transparent Box Design,(Deep) Neural Network,Recommendation,"Graph, Text",Interpretability built into the predictive model,Yes,Yes
aaai/WickramanayakeH19,FLEX - Faithful Linguistic Explanations for Neural Net Based Model Decisions.,https://doi.org/10.1609/aaai.v33i01.33012539,2019,AAAI,"Sandareka Wickramanayake, Wynne Hsu, Mong-Li Lee",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Text",Post-hoc explanation method,Yes,Yes
aaai/YuanCHJ19,Interpreting Deep Models for Text Analysis via Optimization and Regularization Methods.,https://doi.org/10.1609/aaai.v33i01.33015717,2019,AAAI,"Hao Yuan, Yongjun Chen, Xia Hu, Shuiwang Ji",Text,Model Inspection,(Deep) Neural Network,Classification,"Prototypes, Representation Visualization",Post-hoc explanation method,Yes,Yes
acl/BastingsAT19,Interpretable Neural Predictions with Differentiable Binary Variables.,https://doi.org/10.18653/v1/p19-1284,2019,ACL,"Jasmijn Bastings, Wilker Aziz, Ivan Titov",Text,"Outcome Explanation, Transparent Box Design",(Deep) Neural Network,"Classification, Regression","Localization, Text, White-box model",Interpretability built into the predictive model,Yes,Yes
acl/JiangJCB19,"Explore, Propose, and Assemble - An Interpretable Model for Multi-Hop Reading Comprehension.",https://doi.org/10.18653/v1/p19-1261,2019,ACL,"Yichen Jiang, Nitish Joshi, Yen-Chun Chen 0001, Mohit Bansal",Text,Transparent Box Design,(Deep) Neural Network,Question Answering,Localization,Interpretability built into the predictive model,Yes,Yes
acl/LuZXLZX19,Constructing Interpretive Spatio-Temporal Features for Multi-Turn Responses Selection.,https://doi.org/10.18653/v1/p19-1006,2019,ACL,"Junyu Lu, Chenbin Zhang, Zeying Xie, Guang Ling, Tom Chao Zhou, Zenglin Xu",Text,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Interpretability built into the predictive model,Yes,Yes
acl/MoonSKS19,OpenDialKG - Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs.,https://doi.org/10.18653/v1/p19-1081,2019,ACL,"Seungwhan Moon, Pararth Shah, Anuj Kumar, Rajen Subba",Text,Outcome Explanation,(Deep) Neural Network,Generation,Graph,Interpretability built into the predictive model,Yes,Yes
acl/PanigrahiSB19,Word2Sense - Sparse Interpretable Word Embeddings.,https://doi.org/10.18653/v1/p19-1570,2019,ACL,"Abhishek Panigrahi, Harsha Vardhan Simhadri, Chiranjib Bhattacharyya",Text,Model Inspection,"Tree Ensemble, Support Vector Machine, Any (for a specific task); model-agnostic, Logistic Regression","Classification, Representation learning, Other",Disentanglement,Interpretability built into the predictive model,Yes,Yes
acl/RajaniMXS19,Explain Yourself! Leveraging Language Models for Commonsense Reasoning.,https://doi.org/10.18653/v1/p19-1487,2019,ACL,"Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, Richard Socher",Text,Outcome Explanation,(Deep) Neural Network,Question Answering,Text,"Post-hoc explanation method, Supervised explanation training",Yes,Yes
acl/SydorovaPR19,Interpretable Question Answering on Knowledge Bases and Text.,https://doi.org/10.18653/v1/p19-1488,2019,ACL,"Alona Sydorova, Nina Pörner, Benjamin Roth 0001","Tabular / structured, Text",Outcome Explanation,(Deep) Neural Network,Question Answering,Feature Importance,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
cvpr/FukuiHYF19,Attention Branch Network - Learning of Attention Mechanism for Visual Explanation.,http://openaccess.thecvf.com/content_CVPR_2019/html/Fukui_Attention_Branch_Network_Learning_of_Attention_Mechanism_for_Visual_Explanation_CVPR_2019_paper.html,2019,CVPR,"Hiroshi Fukui, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi",Images,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Interpretability built into the predictive model,Yes,Yes
cvpr/KanehiraH19,Learning to Explain With Complemental Examples.,http://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Learning_to_Explain_With_Complemental_Examples_CVPR_2019_paper.html,2019,CVPR,"Atsushi Kanehira, Tatsuya Harada",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Prototypes, Text",Post-hoc explanation method,Yes,Yes
cvpr/KanehiraTIH19,Multimodal Explanations by Predicting Counterfactuality in Videos.,http://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Multimodal_Explanations_by_Predicting_Counterfactuality_in_Videos_CVPR_2019_paper.html,2019,CVPR,"Atsushi Kanehira, Kentaro Takemoto, Sho Inayoshi, Tatsuya Harada",Video,Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Text",Post-hoc explanation method,Yes,Yes
cvpr/PopeKRMH19,Explainability Methods for Graph Convolutional Neural Networks.,http://openaccess.thecvf.com/content_CVPR_2019/html/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.html,2019,CVPR,"Phillip E. Pope, Soheil Kolouri, Mohammad Rostami, Charles E. Martin, Heiko Hoffmann",Graph data,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
cvpr/ShiZL19,Explainable and Explicit Visual Reasoning Over Scene Graphs.,http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Explainable_and_Explicit_Visual_Reasoning_Over_Scene_Graphs_CVPR_2019_paper.html,2019,CVPR,"Jiaxin Shi, Hanwang Zhang, Juanzi Li","Images, Graph data",Outcome Explanation,(Deep) Neural Network,Question Answering,Localization,Interpretability built into the predictive model,Yes,Yes
cvpr/ZengLSSYCU19,End-To-End Interpretable Neural Motion Planner.,http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_End-To-End_Interpretable_Neural_Motion_Planner_CVPR_2019_paper.html,2019,CVPR,"Wenyuan Zeng, Wenjie Luo, Simon Suo, Abbas Sadat, Bin Yang 0021, Sergio Casas 0002, Raquel Urtasun","Time series, Other",Outcome Explanation,(Deep) Neural Network,Policy learning,Localization,Post-hoc explanation method,Yes,Yes
cvpr/ZhangYMW19,Interpreting CNNs via Decision Trees.,http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.html,2019,CVPR,"Quanshi Zhang, Yu Yang, Haotian Ma, Ying Nian Wu",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Decision Tree, Heatmap, Prototypes, Feature Importance",Post-hoc explanation method,Yes,Yes
iccv/ChenCHRZ19,Explaining Neural Networks Semantically and Quantitatively.,https://doi.org/10.1109/ICCV.2019.00928,2019,ICCV,"Runjin Chen, Hao Chen, Ge Huang, Jie Ren, Quanshi Zhang",Images,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Post-hoc explanation method,Yes,Yes
iccv/ManhardtA0BBNT19,Explaining the Ambiguity of Object Detection and 6D Pose From Visual Data.,https://doi.org/10.1109/ICCV.2019.00694,2019,ICCV,"Fabian Manhardt, Diego Martín Arroyo, Christian Rupprecht 0001, Benjamin Busam, Tolga Birdal, Nassir Navab, Federico Tombari",Images,Outcome Explanation,(Deep) Neural Network,Other,Other,Interpretability built into the predictive model,Yes,Yes
iccv/MicheliniLLJ19,A Tour of Convolutional Networks Guided by Linear Interpreters.,https://doi.org/10.1109/ICCV.2019.00485,2019,ICCV,"Pablo Navarrete Michelini, Hanwen Liu, Yunhua Lu, Xingqun Jiang",Images,Outcome Explanation,(Deep) Neural Network,"Classification, Generation","Heatmap, Representation Synthesis",Post-hoc explanation method,Yes,Yes
iccv/PatroLPN19,U-CAM - Visual Explanation Using Uncertainty Based Class Activation Maps.,https://doi.org/10.1109/ICCV.2019.00754,2019,ICCV,"Badri N. Patro, Mayank Lunayach, Shivansh Patel, Vinay Namboodiri","Images, Text",Outcome Explanation,(Deep) Neural Network,"Classification, Question Answering",Heatmap,Post-hoc explanation method,Yes,Yes
iccv/SelvarajuLSJGHB19,Taking a HINT - Leveraging Explanations to Make Vision and Language Models More Grounded.,https://doi.org/10.1109/ICCV.2019.00268,2019,ICCV,"Ramprasaath Ramasamy Selvaraju, Stefan Lee, Yilin Shen, Hongxia Jin, Shalini Ghosh, Larry P. Heck, Dhruv Batra, Devi Parikh","Images, Text",Outcome Explanation,(Deep) Neural Network,"Question Answering, Generation",Heatmap,Post-hoc explanation method,Yes,Yes
iccv/SubramanyaPP19,Fooling Network Interpretation in Image Classification.,https://doi.org/10.1109/ICCV.2019.00211,2019,ICCV,"Akshayvarun Subramanya, Vipin Pillai, Hamed Pirsiavash",Images,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
iccv/SunRS19,Adaptive Activation Thresholding - Dynamic Routing Type Behavior for Interpretability in Convolutional Neural Networks.,https://doi.org/10.1109/ICCV.2019.00504,2019,ICCV,"Yiyou Sun, Sathya N. Ravi, Vikas Singh",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Heatmap, Prototypes","Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
iccv/WuS19,Towards Interpretable Object Detection by Unfolding Latent Structures.,https://doi.org/10.1109/ICCV.2019.00613,2019,ICCV,"Tianfu Wu 0001, Xi Song",Images,Outcome Explanation,(Deep) Neural Network,Classification,Localization,Interpretability built into the predictive model,Yes,Yes
iccv/YinTLS019,Towards Interpretable Face Recognition.,https://doi.org/10.1109/ICCV.2019.00944,2019,ICCV,"Bangjie Yin, Luan Tran, Haoxiang Li, Xiaohui Shen, Xiaoming Liu 0002",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Disentanglement",Interpretability built into the predictive model,Yes,Yes
icdm/AssafGBS19,MTEX-CNN - Multivariate Time Series EXplanations for Predictions with Convolutional Neural Networks.,https://doi.org/10.1109/ICDM.2019.00106,2019,ICDM,"Roy Assaf, Ioana Giurgiu, Frank Bagehorn, Anika Schumann",Time series,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
icdm/ChenL0X19,Scalable Explanation of Inferences on Large Graphs.,https://doi.org/10.1109/ICDM.2019.00111,2019,ICDM,"Chao Chen, Yifei Liu, Xi Zhang 0008, Sihong Xie",Graph data,Outcome Explanation,(Deep) Neural Network,Classification,Decision Tree,Post-hoc explanation method,Yes,Yes
icdm/HamdiA19,Interpretable Feature Learning of Graphs using Tensor Decomposition.,https://doi.org/10.1109/ICDM.2019.00037,2019,ICDM,"Shah Muhammad Hamdi, Rafal A. Angryk",Graph data,Model Inspection,(Deep) Neural Network,Classification,"Disentanglement, Heatmap",Post-hoc explanation method,Yes,Yes
icdm/YooS19,EDiT - Interpreting Ensemble Models via Compact Soft Decision Trees.,https://doi.org/10.1109/ICDM.2019.00187,2019,ICDM,"Jaemin Yoo, Lee Sael",Tabular / structured,Transparent Box Design,Tree Ensemble,Classification,Decision Tree,Interpretability built into the predictive model,Yes,Yes
icdm/ZhangQLYWZ19,KnowRisk - An Interpretable Knowledge-Guided Model for Disease Risk Prediction.,https://doi.org/10.1109/ICDM.2019.00196,2019,ICDM,"Xianli Zhang, Buyue Qian, Yang Li, Changchang Yin, Xudong Wang, Qinghua Zheng","Tabular / structured, Graph data",Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
icdm/ZhouSC19,A Model-Agnostic Approach for Explaining the Predictions on Clustered Data.,https://doi.org/10.1109/ICDM.2019.00202,2019,ICDM,"Zihan Zhou 0003, Mingxuan Sun, Jianhua Chen 0003","User-item matrix, Other",Model Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic, Other","Classification, Regression",White-box model,Post-hoc explanation method,Yes,Yes
iclr/ChangCGD19,Explaining Image Classifiers by Counterfactual Generation.,https://openreview.net/forum?id=B1MXz20cYQ,2019,ICLR,"Chun-Hao Chang, Elliot Creager, Anna Goldenberg, David Duvenaud",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Prototypes",Post-hoc explanation method,Yes,Yes
iclr/ChenSWJ19,L-Shapley and C-Shapley - Efficient Model Interpretation for Structured Data.,https://openreview.net/forum?id=S1E3Ko09F7,2019,ICLR,"Jianbo Chen, Le Song, Martin J. Wainwright, Michael I. Jordan","Images, Text",Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,"Feature Importance, Localization",Post-hoc explanation method,Yes,Yes
iclr/FortuinHLSR19,SOM-VAE - Interpretable Discrete Representation Learning on Time Series.,https://openreview.net/forum?id=rygjcsR9Y7,2019,ICLR,"Vincent Fortuin, Matthias Hüser, Francesco Locatello, Heiko Strathmann, Gunnar Rätsch","Images, Time series",Model Inspection,(Deep) Neural Network,"Representation learning, Clustering","Representation Visualization, Representation Synthesis",Interpretability built into the predictive model,Yes,Yes
iclr/SinghMY19,Hierarchical interpretations for neural network predictions.,https://openreview.net/forum?id=SkEqro0ctQ,2019,ICLR,"Chandan Singh, W. James Murdoch, Bin Yu","Images, Text",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Graph",Post-hoc explanation method,Yes,Yes
iclr/ZhengPBH19,Revealing interpretable object representations from human behavior.,https://openreview.net/forum?id=ryxSrhC9KX,2019,ICLR,"Charles Y. Zheng, Francisco Pereira, Chris I. Baker, Martin N. Hebart",Images,Outcome Explanation,Any (for a specific task); model-agnostic,Representation learning,"Disentanglement, Feature Importance",Interpretability built into the predictive model,Yes,Yes
icml/0002LA19,Exploring interpretable LSTM neural networks over multi-variable data.,http://proceedings.mlr.press/v97/guo19b.html,2019,ICML,"Tian Guo 0002, Tao Lin, Nino Antulov-Fantulin",Time series,Model Inspection,(Deep) Neural Network,Regression,"Feature Importance, Heatmap",Interpretability built into the predictive model,Yes,Yes
icml/AnconaOG19,Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Value Approximation.,http://proceedings.mlr.press/v97/ancona19a.html,2019,ICML,"Marco Ancona, Cengiz Öztireli, Markus H. Gross","Tabular / structured, Images, Any",Outcome Explanation,(Deep) Neural Network,"Classification, Regression",Feature Importance,Post-hoc explanation method,Yes,Yes
icml/DunckerBBS19,Learning interpretable continuous-time models of latent stochastic dynamical systems.,http://proceedings.mlr.press/v97/duncker19a.html,2019,ICML,"Lea Duncker, Gergo Bohner, Julien Boussard, Maneesh Sahani",Time series,Model Inspection,Bayesian or Hierarchical Network,Regression,"Representation Visualization, Feature plot",Interpretability built into the predictive model,Yes,Yes
icml/GoyalWEBPL19,Counterfactual Visual Explanations.,http://proceedings.mlr.press/v97/goyal19a.html,2019,ICML,"Yash Goyal, Ziyan Wu, Jan Ernst, Dhruv Batra, Devi Parikh, Stefan Lee",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Prototypes, Representation Synthesis",Post-hoc explanation method,Yes,Yes
icml/SinglaWFF19,Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation.,http://proceedings.mlr.press/v97/singla19a.html,2019,ICML,"Sahil Singla 0002, Eric Wallace, Shi Feng, Soheil Feizi",Images,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
icml/VedantamDLRBP19,Probabilistic Neural Symbolic Models for Interpretable Visual Question Answering.,http://proceedings.mlr.press/v97/vedantam19a.html,2019,ICML,"Ramakrishna Vedantam, Karan Desai, Stefan Lee, Marcus Rohrbach, Dhruv Batra, Devi Parikh","Images, Text",Outcome Explanation,(Deep) Neural Network,Question Answering,Decision Rules,"Interpretability built into the predictive model, Supervised explanation training",Yes,Yes
icml/WangZB19,Bias Also Matters - Bias Attribution for Deep Neural Network Explanation.,http://proceedings.mlr.press/v97/wang19p.html,2019,ICML,"Shengjie Wang, Tianyi Zhou, Jeff A. Bilmes",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
ijcai/ChenW0WBWC19,Co-Attentive Multi-Task Learning for Explainable Recommendation.,https://doi.org/10.24963/ijcai.2019/296,2019,IJCAI,"Zhongxia Chen, Xiting Wang, Xing Xie 0001, Tong Wu, Guoqing Bu, Yining Wang, Enhong Chen","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,Text,Supervised explanation training,Yes,Yes
ijcai/FuscoVVWS19,RecoNet - An Interpretable Neural Architecture for Recommender Systems.,https://doi.org/10.24963/ijcai.2019/325,2019,IJCAI,"Francesco Fusco, Michalis Vlachos, Vasileios Vasileiadis, Kathrin Wardatzky, Johannes Schneider",User-item matrix,Outcome Explanation,(Deep) Neural Network,Recommendation,Feature Importance,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
ijcai/HouWCLZL19,Explainable Fashion Recommendation - A Semantic Attribute Region Guided Approach.,https://doi.org/10.24963/ijcai.2019/650,2019,IJCAI,"Min Hou, Le Wu, Enhong Chen, Zhi Li, Vincent W. Zheng, Qi Liu 0003",Images,Outcome Explanation,(Deep) Neural Network,"Classification, Recommendation","Feature Importance, Heatmap, Localization, Prototypes, Text",Interpretability built into the predictive model,Yes,Yes
ijcai/KennyK19,Twin-Systems to Explain Artificial Neural Networks using Case-Based Reasoning - Comparative Tests of Feature-Weighting Methods in ANN-CBR Twins for XAI.,https://doi.org/10.24963/ijcai.2019/376,2019,IJCAI,"Eoin M. Kenny, Mark T. Keane","Tabular / structured, Images, Any","Model Explanation, Outcome Explanation",(Deep) Neural Network,"Classification, Regression",Prototypes,Post-hoc explanation method,Yes,Yes
ijcai/LiYYJ19,Learning Interpretable Deep State Space Model for Probabilistic Time Series Forecasting.,https://doi.org/10.24963/ijcai.2019/402,2019,IJCAI,"Longyuan Li, Junchi Yan, Xiaokang Yang, Yaohui Jin",Time series,Model Inspection,(Deep) Neural Network,Regression,Feature Importance,Interpretability built into the predictive model,Yes,Yes
ijcai/ZhangR19,Learning Interpretable Relational Structures of Hinge-loss Markov Random Fields.,https://doi.org/10.24963/ijcai.2019/838,2019,IJCAI,"Yue Zhang, Arti Ramesh",Text,Transparent Box Design,Other,"Policy learning, Classification",Decision Rules,Interpretability built into the predictive model,Yes,Yes
kdd/ChengSHZ19,Incorporating Interpretability into Latent Factor Models via Fast Influence Analysis.,https://doi.org/10.1145/3292500.3330857,2019,KDD,"Weiyu Cheng, Yanyan Shen, Linpeng Huang, Yanmin Zhu",User-item matrix,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Post-hoc explanation method,Yes,Yes
kdd/Jia0RLH19,Improving the Quality of Explanations with Local Embedding Perturbations.,https://doi.org/10.1145/3292500.3330930,2019,KDD,"Yunzhe Jia, James Bailey 0001, Kotagiri Ramamohanarao, Christopher Leckie, Michael E. Houle",Tabular / structured,Outcome Explanation,"Tree Ensemble, Any (for a specific task); model-agnostic",Classification,"Feature Importance, Localization",Post-hoc explanation method,Yes,Yes
kdd/MingXQR19,Interpretable and Steerable Sequence Learning via Prototypes.,https://doi.org/10.1145/3292500.3330908,2019,KDD,"Yao Ming, Panpan Xu, Huamin Qu, Liu Ren","Text, Time series, Other","Outcome Explanation, Transparent Box Design",(Deep) Neural Network,Classification,Prototypes,Interpretability built into the predictive model,Yes,Yes
kdd/ShuCW0L19,dEFEND - Explainable Fake News Detection.,https://doi.org/10.1145/3292500.3330935,2019,KDD,"Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee 0001, Huan Liu 0001",Text,Outcome Explanation,(Deep) Neural Network,Classification,Text,Interpretability built into the predictive model,Yes,Yes
kdd/Tao0WFYZ019,Log2Intent - Towards Interpretable User Modeling via Recurrent Semantics Memory Unit.,https://doi.org/10.1145/3292500.3330889,2019,KDD,"Zhiqiang Tao, Sheng Li 0001, Zhaowen Wang, Chen Fang, Longqi Yang, Handong Zhao, Yun Fu 0001",Time series,Outcome Explanation,(Deep) Neural Network,Classification,Text,"Interpretability built into the predictive model, Supervised explanation training",Yes,Yes
kdd/YanZDSSK19,"GroupINN - Grouping-based Interpretable Neural Network for Classification of Limited, Noisy Brain Data.",https://doi.org/10.1145/3292500.3330921,2019,KDD,"Yujun Yan, Jiong Zhu, Marlena Duda, Eric Solarz, Chandra Sekhar Sripada, Danai Koutra","Images, Time series",Outcome Explanation,(Deep) Neural Network,Classification,"Graph, Heatmap",Interpretability built into the predictive model,Yes,Yes
kdd/YoshidaTK19,Learning Interpretable Metric between Graphs - Convex Formulation and Computation with Graph Mining.,https://doi.org/10.1145/3292500.3330845,2019,KDD,"Tomoki Yoshida, Ichiro Takeuchi, Masayuki Karasuyama",Graph data,Transparent Box Design,Other,Representation learning,"Feature Importance, Localization, Graph",Interpretability built into the predictive model,Yes,Yes
kdd/ZhangTKLCC19,Axiomatic Interpretability for Multiclass Additive Models.,https://doi.org/10.1145/3292500.3330898,2019,KDD,"Xuezhou Zhang, Sarah Tan, Paul Koch, Yin Lou, Urszula Chajewska, Rich Caruana",Tabular / structured,Model Inspection,Other,Classification,Feature plot,Post-hoc explanation method,Yes,Yes
kdd/ZhaoGS19,Riker - Mining Rich Keyword Representations for Interpretable Product Question Answering.,https://doi.org/10.1145/3292500.3330985,2019,KDD,"Jie Zhao, Ziyu Guan, Huan Sun",Text,Outcome Explanation,(Deep) Neural Network,Question Answering,Feature Importance,Interpretability built into the predictive model,Yes,Yes
nips/ChenLTBRS19,This Looks Like That - Deep Learning for Interpretable Image Recognition.,https://proceedings.neurips.cc/paper/2019/hash/adf7ee2dcf142b0e11888e72b43fcb75-Abstract.html,2019,NeurIPS,"Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, Jonathan Su",Images,Transparent Box Design,(Deep) Neural Network,Classification,Prototypes,Interpretability built into the predictive model,Yes,Yes
nips/GhorbaniWZK19,Towards Automatic Concept-based Explanations.,https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html,2019,NeurIPS,"Amirata Ghorbani, James Wexler, James Y. Zou, Been Kim",Images,Model Inspection,(Deep) Neural Network,Classification,"Prototypes, Localization, Feature Importance",Post-hoc explanation method,Yes,Yes
nips/HoyerMKKF19,Grid Saliency for Context Explanations of Semantic Segmentation.,https://proceedings.neurips.cc/paper/2019/hash/6950aa02ae8613af620668146dd11840-Abstract.html,2019,NeurIPS,"Lukas Hoyer, Mauricio Munoz, Prateek Katiyar, Anna Khoreva, Volker Fischer 0003",Images,Outcome Explanation,(Deep) Neural Network,Other,"Heatmap, Localization",Interpretability built into the predictive model,Yes,Yes
nips/KimL19,Learning Dynamics of Attention - Human Prior for Interpretable Machine Reasoning.,https://proceedings.neurips.cc/paper/2019/hash/ae3539867aaeec609a4260c6feb725f4-Abstract.html,2019,NeurIPS,"Wonjae Kim, Yoonho Lee","Images, Text, Graph data",Outcome Explanation,Any (for a specific task); model-agnostic,Question Answering,Heatmap,Interpretability built into the predictive model,Yes,Yes
nips/WangN19,Deliberative Explanations - visualizing network insecurities.,https://proceedings.neurips.cc/paper/2019/hash/68053af2923e00204c3ca7c6a3150cf7-Abstract.html,2019,NeurIPS,"Pei Wang, Nuno Vasconcelos",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Prototypes",Interpretability built into the predictive model,Yes,Yes
nips/YingBYZL19,GNNExplainer - Generating Explanations for Graph Neural Networks.,https://proceedings.neurips.cc/paper/2019/hash/d80b7040b773199015de6d3b4293c8ff-Abstract.html,2019,NeurIPS,"Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec",Graph data,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Feature Importance, Graph",Post-hoc explanation method,Yes,Yes
sigir/BalogRA19,"Transparent, Scrutable and Explainable User Models for Personalized Recommendation.",https://doi.org/10.1145/3331184.3331211,2019,SIGIR,"Krisztian Balog, Filip Radlinski, Shushan Arakelyan",User-item matrix,Transparent Box Design,Other,Recommendation,Text,Interpretability built into the predictive model,Yes,Yes
sigir/HanSYWN19,Prototype-guided Attribute-wise Interpretable Scheme for Clothing Matching.,https://doi.org/10.1145/3331184.3331245,2019,SIGIR,"Xianjing Han, Xuemeng Song, Jianhua Yin, Yinglong Wang 0001, Liqiang Nie","Images, Text, Images",Outcome Explanation,(Deep) Neural Network,Classification,"Prototypes, Text",Interpretability built into the predictive model,Yes,Yes
sigir/LiQPQDW19,A Capsule Network for Recommendation and Explaining What You Like and Dislike.,https://doi.org/10.1145/3331184.3331216,2019,SIGIR,"Chenliang Li, Cong Quan, Li Peng, Yunwei Qi, Yuming Deng, Libing Wu","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,"Heatmap, Localization",Interpretability built into the predictive model,Yes,Yes
sigir/TaoJWW19,The FacT - Taming Latent Factor Models for Explainability with Factorization Trees.,https://doi.org/10.1145/3331184.3331244,2019,SIGIR,"Yiyi Tao, Yiling Jia, Nan Wang, Hongning Wang",User-item matrix,Transparent Box Design,Other,Recommendation,"Decision Tree, Text",Interpretability built into the predictive model,Yes,Yes
sigir/XianFMMZ19,Reinforcement Knowledge Graph Reasoning for Explainable Recommendation.,https://doi.org/10.1145/3331184.3331203,2019,SIGIR,"Yikun Xian, Zuohui Fu, S. Muthukrishnan, Gerard de Melo, Yongfeng Zhang",User-item matrix,Outcome Explanation,Other,"Policy learning, Recommendation",Graph,Interpretability built into the predictive model,Yes,Yes
sigir/Yang0WMF0C19,Interpretable Fashion Matching with Rich Attributes.,https://doi.org/10.1145/3331184.3331242,2019,SIGIR,"Xun Yang, Xiangnan He 0001, Xiang Wang 0010, Yunshan Ma, Fuli Feng, Meng Wang 0001, Tat-Seng Chua",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Decision Rules, Decision Tree, Prototypes",Interpretability built into the predictive model,Yes,Yes
www/MaZCJWLMR19,Jointly Learning Explainable Rules for Recommendation with Knowledge Graph.,https://doi.org/10.1145/3308558.3313607,2019,WWW,"Weizhi Ma, Min Zhang 0006, Yue Cao, Woojeong Jin, Chenyang Wang, Yiqun Liu 0001, Shaoping Ma, Xiang Ren 0001","Graph data, User-item matrix",Transparent Box Design,Other,Recommendation,Decision Rules,Interpretability built into the predictive model,Yes,Yes
aaai/BiskSCM18,Learning Interpretable Spatial Operations in a Rich 3D Blocks World.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17410,2018,AAAI,"Yonatan Bisk, Kevin J. Shih, Yejin Choi, Daniel Marcu",Other,Model Inspection,(Deep) Neural Network,Policy learning,Other,Post-hoc explanation method,Yes,Yes
aaai/HsuM0S18,An Interpretable Generative Adversarial Approach to Classification of Latent Entity Relations in Unstructured Sentences.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16629,2018,AAAI,"Shiou Tian Hsu, Changsung Moon, Paul Jones 0001, Nagiza F. Samatova",Text,Model Inspection,(Deep) Neural Network,Classification,Localization,Interpretability built into the predictive model,Yes,Yes
aaai/LiLCR18,Deep Learning for Case-Based Reasoning Through Prototypes - A Neural Network That Explains Its Predictions.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17082,2018,AAAI,"Oscar Li, Hao Liu 0015, Chaofan Chen, Cynthia Rudin",Images,Outcome Explanation,(Deep) Neural Network,Classification,Prototypes,Interpretability built into the predictive model,Yes,Yes
aaai/NguyenKLW18,An Interpretable Joint Graphical Model for Fact-Checking From Crowds.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16673,2018,AAAI,"An T. Nguyen 0001, Aditya Kharosekar, Matthew Lease, Byron C. Wallace",Text,Outcome Explanation,Logistic Regression,Classification,Other,Interpretability built into the predictive model,Yes,Yes
aaai/PalangiSHD18,Question-Answering with Grammatically-Interpretable Representations.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17090,2018,AAAI,"Hamid Palangi, Paul Smolensky, Xiaodong He 0001, Li Deng 0001",Text,"Model Inspection, Outcome Explanation",(Deep) Neural Network,"Classification, Question Answering",Disentanglement,Interpretability built into the predictive model,Yes,Yes
aaai/Ribeiro0G18,Anchors - High-Precision Model-Agnostic Explanations.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16982,2018,AAAI,"Marco Túlio Ribeiro, Sameer Singh 0001, Carlos Guestrin","Tabular / structured, Images, Text","Model Inspection, Outcome Explanation","(Deep) Neural Network, Tree Ensemble, Any (for a specific task); model-agnostic, Logistic Regression","Classification, Question Answering","Decision Rules, Localization",Post-hoc explanation method,Yes,Yes
aaai/RossD18,Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17337,2018,AAAI,"Andrew Slavin Ross, Finale Doshi-Velez",Images,Outcome Explanation,(Deep) Neural Network,Classification,Representation Synthesis,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
aaai/RustamovK18,Interpretable Graph-Based Semi-Supervised Learning via Flows.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16396,2018,AAAI,"Raif M. Rustamov, James T. Klosowski","Tabular / structured, Images, Text",Model Inspection,Other,"Classification, Regression",Graph,Interpretability built into the predictive model,Yes,Yes
aaai/SubramanianPJBH18,SPINE - SParse Interpretable Neural Embeddings.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17433,2018,AAAI,"Anant Subramanian, Danish Pruthi, Harsh Jhamtani, Taylor Berg-Kirkpatrick, Eduard H. Hovy",Text,Model Inspection,"(Deep) Neural Network, Tree Ensemble, Support Vector Machine, Logistic Regression, Any (for a specific task); model-agnostic","Classification, Regression, Representation learning",Disentanglement,Interpretability built into the predictive model,Yes,Yes
aaai/WuHPZ0D18,Beyond Sparsity - Tree Regularization of Deep Models for Interpretability.,https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16285,2018,AAAI,"Mike Wu, Michael C. Hughes, Sonali Parbhoo, Maurizio Zazzi, Volker Roth 0001, Finale Doshi-Velez","Tabular / structured, Time series",Model Explanation,(Deep) Neural Network,Classification,Decision Tree,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
acl/EskenaziLZ18,Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation.,https://www.aclweb.org/anthology/P18-1101/,2018,ACL,"Tiancheng Zhao, Kyusong Lee, Maxine Eskénazi",Text,Outcome Explanation,(Deep) Neural Network,"Generation, Representation learning",Disentanglement,Interpretability built into the predictive model,Yes,Yes
acl/InuiTT18,Interpretable and Compositional Relation Learning by Joint Training with an Autoencoder.,https://www.aclweb.org/anthology/P18-1200/,2018,ACL,"Ryo Takahashi, Ran Tian, Kentaro Inui",Graph data,Model Inspection,(Deep) Neural Network,"Representation learning, Other","Disentanglement, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
acl/MorencyCPLZ18,Multimodal Language Analysis in the Wild - CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph.,https://www.aclweb.org/anthology/P18-1208/,2018,ACL,"Amir Zadeh 0001, Paul Pu Liang, Soujanya Poria, Erik Cambria, Louis-Philippe Morency","Text, Video, Time series",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Feature plot",Interpretability built into the predictive model,Yes,Yes
acl/SchutzeRP18,Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement.,https://www.aclweb.org/anthology/P18-1032/,2018,ACL,"Nina Pörner, Hinrich Schütze, Benjamin Roth 0001",Text,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Post-hoc explanation method,Yes,Yes
cvpr/ChuangL0F18,Learning to Act Properly - Predicting and Explaining Affordances From Images.,http://openaccess.thecvf.com/content_cvpr_2018/html/Chuang_Learning_to_Act_CVPR_2018_paper.html,2018,CVPR,"Ching-Yao Chuang, Jiaman Li, Antonio Torralba 0001, Sanja Fidler","Images, Text",Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Text",Interpretability built into the predictive model,Yes,Yes
cvpr/FongV18,Net2Vec - Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks.,http://openaccess.thecvf.com/content_cvpr_2018/html/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.html,2018,CVPR,"Ruth Fong, Andrea Vedaldi",Images,Model Inspection,(Deep) Neural Network,Classification,"Localization, Prototypes",Post-hoc explanation method,Yes,Yes
cvpr/MascharkaTSM18,Transparency by Design - Closing the Gap Between Performance and Interpretability in Visual Reasoning.,http://openaccess.thecvf.com/content_cvpr_2018/html/Mascharka_Transparency_by_Design_CVPR_2018_paper.html,2018,CVPR,"David Mascharka, Philip Tran, Ryan Soklaski, Arjun Majumdar","Images, Text",Transparent Box Design,(Deep) Neural Network,Question Answering,Heatmap,Interpretability built into the predictive model,Yes,Yes
cvpr/ParkHARSDR18,Multimodal Explanations - Justifying Decisions and Pointing to the Evidence.,http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.html,2018,CVPR,"Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Anna Rohrbach, Bernt Schiele, Trevor Darrell, Marcus Rohrbach","Images, Text",Outcome Explanation,(Deep) Neural Network,Question Answering,"Heatmap, Localization, Text",Post-hoc explanation method,Yes,Yes
cvpr/WangS0H18,Interpret Neural Networks by Identifying Critical Data Routing Paths.,http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Interpret_Neural_Networks_CVPR_2018_paper.html,2018,CVPR,"Yulong Wang, Hang Su 0006, Bo Zhang 0010, Xiaolin Hu 0001",Images,Outcome Explanation,(Deep) Neural Network,Classification,Other,Post-hoc explanation method,Yes,Yes
cvpr/WuLCJL18,Interpretable Video Captioning via Trajectory Structured Localization.,http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.html,2018,CVPR,"Xian Wu, Guanbin Li, Qingxing Cao, Qingge Ji, Liang Lin",Video,Transparent Box Design,(Deep) Neural Network,Generation,Localization,Interpretability built into the predictive model,Yes,Yes
cvpr/ZhangWZ18a,Interpretable Convolutional Neural Networks.,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.html,2018,CVPR,"Quanshi Zhang, Ying Nian Wu, Song-Chun Zhu",Images,Model Inspection,(Deep) Neural Network,Classification,"Disentanglement, Heatmap, Localization",Interpretability built into the predictive model,Yes,Yes
cvpr/ZhangXWXY18,DeepVoting - A Robust and Explainable Deep Network for Semantic Part Detection Under Partial Occlusion.,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.html,2018,CVPR,"Zhishuai Zhang, Cihang Xie, Jianyu Wang, Lingxi Xie, Alan L. Yuille",Images,Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Localization, Prototypes",Interpretability built into the predictive model,Yes,Yes
icdm/JhaWXZ18,Interpretable Word Embeddings for Medical Domain.,https://doi.org/10.1109/ICDM.2018.00135,2018,ICDM,"Kishlay Jha, Yaqing Wang, Guangxu Xun, Aidong Zhang",Text,Model Inspection,(Deep) Neural Network,Representation learning,Disentanglement,Post-hoc explanation method,Yes,Yes
icdm/KarlssonRPG18,Explainable Time Series Tweaking via Irreversible and Reversible Temporal Transformations.,https://doi.org/10.1109/ICDM.2018.00036,2018,ICDM,"Isak Karlsson, Jonathan Rebane, Panagiotis Papapetrou, Aristides Gionis",Time series,Outcome Explanation,Tree Ensemble,Classification,Representation Synthesis,Post-hoc explanation method,Yes,Yes
icdm/WangCYWW018,A Reinforcement Learning Framework for Explainable Recommendation.,https://doi.org/10.1109/ICDM.2018.00074,2018,ICDM,"Xiting Wang, Yiru Chen, Jie Yang, Le Wu, Zhengtao Wu, Xing Xie 0001",User-item matrix,Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Recommendation,Text,Post-hoc explanation method,Yes,Yes
iclr/KindermansSAMEK18,Learning how to explain neural networks - PatternNet and PatternAttribution.,https://openreview.net/forum?id=Hkn7CBaTW,2018,ICLR,"Pieter-Jan Kindermans, Kristof T. Schütt, Maximilian Alber, Klaus-Robert Müller, Dumitru Erhan, Been Kim, Sven Dähne","Images, Any",Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
iclr/ShuXS18,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning.,https://openreview.net/forum?id=SJJQVZW0b,2018,ICLR,"Tianmin Shu, Caiming Xiong, Richard Socher",Images,Transparent Box Design,Other,Policy learning,"Graph, Text",Interpretability built into the predictive model,Yes,Yes
iclr/TrottXS18,Interpretable Counting for Visual Question Answering.,https://openreview.net/forum?id=S1J2ZyZ0Z,2018,ICLR,"Alexander Trott, Caiming Xiong, Richard Socher","Images, Text",Outcome Explanation,(Deep) Neural Network,Question Answering,Localization,Interpretability built into the predictive model,Yes,Yes
icml/AdelGW18,Discovering Interpretable Representations for Both Deep Generative and Discriminative Models.,http://proceedings.mlr.press/v80/adel18a.html,2018,ICML,"Tameem Adel, Zoubin Ghahramani, Adrian Weller",Images,Model Inspection,(Deep) Neural Network,"Classification, Representation learning",Disentanglement,Post-hoc explanation method,Yes,Yes
icml/AinsworthFLF18,oi-VAE - Output Interpretable VAEs for Nonlinear Group Factor Analysis.,http://proceedings.mlr.press/v80/ainsworth18a.html,2018,ICML,"Samuel K. Ainsworth, Nicholas J. Foti, Adrian K. C. Lee, Emily B. Fox","Images, Video, Time series",Model Inspection,(Deep) Neural Network,Generation,Disentanglement,Interpretability built into the predictive model,Yes,Yes
icml/KimWGCWVS18,Interpretability Beyond Feature Attribution - Quantitative Testing with Concept Activation Vectors (TCAV).,http://proceedings.mlr.press/v80/kim18d.html,2018,ICML,"Been Kim, Martin Wattenberg, Justin Gilmer, Carrie J. Cai, James Wexler, Fernanda B. Viégas, Rory Sayres",Images,Model Inspection,(Deep) Neural Network,Classification,"Feature Importance, Heatmap, Prototypes, Representation Synthesis",Post-hoc explanation method,Yes,Yes
icml/VermaMSKC18,Programmatically Interpretable Reinforcement Learning.,http://proceedings.mlr.press/v80/verma18a.html,2018,ICML,"Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, Swarat Chaudhuri",Time series,Model Explanation,(Deep) Neural Network,Policy learning,Decision Rules,Post-hoc explanation method,Yes,Yes
ijcai/HuJCC18,Interpretable Recommendation via Attraction Modeling - Learning Multilevel Attractiveness over Multimodal Movie Contents.,https://doi.org/10.24963/ijcai.2018/472,2018,IJCAI,"Liang Hu 0004, Songlei Jian, Longbing Cao, Qingkui Chen","Tabular / structured, Text, User-item matrix",Outcome Explanation,Other,Recommendation,Feature Importance,Interpretability built into the predictive model,Yes,Yes
ijcai/LabreucheF18,Explaining Multi-Criteria Decision Aiding Models with an Extended Shapley Value.,https://doi.org/10.24963/ijcai.2018/46,2018,IJCAI,"Christophe Labreuche, Simon Fossier",Tabular / structured,"Model Inspection, Outcome Explanation",Bayesian or Hierarchical Network,Other,Feature Importance,Post-hoc explanation method,Yes,Yes
ijcai/LiuSH18,Contextual Outlier Interpretation.,https://doi.org/10.24963/ijcai.2018/341,2018,IJCAI,"Ninghao Liu, Donghwa Shin, Xia Hu","Tabular / structured, Images",Outcome Explanation,"(Deep) Neural Network, Support Vector Machine, Any (for a specific task); model-agnostic",Anomaly detection,"Localization, Prototypes, Other",Post-hoc explanation method,Yes,Yes
ijcai/LuoAPWZYH18,Beyond Polarity - Interpretable Financial Sentiment Analysis with Hierarchical Query-driven Attention.,https://doi.org/10.24963/ijcai.2018/590,2018,IJCAI,"Ling Luo, Xiang Ao, Feiyang Pan, Jin Wang 0007, Tong Zhao, Ningzi Yu, Qing He 0003",Text,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
ijcai/RagoCT18,Argumentation-Based Recommendations - Fantastic Explanations and How to Find Them.,https://doi.org/10.24963/ijcai.2018/269,2018,IJCAI,"Antonio Rago 0001, Oana Cocarascu, Francesca Toni",User-item matrix,Outcome Explanation,Other,Recommendation,"Feature Importance, Graph",Interpretability built into the predictive model,Yes,Yes
ijcai/SatoSS018,Interpretable Adversarial Perturbation in Input Embedding Space for Text.,https://doi.org/10.24963/ijcai.2018/601,2018,IJCAI,"Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto 0001",Text,Model Inspection,(Deep) Neural Network,Generation,"Prototypes, Text",Interpretability built into the predictive model,Yes,Yes
ijcai/ShihCD18,A Symbolic Approach to Explaining Bayesian Network Classifiers.,https://doi.org/10.24963/ijcai.2018/708,2018,IJCAI,"Andy Shih, Arthur Choi, Adnan Darwiche",Tabular / structured,"Model Explanation, Outcome Explanation",Bayesian or Hierarchical Network,Classification,"Localization, White-box model",Post-hoc explanation method,Yes,Yes
kdd/BaiZEV18,Interpretable Representation Learning for Healthcare via Capturing Disease Progression through Time.,https://doi.org/10.1145/3219819.3219904,2018,KDD,"Tian Bai, Shanshan Zhang, Brian L. Egleston, Slobodan Vucetic","Text, Time series","Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
kdd/ChuHHWP18,Exact and Consistent Interpretation for Piecewise Linear Neural Networks - A Closed Form Solution.,https://doi.org/10.1145/3219819.3220063,2018,KDD,"Lingyang Chu, Xia Hu, Juhua Hu, Lanjun Wang, Jian Pei","Tabular / structured, Images",Model Inspection,(Deep) Neural Network,Classification,"Heatmap, White-box model",Post-hoc explanation method,Yes,Yes
kdd/DuLSH18,Towards Explanation of DNN-based Prediction with Guided Feature Inversion.,https://doi.org/10.1145/3219819.3220099,2018,KDD,"Mengnan Du, Ninghao Liu, Qingquan Song, Xia Hu",Images,Outcome Explanation,(Deep) Neural Network,Classification,Heatmap,Post-hoc explanation method,Yes,Yes
kdd/Janakiraman18,Explaining Aviation Safety Incidents Using Deep Temporal Multiple Instance Learning.,https://doi.org/10.1145/3219819.3219871,2018,KDD,Vijay Manikandan Janakiraman,Time series,Outcome Explanation,(Deep) Neural Network,Classification,"Localization, Text",Post-hoc explanation method,Yes,Yes
kdd/LiuHLH18,On Interpretation of Network Embedding via Taxonomy Induction.,https://doi.org/10.1145/3219819.3220001,2018,KDD,"Ninghao Liu, Xiao Huang 0001, Jundong Li, Xia Hu","Graph data, Other",Model Inspection,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,"Graph, Representation Visualization, Feature Importance",Post-hoc explanation method,Yes,Yes
kdd/LiuYH18,Adversarial Detection with Model Interpretation.,https://doi.org/10.1145/3219819.3220027,2018,KDD,"Ninghao Liu, Hongxia Yang, Xia Hu","Text, Any",Outcome Explanation,"(Deep) Neural Network, Tree Ensemble, Support Vector Machine, Any (for a specific task); model-agnostic, Logistic Regression",Classification,White-box model,Post-hoc explanation method,Yes,Yes
kdd/WangWLW18,Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis.,https://doi.org/10.1145/3219819.3220060,2018,KDD,"Jingyuan Wang, Ze Wang, Jianfeng Li, Junjie Wu 0001",Time series,Model Inspection,(Deep) Neural Network,"Classification, Regression",Heatmap,Post-hoc explanation method,Yes,Yes
kdd/YangSJ018,I Know You'll Be Back - Interpretable New User Clustering and Churn Prediction on a Mobile Social Application.,https://doi.org/10.1145/3219819.3219821,2018,KDD,"Carl Yang, Xiaolin Shi, Luo Jie, Jiawei Han 0001","Time series, Graph data",Model Inspection,(Deep) Neural Network,"Clustering, Classification","Feature Importance, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
kdd/ZangC018,Learning and Interpreting Complex Distributions in Empirical Data.,https://doi.org/10.1145/3219819.3220073,2018,KDD,"Chengxi Zang, Peng Cui 0001, Wenwu Zhu 0001","Tabular / structured, Time series",Transparent Box Design,Other,Regression,White-box model,Interpretability built into the predictive model,Yes,Yes
nips/CamburuRLB18,e-SNLI - Natural Language Inference with Natural Language Explanations.,https://proceedings.neurips.cc/paper/2018/hash/4c7a167bb329bd92580a99ce422d6fa6-Abstract.html,2018,NeurIPS,"Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, Phil Blunsom",Text,Outcome Explanation,(Deep) Neural Network,Classification,Text,Supervised explanation training,Yes,Yes
nips/GuoHTXL18,Explaining Deep Learning Models - A Bayesian Non-parametric Approach.,https://proceedings.neurips.cc/paper/2018/hash/4b4edc2630fe75800ddc29a7b4070add-Abstract.html,2018,NeurIPS,"Wenbo Guo 0002, Sui Huang, Yunzhe Tao, Xinyu Xing, Lin Lin",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Heatmap, Localization",Post-hoc explanation method,Yes,Yes
nips/GuptaBCC18,Diminishing Returns Shape Constraints for Interpretability and Regularization.,https://proceedings.neurips.cc/paper/2018/hash/caa202034f268232c26fac9435f54e15-Abstract.html,2018,NeurIPS,"Maya R. Gupta, Dara Bahri, Andrew Cotter, Kevin Robert Canini",Tabular / structured,Transparent Box Design,"(Deep) Neural Network, Other",Regression,Feature plot,Interpretability built into the predictive model,Yes,Yes
nips/HeoLKLKYH18,Uncertainty-Aware Attention for Reliable Interpretation and Prediction.,https://proceedings.neurips.cc/paper/2018/hash/285e19f20beded7d215102b49d5c09a0-Abstract.html,2018,NeurIPS,"Jay Heo, Haebeom Lee, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho Yang, Sung Ju Hwang",Time series,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
nips/Norcliffe-Brown18,Learning Conditioned Graph Structures for Interpretable Visual Question Answering.,https://proceedings.neurips.cc/paper/2018/hash/4aeae10ea1c6433c926cdfa558d31134-Abstract.html,2018,NeurIPS,"Will Norcliffe-Brown, Stathis Vafeias, Sarah Parisot","Images, Text",Transparent Box Design,(Deep) Neural Network,"Classification, Question Answering","Graph, Localization",Interpretability built into the predictive model,Yes,Yes
nips/PlumbMT18,Model Agnostic Supervised Local Explanations.,https://proceedings.neurips.cc/paper/2018/hash/b495ce63ede0f4efc9eec62cb947c162-Abstract.html,2018,NeurIPS,"Gregory Plumb, Denali Molitor, Ameet S. Talwalkar","Tabular / structured, Any","Model Inspection, Outcome Explanation, Transparent Box Design","Tree Ensemble, Any (for a specific task); model-agnostic",Classification,White-box model,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
nips/TsangLPML18,Neural Interaction Transparency (NIT) - Disentangling Learned Interactions for Improved Interpretability.,https://proceedings.neurips.cc/paper/2018/hash/74378afe5e8b20910cf1f939e57f0480-Abstract.html,2018,NeurIPS,"Michael Tsang, Hanpeng Liu, Sanjay Purushotham, Pavankumar Murali, Yan Liu 0002","Tabular / structured, Images, Any",Model Inspection,"(Deep) Neural Network, Tree Ensemble, Logistic Regression, Any (for a specific task); model-agnostic","Classification, Regression",Disentanglement,Interpretability built into the predictive model,Yes,Yes
nips/Wang18,Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations.,https://proceedings.neurips.cc/paper/2018/hash/32bbf7b2bc4ed14eb1e9c2580056a989-Abstract.html,2018,NeurIPS,Tong Wang,Tabular / structured,Transparent Box Design,Bayesian or Hierarchical Network,Classification,Decision Rules,Interpretability built into the predictive model,Yes,Yes
nips/YehKYR18,Representer Point Selection for Explaining Deep Neural Networks.,https://proceedings.neurips.cc/paper/2018/hash/8a7129b8f3edd95b7d969dfc2c8e9d9d-Abstract.html,2018,NeurIPS,"Chih-Kuan Yeh, Joon Sik Kim, Ian En-Hsu Yen, Pradeep Ravikumar","Any, Images",Outcome Explanation,(Deep) Neural Network,Classification,Prototypes,Post-hoc explanation method,Yes,Yes
nips/ZhangSS18,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections.",https://proceedings.neurips.cc/paper/2018/hash/300891a62162b960cf02ce3827bb363c-Abstract.html,2018,NeurIPS,"Xin Zhang 0035, Armando Solar-Lezama, Rishabh Singh",Tabular / structured,Outcome Explanation,(Deep) Neural Network,Classification,Prototypes,Post-hoc explanation method,Yes,Yes
sigir/WangWJY18,Explainable Recommendation via Multi-Task Learning in Opinionated Text Data.,https://doi.org/10.1145/3209978.3210010,2018,SIGIR,"Nan Wang, Hongning Wang, Yiling Jia, Yue Yin","User-item matrix, Text",Outcome Explanation,Other,Recommendation,"Localization, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
www/ChenZLM18,Neural Attentional Rating Regression with Review-level Explanations.,https://doi.org/10.1145/3178876.3186070,2018,WWW,"Chong Chen, Min Zhang 0006, Yiqun Liu 0001, Shaoping Ma","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,"Classification, Regression",Localization,Interpretability built into the predictive model,Yes,Yes
www/Wang0FNC18,TEM - Tree-enhanced Embedding Model for Explainable Recommendation.,https://doi.org/10.1145/3178876.3186066,2018,WWW,"Xiang Wang 0010, Xiangnan He 0001, Fuli Feng, Liqiang Nie, Tat-Seng Chua",User-item matrix,Outcome Explanation,Other,Recommendation,Feature Importance,"Post-hoc explanation method, Interpretability built into the predictive model",Yes,Yes
www/WuWYLZ18,Sharing Deep Neural Network Models with Interpretation.,https://doi.org/10.1145/3178876.3185995,2018,WWW,"Huijun Wu 0001, Chen Wang 0008, Jie Yin, Kai Lu, Liming Zhu",Images,"Model Inspection, Outcome Explanation",(Deep) Neural Network,Classification,"Graph, Prototypes",Post-hoc explanation method,Yes,Yes
aaai/ZhangCWZ17,Growing Interpretable Part Graphs on ConvNets via Multi-Shot Learning.,http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14909,2017,AAAI,"Quanshi Zhang, Ruiming Cao, Ying Nian Wu, Song-Chun Zhu",Images,Model Inspection,"(Deep) Neural Network, Support Vector Machine",Classification,"Graph, Localization",Post-hoc explanation method,Yes,Yes
acl/XieMDH17,An Interpretable Knowledge Transfer Model for Knowledge Base Completion.,https://doi.org/10.18653/v1/P17-1088,2017,ACL,"Qizhe Xie, Xuezhe Ma, Zihang Dai, Eduard H. Hovy",Tabular / structured,Outcome Explanation,Other,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
cvpr/BauZKO017,Network Dissection - Quantifying Interpretability of Deep Visual Representations.,https://doi.org/10.1109/CVPR.2017.354,2017,CVPR,"David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, Antonio Torralba 0001",Images,Model Inspection,(Deep) Neural Network,Classification,"Disentanglement, Localization, Text",Post-hoc explanation method,Yes,Yes
cvpr/DongSZZ17,Improving Interpretability of Deep Neural Networks with Semantic Information.,https://doi.org/10.1109/CVPR.2017.110,2017,CVPR,"Yinpeng Dong, Hang Su 0006, Jun Zhu 0001, Bo Zhang 0010",Video,Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Text",Interpretability built into the predictive model,Yes,Yes
cvpr/LiangLSFYX17,Interpretable Structure-Evolving LSTM.,https://doi.org/10.1109/CVPR.2017.234,2017,CVPR,"Xiaodan Liang, Liang Lin, Xiaohui Shen, Jiashi Feng, Shuicheng Yan, Eric P. Xing",Images,Outcome Explanation,(Deep) Neural Network,Classification,Localization,Interpretability built into the predictive model,Yes,Yes
iccv/KimC17,Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention.,https://doi.org/10.1109/ICCV.2017.320,2017,ICCV,"Jinkyu Kim, John F. Canny","Images, Video",Outcome Explanation,(Deep) Neural Network,Regression,Heatmap,Post-hoc explanation method,Yes,Yes
iccv/SelvarajuCDVPB17,Grad-CAM - Visual Explanations from Deep Networks via Gradient-Based Localization.,https://doi.org/10.1109/ICCV.2017.74,2017,ICCV,"Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra","Images, Text",Outcome Explanation,(Deep) Neural Network,Classification,"Heatmap, Localization",Post-hoc explanation method,Yes,Yes
iccv/WorrallGTB17,Interpretable Transformations with Encoder-Decoder Networks.,https://doi.org/10.1109/ICCV.2017.611,2017,ICCV,"Daniel E. Worrall, Stephan J. Garbin, Daniyar Turmukhambetov, Gabriel J. Brostow",Images,Model Inspection,(Deep) Neural Network,"Classification, Generation, Representation learning",Disentanglement,Interpretability built into the predictive model,Yes,Yes
icdm/OyamadaN17,Relational Mixture of Experts - Explainable Demographics Prediction with Behavioral Data.,https://doi.org/10.1109/ICDM.2017.45,2017,ICDM,"Masafumi Oyamada, Shinji Nakadai",User-item matrix,Model Inspection,"Support Vector Machine, Bayesian or Hierarchical Network",Classification,"Decision Rules, Heatmap",Interpretability built into the predictive model,Yes,Yes
iclr/YuV17,Towards Deep Interpretability (MUS-ROVER II) - Learning Hierarchical Representations of Tonal Music.,https://openreview.net/forum?id=ryhqQFKgl,2017,ICLR,"Haizi Yu, Lav R. Varshney",Other,Transparent Box Design,Bayesian or Hierarchical Network,Representation learning,"Decision Rules, Graph",Interpretability built into the predictive model,Yes,Yes
icml/DempseyMSDGMR17,"iSurvive - An Interpretable, Event-time Prediction Model for mHealth.",http://proceedings.mlr.press/v70/dempsey17a.html,2017,ICML,"Walter H. Dempsey, Alexander Moreno, Christy K. Scott, Michael L. Dennis, David H. Gustafson, Susan A. Murphy, James M. Rehg","Tabular / structured, Time series",Transparent Box Design,Other,Regression,White-box model,Interpretability built into the predictive model,Yes,Yes
icml/FoersterGSCS17,Input Switched Affine Networks - An RNN Architecture Designed for Interpretability.,http://proceedings.mlr.press/v70/foerster17a.html,2017,ICML,"Jakob N. Foerster, Justin Gilmer, Jascha Sohl-Dickstein, Jan Chorowski, David Sussillo",Text,"Outcome Explanation, Transparent Box Design",(Deep) Neural Network,Generation,"Feature Importance, Feature plot",Interpretability built into the predictive model,Yes,Yes
ijcai/RossHD17,Right for the Right Reasons - Training Differentiable Models by Constraining their Explanations.,https://doi.org/10.24963/ijcai.2017/371,2017,IJCAI,"Andrew Slavin Ross, Michael C. Hughes, Finale Doshi-Velez","Tabular / structured, Images, Text",Outcome Explanation,(Deep) Neural Network,Classification,"Feature Importance, Heatmap",Supervised explanation training,Yes,Yes
kdd/TolomeiSHL17,Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking.,https://doi.org/10.1145/3097983.3098039,2017,KDD,"Gabriele Tolomei, Fabrizio Silvestri, Andrew Haines, Mounia Lalmas",Tabular / structured,Model Inspection,Tree Ensemble,Classification,Other,Post-hoc explanation method,Yes,Yes
nips/ElenbergDFK17,Streaming Weak Submodularity - Interpreting Neural Networks on the Fly.,https://proceedings.neurips.cc/paper/2017/hash/c182f930a06317057d31c73bb2fedd4f-Abstract.html,2017,NeurIPS,"Ethan R. Elenberg, Alexandros G. Dimakis, Moran Feldman, Amin Karbasi",Images,Outcome Explanation,(Deep) Neural Network,Classification,Localization,Post-hoc explanation method,Yes,Yes
nips/HsuZG17,Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data.,https://proceedings.neurips.cc/paper/2017/hash/0a0a0c8aaa00ade50f74a3f0ca981ed7-Abstract.html,2017,NeurIPS,"Wei-Ning Hsu, Yu Zhang 0033, James R. Glass",Time series,Model Inspection,(Deep) Neural Network,Representation learning,"Disentanglement, Representation Synthesis",Interpretability built into the predictive model,Yes,Yes
nips/LiSE17,InfoGAIL - Interpretable Imitation Learning from Visual Demonstrations.,https://proceedings.neurips.cc/paper/2017/hash/2cd4e8a2ce081c3d7c32c3cde4312ef7-Abstract.html,2017,NeurIPS,"Yunzhu Li, Jiaming Song, Stefano Ermon",Other,Transparent Box Design,Other,Policy learning,Disentanglement,Interpretability built into the predictive model,Yes,Yes
nips/LundbergL17,A Unified Approach to Interpreting Model Predictions.,https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html,2017,NeurIPS,"Scott M. Lundberg, Su-In Lee","Tabular / structured, Images, Any",Outcome Explanation,"(Deep) Neural Network, Any (for a specific task); model-agnostic","Classification, Regression","Feature Importance, Heatmap",Post-hoc explanation method,Yes,Yes
nips/RaghuGYS17,SVCCA - Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability.,https://proceedings.neurips.cc/paper/2017/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html,2017,NeurIPS,"Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein","Tabular / structured, Images",Model Inspection,(Deep) Neural Network,"Classification, Regression",Feature Importance,Post-hoc explanation method,Yes,Yes
icdm/ChenCHCCSD16,Interpretable Clustering via Discriminative Rectangle Mixture Model.,https://doi.org/10.1109/ICDM.2016.0097,2016,ICDM,"Junxiang Chen, Yale Chang, Brian Hobbs, Peter J. Castaldi, Michael H. Cho, Edwin K. Silverman, Jennifer G. Dy",Tabular / structured,Model Inspection,Other,Clustering,"Decision Rules, Representation Visualization",Interpretability built into the predictive model,Yes,Yes
icdm/DangSSSB16,Outlier Detection from Network Data with Subnetwork Interpretation.,https://doi.org/10.1109/ICDM.2016.0101,2016,ICDM,"Xuan-Hong Dang, Arlei Silva, Ambuj K. Singh, Ananthram Swami, Prithwish Basu",Graph data,Model Inspection,Other,Anomaly detection,Localization,Interpretability built into the predictive model,Yes,Yes
icdm/WangRDLKM16,Bayesian Rule Sets for Interpretable Classification.,https://doi.org/10.1109/ICDM.2016.0171,2016,ICDM,"Tong Wang 0011, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, Perry MacNeille",Tabular / structured,Transparent Box Design,Bayesian or Hierarchical Network,Classification,Decision Rules,Interpretability built into the predictive model,Yes,Yes
kdd/LakkarajuBL16,Interpretable Decision Sets - A Joint Framework for Description and Prediction.,https://doi.org/10.1145/2939672.2939874,2016,KDD,"Himabindu Lakkaraju, Stephen H. Bach, Jure Leskovec",Tabular / structured,Transparent Box Design,Other,Classification,Decision Rules,Interpretability built into the predictive model,Yes,Yes
kdd/Ribeiro0G16,"""Why Should I Trust You?"" - Explaining the Predictions of Any Classifier.",https://doi.org/10.1145/2939672.2939778,2016,KDD,"Marco Túlio Ribeiro, Sameer Singh 0001, Carlos Guestrin","Tabular / structured, Images, Text","Model Inspection, Outcome Explanation","(Deep) Neural Network, Tree Ensemble, Support Vector Machine, Any (for a specific task); model-agnostic, Logistic Regression, Other","Classification, Regression","Feature Importance, Localization",Post-hoc explanation method,Yes,Yes
nips/ChenCDHSSA16,InfoGAN - Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.,https://proceedings.neurips.cc/paper/2016/hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Abstract.html,2016,NeurIPS,"Xi Chen 0022, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel",Images,Model Inspection,(Deep) Neural Network,Representation learning,Disentanglement,Interpretability built into the predictive model,Yes,Yes
nips/ChoiBSKSS16,RETAIN - An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism.,https://proceedings.neurips.cc/paper/2016/hash/231141b34c82aa95e48810a9d1b33a79-Abstract.html,2016,NeurIPS,"Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, Walter F. Stewart",Time series,Outcome Explanation,(Deep) Neural Network,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
nips/Jitkrittum0CG16,Interpretable Distribution Features with Maximum Testing Power.,https://proceedings.neurips.cc/paper/2016/hash/0a09c8844ba8f0936c20bd791130d6b6-Abstract.html,2016,NeurIPS,"Wittawat Jitkrittum, Zoltán Szabó 0001, Kacper P. Chwialkowski, Arthur Gretton","Tabular / structured, Images, Text",Model Inspection,"Any (for a specific task); model-agnostic, Other",Other,"Feature Importance, Heatmap",Post-hoc explanation method,Yes,Yes
nips/KimKK16,"Examples are not enough, learn to criticize! Criticism for Interpretability.",https://proceedings.neurips.cc/paper/2016/hash/5680522b8e2bb01943234bce7bf84534-Abstract.html,2016,NeurIPS,"Been Kim, Oluwasanmi Koyejo, Rajiv Khanna",Images,Model Inspection,"(Deep) Neural Network, Any (for a specific task); model-agnostic",Classification,Prototypes,Post-hoc explanation method,Yes,Yes
nips/LakkarajuL16,Confusions over Time - An Interpretable Bayesian Model to Characterize Trends in Decision Making.,https://proceedings.neurips.cc/paper/2016/hash/97d0145823aeb8ed80617be62e08bdcc-Abstract.html,2016,NeurIPS,"Himabindu Lakkaraju, Jure Leskovec","Time series, User-item matrix",Model Inspection,Bayesian or Hierarchical Network,"Classification, Clustering","Feature Importance, Prototypes",Interpretability built into the predictive model,Yes,Yes
nips/ZhaoP16,Interpretable Nonlinear Dynamic Modeling of Neural Trajectories.,https://proceedings.neurips.cc/paper/2016/hash/b2531e7bb29bf22e1daae486fae3417a-Abstract.html,2016,NeurIPS,"Yuan Zhao 0004, Il Memming Park",Time series,Model Explanation,(Deep) Neural Network,Regression,White-box model,Interpretability built into the predictive model,Yes,Yes
sigir/ZhaoLRMYR16,Explainable User Clustering in Short Text Streams.,https://doi.org/10.1145/2911451.2911522,2016,SIGIR,"Yukun Zhao, Shangsong Liang, Zhaochun Ren, Jun Ma 0001, Emine Yilmaz, Maarten de Rijke","Text, Time series, Graph data","Model Inspection, Outcome Explanation",Other,Clustering,Prototypes,Interpretability built into the predictive model,Yes,Yes
aaai/KimPRS15,"Scalable and Interpretable Data Representation for High-Dimensional, Complex Data.",http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9738,2015,AAAI,"Been Kim, Kayur Patel, Afshin Rostamizadeh, Julie A. Shah",Text,Outcome Explanation,Other,Classification,Feature Importance,Interpretability built into the predictive model,Yes,Yes
kdd/WangFM15,Trading Interpretability for Accuracy - Oblique Treed Sparse Additive Models.,https://doi.org/10.1145/2783258.2783407,2015,KDD,"Jialei Wang, Ryohei Fujimaki, Yosuke Motohashi",Tabular / structured,Transparent Box Design,Other,"Classification, Regression","Decision Tree, Feature plot",Interpretability built into the predictive model,Yes,Yes
nips/KimSD15,Mind the Gap - A Generative Approach to Interpretable Feature Selection and Extraction.,https://proceedings.neurips.cc/paper/2015/hash/82965d4ed8150294d4330ace00821d77-Abstract.html,2015,NeurIPS,"Been Kim, Julie A. Shah, Finale Doshi-Velez",Tabular / structured,Model Inspection,Bayesian or Hierarchical Network,Clustering,Feature Importance,Interpretability built into the predictive model,Yes,Yes
acl/FysheTMM14,Interpretable Semantic Vectors from a Joint Model of Brain- and Text- Based Meaning.,https://doi.org/10.3115/v1/p14-1046,2014,ACL,"Alona Fyshe, Partha Pratim Talukdar, Brian Murphy, Tom M. Mitchell","Time series, Text","Model Inspection, Outcome Explanation",Other,Representation learning,"Heatmap, Feature Importance",Interpretability built into the predictive model,Yes,Yes
icdm/ChanLBR14,TRIBAC - Discovering Interpretable Clusters and Latent Structures in Graphs.,https://doi.org/10.1109/ICDM.2014.118,2014,ICDM,"Jeffrey Chan, Christopher Leckie, James Bailey 0001, Kotagiri Ramamohanarao",Graph data,Model Inspection,Other,Clustering,Feature plot,Interpretability built into the predictive model,Yes,Yes
kdd/BarbieriBM14,Who to follow and why - link prediction with explanations.,https://doi.org/10.1145/2623330.2623733,2014,KDD,"Nicola Barbieri, Francesco Bonchi, Giuseppe Manco 0001",Graph data,Outcome Explanation,Bayesian or Hierarchical Network,Classification,"Localization, Feature Importance",Post-hoc explanation method,Yes,Yes
kdd/GhalwashRO14,Utilizing temporal patterns for estimating uncertainty in interpretable early decision making.,https://doi.org/10.1145/2623330.2623694,2014,KDD,"Mohamed F. Ghalwash, Vladan Radosavljevic, Zoran Obradovic",Time series,Outcome Explanation,"Any (for a specific task); model-agnostic, Other",Classification,Prototypes,Interpretability built into the predictive model,Yes,Yes
sigir/ZhangL0ZLM14,Explicit factor models for explainable recommendation based on phrase-level sentiment analysis.,https://doi.org/10.1145/2600428.2609579,2014,SIGIR,"Yongfeng Zhang, Guokun Lai, Min Zhang 0006, Yi Zhang, Yiqun Liu 0001, Shaoping Ma","Text, User-item matrix",Outcome Explanation,(Deep) Neural Network,Recommendation,"Feature Importance, Text",Interpretability built into the predictive model,Yes,Yes
